{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\", \n",
        "      \"Product\", \n",
        "      \"Sub-product\", \n",
        "      \"Issue\", \n",
        "      \"Sub-issue\", \n",
        "      \"Consumer complaint narrative\", \n",
        "      \"Company public response\", \n",
        "      \"Company\", \n",
        "      \"State\", \n",
        "      \"ZIP code\", \n",
        "      \"Tags\", \n",
        "      \"Consumer consent provided?\", \n",
        "      \"Submitted via\", \n",
        "      \"Date sent to company\", \n",
        "      \"Company response to consumer\", \n",
        "      \"Timely response?\", \n",
        "      \"Consumer disputed?\", \n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/complaints.csv', 'row': 0, 'Date received': '03/27/25', 'Product': 'Student loan', 'Sub-product': 'Federal student loan servicing', 'Issue': 'Dealing with your lender or servicer', 'Sub-issue': 'Trouble with how payments are being handled', 'Consumer complaint narrative': \"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\", 'Company public response': 'None', 'Company': 'Nelnet, Inc.', 'State': 'IL', 'ZIP code': '60030', 'Tags': 'None', 'Consumer consent provided?': 'Consent provided', 'Submitted via': 'Web', 'Date sent to company': '03/27/25', 'Company response to consumer': 'Closed with explanation', 'Timely response?': 'Yes', 'Consumer disputed?': 'N/A', 'Complaint ID': '12686613'}, page_content=\"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\")"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common issues with student loans appear to be related to problems with loan servicing and administration. These include:\\n\\n- Dealing with lenders or servicers, such as receiving bad information, errors in loan balances, misapplied payments, wrongful denials of payment plans, and difficulties with how payments are being handled.\\n- Incorrect or inconsistent information on credit reports and account status.\\n- Discrepancies in loan balances and interest accumulation due to mismanagement or lack of transparency.\\n- Problems with loan transfer notifications and changes in servicers without proper communication.\\n- Issues with payment application, especially in applying extra funds to interest instead of principal, or restrictions on paying off smaller loans more quickly.\\n- Challenges with understanding or accessing repayment options, including forbearance, deferment, and loan forgiveness programs.\\n\\nWhile the specific questions about the \"most common issue\" can vary, the recurring theme in these complaints points toward **mismanagement and misinformation by loan servicers as the most common problem**. This includes errors in balances, lack of transparent communication, and difficulties in managing repayment or understanding loan terms.\\n\\nPlease note, if you are looking for a single most frequent issue, the broad category of \"Dealing with your lender or servicer\" appears repeatedly and encompasses many specific problems related to loan management and information accuracy.\\n\\n**In summary:**  \\nThe most common issue with loans, based on this data, is **problems arising from mismanagement, miscommunication, and errors by loan servicers or lenders**.'"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, yes, some complaints did not get handled in a timely manner. Specifically, there is at least one complaint where the response was noted as \"No\" under the \"Timely response?\" category, indicating it was not handled promptly. For example, the complaint received on 03/28/25 by MOHELA involved delays in addressing the issue, with the consumer reporting that they had not received any response or resolution after several weeks. \\n\\nAdditionally, multiple complaints mention extended periods without resolution—over a year in some cases—highlighting ongoing delays and issues with timely handling.\\n\\nTherefore, the answer is: Yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a combination of factors including: \\n\\n1. Lack of clear communication and notification from loan servicers about when payments were to resume or any changes in loan status.\\n2. The complexity of repayment options, such as forbearance or deferment, which often lead to accruing interest that increases the total amount owed over time.\\n3. Financial hardships such as stagnant wages, inflation, and unforeseen economic downturns, making it difficult for individuals to afford increasing or unchanged payments.\\n4. Mismanagement or lack of transparency regarding loan transfers, interest calculations, and delinquency reporting, which can cause confusion and unintended delinquency.\\n5. Limited access to or awareness of income-driven repayment plans or forgiveness programs, leading individuals to default when they cannot meet standard repayment terms.\\n6. Problems with loan servicing practices, where payments are applied in a manner that favors interest accumulation or where borrowers are not properly notified about their loan status, resulting in late payments, credit score drops, and further financial hardship.\\n\\nOverall, these issues stem from a combination of systemic miscommunication, economic hardship, and the complex, often opaque nature of student loan management.'"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans, specifically student loans, appears to be problems dealing with lenders or servicers. Common sub-issues include disputes over fees charged, trouble with how payments are being handled (such as difficulty applying payments correctly), and receiving incorrect or bad information about loan balances and terms. These issues often involve a lack of trust in the loan servicers, allegations of predatory practices, and difficulties in understanding or managing loan details.\\n\\nTherefore, the most common issue with loans, as indicated by the complaints, is problems related to dealing with lenders or servicers, including mismanagement, miscommunication, and issues with payment application and fees.'"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all of the complaints referenced were responded to in a timely manner. Specifically, the responses to complaints numbered 13197090, 12792958, 13160766, and 13410623 were all marked as \"Yes\" for timely response.'"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People often fail to pay back their loans due to issues such as incorrect or problematic payment plans, lack of communication from the lender or servicer, or difficulties stemming from mismanagement or deception by the loan servicing companies. For example, some individuals have experienced their autopayments being unenrolled or not properly communicated, leading to missed or late payments. Others have faced challenges with repayment plans that do not suit their financial situation or have been misled about their account status, resulting in unpaid bills and damaged credit scores. Additionally, some borrowers have reported the transfer of their loans to different companies without proper notification, causing confusion and unintended missed payments. Overall, failures to repay are often linked to poor communication, administrative errors, or problematic servicing practices.'"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "Example: \"How to fix PostgreSQL error 23505 duplicate key violation\" in documents related to databases/general CS\n",
        "Explanation: BM25 retriever looks for exact matches, so a rare error would be easily found by it. Naive retriever may look up documents that look similar but ultimately fail to mention this specific error. \n",
        "General principle: BM25 will perform really well where exact term matches are important. While naive retriever will focus on similar documents, BM25 will focus on documents with exact matches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans, particularly student loans, appears to be problems related to the handling of payments, interest accumulation, and information accuracy. Many complaints highlight issues such as:\\n\\n- Interest continuing to accrue during forbearance or deferment, leading to increased total debt.\\n- Lack of transparent information about loan balances, interest calculations, and payment breakdowns.\\n- Errors and inconsistencies in loan balances and interest in credit reports.\\n- Difficulties in managing payments, with options like forbearance or deferment often leading to increased total debt rather than reducing it.\\n\\nOverall, a primary issue is the mismanagement and lack of clear communication from loan servicers regarding how loans are handled, especially around interest accumulation and repayment options.'"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, there are indications that some complaints did not get handled in a timely manner. For example, a complaint about a delayed response to a request has been open for over 1 year without resolution, and nearly 18 months with no resolution regarding account review and violations. Additionally, issues related to payments not being applied correctly were ongoing, with no resolution mentioned. \\n\\nTherefore, yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans primarily due to a lack of clear communication, misunderstandings about loan obligations, and the ongoing accumulation of interest. Many borrowers were not adequately informed about their repayment responsibilities, the effect of interest, or changes in their loan status, such as transfers between servicers without notice. Additionally, options like forbearance or deferment, while accessible, often led to interest continuing to accrue, making it harder to pay off loans over time. Economic hardships, stagnant wages, and unmanageable payment plans also contributed to borrowers' difficulties in repayment.\""
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issues with loans include:\\n\\n- Errors in loan balances, misapplied payments, and wrongful denials of payment plans.\\n- Problems with how payments are being handled, such as inability to apply additional funds to the principal.\\n- Discrepancies and inaccuracies in loan account status and reporting, including incorrect default or delinquency reports.\\n- Lack of communication or inadequate notification from lenders or servicers.\\n- Unauthorized transfers or mishandling of loans.\\n- Problems related to loan forgiveness, discharge, or cancellation.\\n- Issues with loan servicer misconduct, including errors due to bad information or improper processing.\\n- Problems with credit reporting, including incorrect account status or account data.\\n- Challenges in managing repayment plans, especially for borrowers facing financial hardship.\\n- Negative impacts on credit scores due to improper reporting or delays in communication.\\n\\nWhile the specific \"most common\" issue isn\\'t explicitly stated as a single point in the document, errors and mismanagement related to loan balances, account statuses, and the handling of payments or reporting seem to be the predominant themes.\\n\\nIf I had to summarize, the most common issue appears to be **errors and miscommunications related to loan account management and reporting**.\\n\\nPlease note that the issues are often interconnected, and errors in account handling appear frequently across multiple complaints.\\n\\nIf you need a more specific focus or detail, feel free to ask!'"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, it appears that some complaints were not handled in a timely manner. Specifically:\\n\\n- One complaint from 03/28/25 regarding problems with customer service at MOHELA was marked as \"Timely response? No,\" indicating it was not handled within the expected timeframe.\\n- Another complaint from 03/25/25 also about MOHELA\\'s customer service was marked as \"Timely response? No.\"\\n- Several other complaints, such as those from 04/18/25 and 04/24/25, were marked as \"Yes\" for timely responses, indicating they were handled within the expected period.\\n- However, there are complaints from 04/24/25 and 05/06/25 noted as \"Yes,\" implying some complaints are handled on time, but the ones specifically marked \"No\" suggest delays.\\n\\nTherefore, yes, there were complaints that did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans mainly due to a combination of systemic issues, lack of transparent information, and the way loan servicers handled repayment options. The key reasons include:\\n\\n1. **Limited or Misleading Payment Options:** Many borrowers were only offered forbearance or deferment, which allowed interest to continue accumulating, making loans more difficult to pay off over time and increasing the total debt.\\n\\n2. **Lack of Awareness of Alternative Repayment Plans:** Borrowers were often not informed about income-driven repayment plans or loan forgiveness programs that could make repayment more manageable.\\n\\n3. **Interest Accumulation and Capitalization:** Without proper guidance, borrowers did not understand how interest would compound, leading to loans ballooning in size despite ongoing payments.\\n\\n4. **Mismanagement and Poor Communication:** Several complaints highlight that servicers did not properly notify borrowers about their account status, missed payments, or opportunities for alternative repayment options, leading to unintentional delinquency or default.\\n\\n5. **Systemic Failures and Mistreatment:** Instances of forbearance steering, coercive practices to consolidate loans, and reporting errors have caused borrowers' credit scores to drop and their debts to increase unnecessarily.\\n\\n6. **Financial Hardships and Misunderstanding:** Many borrowers faced economic challenges, stagnant wages, or unexpected events like accidents or homelessness, which made repayment unfeasible, especially when compounded by lack of support and poor information.\\n\\nIn summary, failure to repay was often a result of systemic problems in loan servicing, poor communication, and borrowers' financial hardships compounded by the complex, and sometimes opaque, management of their loans.\""
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "1. Slightly reformulated user queries can lead to better targeted retrieval when original user query is incomplete. \n",
        "2. If we do not reduce number of retrieved documents per each query, we'll simply have more documents retrieved into the context. Given that recall = \"Retrieved relevant docs\" / \"Total relevant docs\", we may improve numerator simply by having more documents in the context. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to be related to errors and misconduct by loan servicers, including misreported account information, errors in loan balances, misapplied payments, wrongful denials of payment plans, and issues with loan reporting to credit bureaus. Additionally, complaints frequently mention difficulties in understanding or verifying loan terms, interest rate discrepancies, and improper handling of loans after sale or transfer.'"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all the complaints identified were marked as \"No\" under the \"Timely response?\" field, indicating they were not handled in a timely manner. Specifically, two complaints involving Mohela were explicitly noted as \"No,\" meaning they did not receive a timely response.'"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for various reasons, including:\\n\\n1. Lack of clear communication or proper notification from loan servicers about payment obligations, due dates, or changes in the servicing company.\\n2. Financial hardship or severe economic difficulties that made it impossible to afford repayments.\\n3. Misrepresentations or misleading information regarding the value or manageability of the loans, especially in cases where institutions misled students about career prospects or the stability of their schools.\\n4. Long-term financial consequences that were not fully understood at the time of borrowing, such as accruing interest during deferment or forbearance.\\n5. Institutional issues, such as schools closing or facing financial problems, which impacted graduates' ability to secure employment and ultimately repay loans.\\n6. Administrative errors or disputes, including incorrect reporting of payments, unauthorized collection efforts, or issues verifying the legitimacy of the debt.\\n\\nOverall, the combination of financial hardship, lack of proper information, institutional misconduct, and administrative problems contributed to borrowers' difficulties in repaying their loans.\""
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be dealing with or problematic handling by loan servicers and lenders. Specific sub-issues frequently reported include errors in loan balances, misapplied payments, wrongful denials of payment plans or forgiveness, incorrect account statuses, poor communication or lack of transparency, and unfair or predatory payment enforcement practices. Many complaints also mention the mishandling of loan transfers, incorrect classification of loan types, inaccurate reporting of delinquency status, and issues with understanding or managing interest calculations.\\n\\nIn summary, the predominant problem is the mishandling and mismanagement of student loans by servicers, leading to errors, misinformation, and financial hardship for borrowers.'"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, according to the provided complaints, some complaints were not handled in a timely manner. For example, complaint ID 12935889 regarding issues with Mohela was marked as \"No\" response to being timely, indicating it was not addressed promptly. Similarly, complaint ID 12654977 involving Mohela was also marked as \"No\" for timely response. \\n\\nHowever, there are other complaints, such as IDs 13205525 and 13056764, which were marked as \"Yes\" for timely responses. Overall, at least some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for several reasons, including:\\n\\n1. **Lack of clear and accurate information from lenders or servicers:** Many borrowers were misled or not properly informed about repayment options, interest accumulation, and the long-term costs, leading to confusion and unmanageable debt.\\n\\n2. **Financial hardships:** Borrowers faced unforeseen circumstances such as unemployment, health issues, or economic downturns, making it difficult or impossible to make payments.\\n\\n3. **Inadequate communication and notification:** Several complaints highlighted that servicers did not notify borrowers about the start of repayment, missed payments, or changes in loan status, which sometimes resulted in unintentional delinquency.\\n\\n4. **Problematic loan management practices:** Issues such as improper transfers of loans, errors in account reporting, misapplied payments, and difficulty applying extra payments directly to the principal caused loan balances to grow or payments to become unmanageable.\\n\\n5. **Interest and fees accumulation:** In some cases, borrowers’ balances increased over time due to interest capitalization and the failure to benefit from forgiveness or discharge programs because of mishandling or lack of information.\\n\\n6. **Loan transfer and servicing errors:** Transfers between loan servicers without proper notification caused confusion, missed payments, and negative credit impacts.\\n\\n7. **Difficulty accessing or understanding payment plans:** Borrowers had trouble enrolling in income-driven plans or renegotiating repayment terms, leading to default or delinquency.\\n\\n8. **Perception of predatory practices:** Some borrowers viewed the terms and handling of their loans as unfair or deceptive, especially when servicers steered them into forbearances or failed to offer alternative options.\\n\\nOverall, these issues contributed to borrowers being unable to meet repayment obligations, often not due to irresponsibility but because of systemic mismanagement, miscommunication, and economic hardship.'"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints data, the most common issues with loans tend to involve problems related to borrower communication and account handling, including:\\n\\n- Trouble with how payments are being handled (e.g., auto-debit issues, re-amortization delays)\\n- Receiving incorrect or bad information about the loan status or terms\\n- Problems with loan reporting and credit reporting errors\\n- Difficulties contacting or receiving responsive assistance from the lender or servicer\\n- Disputes over unauthorized or illegal collection practices or privacy breaches\\n\\nOverall, issues related to miscommunication, improper handling of payments, and reporting errors appear most frequently. \\n\\nIf I had to identify the most common issue from this data, it seems to be related to **\"dealing with your lender or servicer,\"** especially issues such as incorrect information, billing problems, and lack of clear communication.\\n\\nIf you need a precise summary, the most recurring theme appears to be **failure of loan servicers to properly communicate or manage the borrower\\'s account, leading to billing errors, reporting mistakes, and difficulties in obtaining accurate information.**'"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, several complaints indicated that they were not handled in a timely manner. For example, one complaint about Nelnet (received on 05/04/25) detailed that despite sending multiple letters by Certified Mail and acknowledging receipt, Nelnet never responded to the complaint. Similarly, another complaint (received on 04/13/25) about Nelnet involved ongoing issues with unresolved disputes and alleged violations, though the response from the company was described as \"Closed with explanation.\" \\n\\nAdditionally, multiple complaints mention delays or lack of responses from the service providers, suggesting that not all complaints were addressed promptly. Therefore, based on this data, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for various reasons reflected in the complaints. Some common reasons include:\\n\\n1. **Lack of Communication and Transparency:** Borrowers experienced poor communication from lenders or servicers, making it difficult to understand their loan status or repayment options. For example, one individual received inconsistent information about their forbearance status and had trouble logging into their accounts.\\n\\n2. **Disputes Over Loan Accuracy and Legitimacy:** Borrowers faced issues with incorrect or disputed loan information, such as loans wrongly reported as delinquent or in default, or discrepancies about payments made. Some were unaware their loans had gone into default due to miscommunications or errors in reporting.\\n\\n3. **Problems with Loan Servicers and Mishandling of Documentation:** Several complaints involved servicers stalling or refusing to process forgiveness or discharge paperwork, or mishandling documentation related to loan forgiveness programs.\\n\\n4. **Legal and Administrative Complications:** Actions such as illegal reporting, data breaches, or the illegitimacy of debts (e.g., due to the abolishment of the Department of Education) contributed to borrowers' inability to repay, as some debts became legally questionable.\\n\\n5. **Financial Hardship or Difficulties in Adjusting to Payment Changes:** Borrowers faced increased payments after forbearance periods ended or due to re-amortization issues, which they may not have been able to afford, leading to missed payments or default.\\n\\nIn summary, failures to repay loans often stem from poor communication, administrative errors, legal disputes over loan validity, and financial difficulties exacerbated by communication and procedural issues.\""
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "\n",
        "Potential problems:\n",
        "1. Embeddings will look similar because they will often have similar pattern (\"How do I..?\")\n",
        "2. Semantic chunking may merge way too much because of the unnaturally high similarity\n",
        "3. Because chunks are overmerged, they add irrelevant information and are big. This means that generation may provide irrelevant information to the user. \n",
        "\n",
        "Fixes I could think of:\n",
        "1. Change threshold to prevent overmerging.\n",
        "2. Cap chunk length to avoid overmerging (although that still may lead to chunks that have random info, while also having incomplete chunks)\n",
        "3. Remove repetitive info from documents (E.g., \"How do\", \"Thank you\", etc.)\n",
        "4. For FAQs specifically, first chunk each question with its answer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import utils\n",
        "utils.get_env_var.cache_clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = f\"AIE7 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16266e9d16044d7494897d0c38b98ac3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140d4eef1b244c40a4af5a07f5060bc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node dd29059b-359d-4141-a870-8d763c1591fe does not have a summary. Skipping filtering.\n",
            "Node c142025d-29e2-4f06-b20e-7958e6fd6b81 does not have a summary. Skipping filtering.\n",
            "Node 7c013f96-9fa3-42dd-beaf-b6b33e2732f8 does not have a summary. Skipping filtering.\n",
            "Node a18f74d8-131d-4681-a1e5-e7d72bdf49b8 does not have a summary. Skipping filtering.\n",
            "Node 70f90cfe-2066-4f16-be53-7a0d6d2ab15f does not have a summary. Skipping filtering.\n",
            "Node 3381621b-f62c-47fc-ad47-7f6f2a08ea30 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67afd8a890464ed280c39afdfac003d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/54 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e3bf800312a4d67abd8317b34af2e85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1544c8105e574b60a8eebe02533c6719",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bff88147c3434ffa83f726fc91db3c1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52ca22301eb84a4f943f64724930b678",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to run retrieval chain\n",
            "Attempting to run retrieval chain\n",
            "Attempting to run retrieval chain\n",
            "Attempting to run retrieval chain\n",
            "Attempting to run retrieval chain\n",
            "Attempting to run retrieval chain\n"
          ]
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from ragas.testset import TestsetGenerator\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "import copy\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(loan_complaint_data[:20], testset_size=10)\n",
        "\n",
        "dataset.to_pandas()\n",
        "\n",
        "all_retrievers = [naive_retrieval_chain, bm25_retrieval_chain, parent_document_retrieval_chain, contextual_compression_retrieval_chain, multi_query_retrieval_chain, ensemble_retriever]\n",
        "\n",
        "dataset_for_naive = copy.deepcopy(dataset)\n",
        "dataset_for_bm25 = copy.deepcopy(dataset)\n",
        "dataset_for_parent_document = copy.deepcopy(dataset)\n",
        "dataset_for_contextual_compression = copy.deepcopy(dataset)\n",
        "dataset_for_multi_query = copy.deepcopy(dataset)\n",
        "dataset_for_ensemble = copy.deepcopy(dataset)\n",
        "\n",
        "retriever_dataset_pairs = [\n",
        "    (naive_retrieval_chain,          dataset_for_naive),\n",
        "    (bm25_retrieval_chain,           dataset_for_bm25),\n",
        "    (parent_document_retrieval_chain, dataset_for_parent_document),\n",
        "    (contextual_compression_retrieval_chain, dataset_for_contextual_compression),\n",
        "    (multi_query_retrieval_chain,    dataset_for_multi_query),\n",
        "    (ensemble_retrieval_chain,             dataset_for_ensemble),\n",
        "]\n",
        "\n",
        "for retriever,ds in retriever_dataset_pairs:\n",
        "    print(\"Attempting to run retrieval chain\")\n",
        "    for test_row in ds:\n",
        "        response = retriever.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "        test_row.eval_sample.response = response[\"response\"].content\n",
        "        test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on retrieval chain 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ff6cba8ad6a45ec85e4bee65f1b6f00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 1 results\n",
            "{'llm_context_precision_without_reference': 0.9691, 'context_recall': 0.9375, 'context_entity_recall': 0.5133, 'noise_sensitivity(mode=relevant)': 0.2467}\n",
            "Working on retrieval chain 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd87e2b8938346058324d2a483babefa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 2 results\n",
            "{'llm_context_precision_without_reference': 0.9375, 'context_recall': 0.6542, 'context_entity_recall': 0.3843, 'noise_sensitivity(mode=relevant)': 0.2107}\n",
            "Working on retrieval chain 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "307adc68f482434294e2e4819906c1a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 3 results\n",
            "{'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.8667, 'context_entity_recall': 0.4927, 'noise_sensitivity(mode=relevant)': 0.3550}\n",
            "Working on retrieval chain 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8792335a0d8c4e4cbfc0488837723037",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 4 results\n",
            "{'llm_context_precision_without_reference': 1.0000, 'context_recall': 0.8125, 'context_entity_recall': 0.5509, 'noise_sensitivity(mode=relevant)': 0.1763}\n",
            "Working on retrieval chain 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47c09c8c91da44bea094e4ae1ae5ec97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[31]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 5 results\n",
            "{'llm_context_precision_without_reference': 0.9178, 'context_recall': 0.9583, 'context_entity_recall': 0.5269, 'noise_sensitivity(mode=relevant)': 0.3699}\n",
            "Working on retrieval chain 6\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "397fe94f644345d78f6c0204f9b57371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[7]: TimeoutError()\n",
            "Exception raised in Job[19]: TimeoutError()\n",
            "Exception raised in Job[27]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval chain 6 results\n",
            "{'llm_context_precision_without_reference': 0.9418, 'context_recall': 0.9792, 'context_entity_recall': 0.5083, 'noise_sensitivity(mode=relevant)': 0.3593}\n"
          ]
        }
      ],
      "source": [
        "from ragas import EvaluationDataset\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, LLMContextPrecisionWithoutReference, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "custom_run_config = RunConfig(timeout=960)\n",
        "\n",
        "ii = 0\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for i, (retriever, ds) in enumerate(retriever_dataset_pairs, start=1):\n",
        "    print(f\"Working on retrieval chain {i}\")\n",
        "    \n",
        "    temp_eval_dataset = EvaluationDataset.from_pandas(ds.to_pandas()[:8])\n",
        "    \n",
        "    result = evaluate(\n",
        "        dataset=temp_eval_dataset,\n",
        "        metrics=[\n",
        "            LLMContextPrecisionWithoutReference(),\n",
        "            LLMContextRecall(),\n",
        "            ContextEntityRecall(),\n",
        "            NoiseSensitivity()\n",
        "        ],\n",
        "        llm=evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "    \n",
        "    print(f\"Retrieval chain {i} results\")\n",
        "    print(result)\n",
        "    all_results[f\"retriever_{i}\"] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "I had to cut down on the number of metrics and examples, otherwise it wasn't possible to complete even with the small dataset we have (ragas is extremely cost/time consuming). \n",
        "\n",
        "##### Comparison table\n",
        "| Metric                     | Naive  | BM25   | Parent doc | ContextCompress | Multi query | Ensemble |\n",
        "| :-------------------------:| :----: | :----: | :--------: | :-------------: | :---------: | :------: |\n",
        "| Context precision (no ref) | 0.9691 | 0.9375 | **✅ 1.0000** | **✅ 1.0000**   | 0.9178    | 0.9418   |\n",
        "| Context recall             | 0.9375 | 0.6542 | 0.8667     | 0.8125          | **✅0.9583** | **✅0.9792**   |\n",
        "| Context entity recall      | **✅0.5133** | 0.3843 | **✅0.4927**     | **✅0.5509**          | **✅0.5269**      | **✅0.5083**   |\n",
        "| Noise sensitivity          | **✅0.2467** | **✅0.2107** | 0.3550     | **✅0.1763**          | 0.3699      | 0.3593   |\n",
        "| Tokens | 93,065 | **✅50,255** | **✅48,888** | **✅30,548 + ???** | 146,417 | 202,328 |\n",
        "| Cost   | **✅$0.01** | **✅$0.01** | **✅$0.01** | **✅$0.005 + $0.002** | $0.02 | $0.02 | \n",
        "| P50 Latency | **✅3.66s** | **✅2.95s** | **✅3.62s** | **✅3.72s** | 6.90s | 6.81s |\n",
        "| P99 Latency | **✅7.33s** | **✅5.77s** | **✅6.45s** | **✅5.67s** | 11.20s | 10.44s |\n",
        "\n",
        "Disclaimer: despite low sample size, I treat this table as if it has a significant sample size, otherwise there is no meaningful interpretation. RAGAS also runs multi-tests to make evals more robust (which doesn't fixes things if underlying dataset is no good, of course). \n",
        "\n",
        "My conclusion:\n",
        "1. Context precision seems to be quite similar across retrievers. Context compression retriever and parent doc outperform other retrievers, because some may be too simplistic (naive, bm25) to have strong context targeting, while other may simply bring in too much context, including the context from simplistic retrievers (ensemble).\n",
        "2. Context recall is high for retrievers with high numbers of retrieved docs, as the metric focuses on not missing important docs. BM25 underperforms as expected due to its simplistic nature that has low fit with non-exact match queries. Context compression retriever underperforms as it cuts down on the number of docs included. \n",
        "3. Context entity recall is mostly similar across retrievers. \n",
        "4. Noise sensitivity (lower — better) is good for retrievers that retrieve low number of documents because it prevents context overload where LLM gets too much information. \n",
        "5. Both token count, costs, and latency explode for multi-query retriever and ensemble retriever. \n",
        "\n",
        "My recommendation:\n",
        "1. Context compression retriever shows strong results across all performance measures while being among the best in both cost and latency. For general cases, I'd prefer going with the context compression retriever. I also like parent doc retriever performance, and the underlying logic of parent doc retriever.  \n",
        "2. However, our current ensemble retriever includes all other retrievers in it. We'd probably get way better cost/latency if we cut down on used retrievers; considering that multiple retrievers also introduce redundancy and context overload, we could probably improve performance of that retriever by using a few retrievers instead of the current state. \n",
        "3. This HW took hours (waiting for data, etc), so I'm not going to re-run ensemble before HW deadline, but will definitely explore other configurations on my own. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
