{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpWDFG11o3G"
      },
      "source": [
        "# Multi-Agent Workflows + RAG - LangGraph\n",
        "\n",
        "Today we'll be looking at an example of a Multi-Agent workflow that's powered by LangGraph, LCEL, and more!\n",
        "\n",
        "We're going to be, more specifically, looking at a \"heirarchical agent teams\" from the [AutoGen: Enabling Next-Gen LLM\n",
        "Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155) paper.\n",
        "\n",
        "This will be the final \"graph\" of our system:\n",
        "\n",
        "![image](https://i.imgur.com/Xro0QiR.png)\n",
        "\n",
        "It's important to keep in mind that the actual implementation will be constructed of 3 separate graphs, the final one having 2 graphs as nodes! LangGraph is a heckuva tool!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyzoBrWoYeOZ"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx3oaVoX5cA2"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv2MWqu5vS9"
      },
      "source": [
        "Since we'll be relying on OpenAI's suite of models to power our agents today, we'll want to provide our OpenAI API Key.\n",
        "\n",
        "We're also going to be using the Tavily search tool - so we'll want to provide that API key as well!\n",
        "\n",
        "Instruction for how to obtain the Tavily API key can be found:\n",
        "\n",
        "1. [Tavily API Key](https://app.tavily.com/sign-in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h30OjkLfeR2Y",
        "outputId": "f75bb26e-b89d-4611-c29b-f339b3e868af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_LD7rwT6PbO"
      },
      "source": [
        "## Task 1: Simple LangGraph RAG\n",
        "\n",
        "Now that we have our dependencies set-up - let's create a simple RAG graph that works over our Loan PDFs from previous sessions.\n",
        "\n",
        "> NOTE: While this particular example is very straight forward - you can \"plug in\" any complexity of chain you desire as a node in a LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7T5kxJ6jGn"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "The 'R' in 'RAG' - this is, at this point, fairly straightforward!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuPxSCk7Ztz"
      },
      "source": [
        "#### Data Collection and Processing\n",
        "\n",
        "A classic first step, at this point, let's grab our desired document!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LfuoEYRCln3H"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "\n",
        "loan_knowledge_resources = directory_loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_t_F1zG6vXa"
      },
      "source": [
        "Now we can chunk it down to size!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5R7A_z8CgL79"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")\n",
        "\n",
        "loan_knowledge_chunks = text_splitter.split_documents(loan_knowledge_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGE-VuMc7AKv"
      },
      "source": [
        "Now we've successfully split our single PDF into..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgYBHsdWmLvW",
        "outputId": "aa9a830e-f7db-4bb3-f542-c0614cb01aca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(loan_knowledge_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxaKmmyh7DHD"
      },
      "source": [
        "documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGWs7KTd7QPS"
      },
      "source": [
        "#### Embedding Model and Vector Store\n",
        "\n",
        "Now that we have our chunked document - lets create a vector store, which will first require us to create an embedding model to get the vector representations of our text!\n",
        "\n",
        "We'll use OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) model - as it's cheap, and performant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xLIWMMZCmfrj"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEi7Ww573sc"
      },
      "source": [
        "Now we can create our QDrant backed vector store!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xct51f8omVAU"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vectorstore = Qdrant.from_documents(\n",
        "    documents=loan_knowledge_chunks,\n",
        "    embedding=embedding_model,\n",
        "    location=\":memory:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGq6o4s79Ar"
      },
      "source": [
        "Let's make sure we can access it as a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OTnQZbWymi4K"
      },
      "outputs": [],
      "source": [
        "qdrant_retriever = qdrant_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU8qSrMS7_D7"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Now that we have our retrieval process set-up, we need to set up our \"augmentation\" process - AKA a prompt template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lezTN0zCmk46"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context respond with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9fa63nM7IKK"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Last, but certainly not least, let's put the 'G' in 'RAG' by adding our generator - in this case, we can rely on OpenAI's [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AwEi29-Jo3a8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO-ZC0T98XJJ"
      },
      "source": [
        "### RAG - Retrieval Augmented Generation\n",
        "\n",
        "All that's left to do is combine our R, A, and G into a single graph - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nlOJrPm_oT3S"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: list[Document]\n",
        "  response: str\n",
        "\n",
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = qdrant_retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}\n",
        "\n",
        "def generate(state: State) -> State:\n",
        "  generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder = graph_builder.add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "rag_graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x1411bbb50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiWrbXpu8ggz"
      },
      "source": [
        "Let's test this out and make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gJhFlW32pBPe",
        "outputId": "7aee04b6-608f-4639-adca-66225d4d3002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the maximum loan amount?',\n",
              " 'context': [Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 69, '_id': '16a4f0b1ee4a4859848529c10100d808', '_collection_name': '858d1990609347649a02ca59c2b403b9'}, page_content='program. Therefore, the maximum loan amount the student may receive for the program at School B (for the\\nabbreviated loan period and any subsequent loan period combined) is a total of $1,815, not more than $1,155 of\\nwhich may be subsidized (the prorated loan limits for the program). If the student receives the maximum prorated\\nloan limit for the program during the abbreviated loan period, there is no remaining loan eligibility for the\\nprogram following the completion of the abbreviated loan period.'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 39, '_id': '2299ab78e26d445494cca5e7a8f4c029', '_collection_name': '858d1990609347649a02ca59c2b403b9'}, page_content='Volume 8, Chapter 4, Table 4: Aggregate Limits for Direct Subsidized Loans and Direct Unsubsidized Loans\\nTotal (Subsidized and\\nUnsubsidized)\\nMaximum\\nSubsidized\\nDependent undergraduates (excluding those whose parents can9t get\\nDirect PLUS Loans)\\n$31,000\\n$23,000\\nIndependent undergraduates (and dependent undergraduates whose\\nparents can9t get Direct PLUS Loans)\\n$57,500\\n$23,000\\nGraduate and professional students\\n$138,500\\n$65,500\\nNotes on the aggregate loan limits shown in Table 4:\\nThe <Total (Subsidized and Unsubsidized)= column shows the maximum combined outstanding subsidized and\\nunsubsidized loan debt for a student. The <Maximum Subsidized= column shows the maximum portion of the\\ncombined subsidized and unsubsidized limit that may be subsidized. For example, a dependent undergraduate may\\nhave up to a maximum of $31,000 in combined subsidized and unsubsidized outstanding loan debt, but no more\\nthan $23,000 of this amount may consist of subsidized loans.\\nCapitalized interest (unpaid accrued interest that has been added to the principal balance of a loan) is not counted\\ntoward a borrower9s aggregate loan limits (see \"Checking Remaining Loan Eligibility Under Aggregate Loan Limits=\\nbelow for more information).\\nThe $138,500 combined subsidized and unsubsidized aggregate loan limit for graduate and professional students\\nincludes loans received for undergraduate study.\\nThe $65,500 subsidized aggregate loan limit for graduate and professional students includes subsidized loans\\nreceived for prior undergraduate study. It also includes any subsidized loans received for prior graduate or\\nprofessional study before July 1, 2012, when graduate and professional students were eligible to receive subsidized\\nloans (subsidized loan eligibility for graduate and professional students was eliminated effective for loan periods\\nbeginning on or after July 1, 2012).\\nThe loan amounts counted toward a borrower9s aggregate loan limits include any outstanding Direct Subsidized Loan\\nand Direct Unsubsidized Loan amounts, and also any outstanding Subsidized and Unsubsidized Federal Stafford\\nLoans previously borrowed under the FFEL Program (no new loans have been made under the FFEL Program since\\nJune 30, 2010).\\nIf a borrower has a Direct Consolidation Loan or a Federal Consolidation Loan (a consolidation loan made under the\\nFFEL Program), the outstanding amount of the consolidation loan representing any Direct Subsidized Loans, Direct\\nUnsubsidized Loans, Subsidized Federal Stafford Loans, or Unsubsidized Federal Stafford Loans that were paid off by\\nthe consolidation loan is counted toward the borrower9s aggregate subsidized and unsubsidized loan limits\\naccordingly.\\nAggregate Loan Limit for an Undergraduate Student With a Graduate Degree\\nAggregate Loan Limits\\n34 CFR 685.203(d), (e)'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 67, '_id': '9748f4636cf349c5a6e2ed25986da436', '_collection_name': '858d1990609347649a02ca59c2b403b9'}, page_content='Generally, the maximum loan amount that the student can receive for the abbreviated loan period is the difference\\nbetween the full annual loan limit applicable to the student at the new school and the loan amount that was\\ndisbursed at the prior school during the overlapping academic year (see the preceding discussion for an exception to\\nthis general rule).\\nThe first disbursement of the loan for the abbreviated loan period at the new school is made at the beginning of the\\nabbreviated loan period. Unless the school qualifies based on its cohort default rate for the exemption from the\\nmultiple disbursement requirement (see Volume 3, Chapter 1), the loan must be disbursed in at least two'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 41, '_id': 'f49f0579f3ff415282bdf2673039a193', '_collection_name': '858d1990609347649a02ca59c2b403b9'}, page_content='teacher certification and preparatory coursework and the applicable annual loan limits.)\\nHigher Aggregate Loan Limit for Certain Health Professions Students\\nAs explained earlier in this chapter, graduate and professional students who are enrolled in certain health professions\\nprograms are eligible for higher annual Direct Unsubsidized Loan limits. These students also have a higher combined\\nsubsidized and unsubsidized aggregate loan limit.\\nThe combined subsidized and unsubsidized aggregate loan limit for graduate and professional health professions students\\nwho are eligible to receive the increased annual unsubsidized amounts is $224,000. Not more than $65,500 of this\\namount may be from subsidized loans (see the notes following Table 4 above regarding the $65,500 subsidized aggregate\\nloan limit for graduate and professional students).\\nIf a student who received increased Direct Unsubsidized Loan amounts for a qualifying health profession program later\\nenrolls in a non-health professions program, the student is no longer eligible for the increased Direct Unsubsidized Loan\\nlimits. However, the additional loan amounts received for the health professions program are not counted toward the\\nnormal aggregate loan limit for that student.\\nChecking Remaining Eligibility Under the Aggregate Loan Limits\\nBefore originating a Direct Subsidized Loan or Direct Unsubsidized Loan, it9s important to make sure the student still has\\nremaining eligibility under the aggregate loan limits. As long as there is no conflicting information, you may rely on the\\nfinancial aid history (provided on the ISIR as well as on the NSLDS Professional Access website) and the Transfer Student\\nMonitoring process (for transfer students only) to tell you if a student is about to exceed the applicable aggregate loan\\nlimit. (See Volume 1, Chapter 3 for more detail on NSLDS financial aid history, which may also affect eligibility for other\\nTitle IV programs.)\\nThe Loan History in NSLDS for a borrower who has received Title IV loans shows Aggregate Loan Information for the\\nborrower9s outstanding subsidized and unsubsidized loans. The Subsidized and Unsubsidized Aggregate Outstanding\\nPrincipal Balance amounts shown for a borrower in NSLDS do not include unpaid accrued interest, capitalized interest\\n(unpaid interest that has been added to the principal balance of the loan), or other charges, as these amounts are not\\ncounted against the aggregate loan limits.\\nFor each individual loan that a borrower has received, NSLDS shows both the Outstanding Principal Balance (OPB) and the\\nAggregate Outstanding Principal Balance (Agg. OPB). The OPB is what the borrower owes, which may include capitalized\\ninterest and other charges. The Agg. OPB is the portion of the OPB that counts against the aggregate loan limits for\\nsubsidized and unsubsidized loans.\\nFor instance, suppose a student has a Direct Unsubsidized Loan disbursed in the amount of $5,000. Over time, $200 in\\ninterest accrues and is capitalized. Assuming that the borrower has made no payments on the loan, the OPB on the loan\\nwill be $5,200 (this is the amount the borrower owes), and the Agg. OPB will be $5,000 (this is the amount that is counted\\nagainst the aggregate loan limit). If you are looking at information in NSLDS for individual loans, it is the Agg. OPB that\\nyou should use to determine the student9s remaining loan eligibility under the applicable aggregate loan limit.\\nThe Subsidized and Unsubsidized Aggregate Outstanding Principal Balance amounts displayed in NSLDS for a borrower')],\n",
              " 'response': 'The maximum loan amount the student may receive for the program at School B (for the abbreviated loan period and any subsequent loan period combined) is a total of $1,815, of which no more than $1,155 may be subsidized.'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_graph.invoke({\"question\" : \"What is the maximum loan amount?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gReMizYk8qd-"
      },
      "source": [
        "### RAG Limitation\n",
        "\n",
        "Notice how we're hard-coding our data, while this is simply meant to be an illustrative example - you could easily extend this to work with any provied paper or document in order to have a more dynamic system.\n",
        "\n",
        "For now, we'll stick with this single hard-coded example in order to keep complexity down in an already very long notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxkbuir-H5rE"
      },
      "source": [
        "##### 🏗️ Activity #1 (Bonus Marks)\n",
        "\n",
        "Allow the system to dynamically fetch Arxiv papers instead of hard coding them.\n",
        "\n",
        "> HINT: Tuesday's assignment will be very useful here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE7 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "import arxiv, requests, uuid, os\n",
        "from langgraph.graph import END\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "class ResearchState(TypedDict, total=False):  # `total=False` = optional keys allowed\n",
        "    question: str\n",
        "    docs: list\n",
        "    chunks: list\n",
        "    context: list\n",
        "    response: str\n",
        "    pdf_path: str\n",
        "    retriever: any\n",
        "    arxiv_metadata: dict \n",
        "    search_query: str\n",
        "\n",
        "def refine_query(state):\n",
        "    # Use your existing chat model to turn the freeform user question\n",
        "    # into a tight arXiv-style query.\n",
        "    system_prompt = \"\"\"\n",
        "You are a helpful assistant that turns a user's research request\n",
        "into a concise arXiv search query. Strip out anything that's not\n",
        "essential keywords or phrases.\n",
        "\"\"\"\n",
        "    human_prompt = \"User wants: \" + state[\"question\"]\n",
        "    \n",
        "    # Create proper message objects\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=human_prompt)\n",
        "    ]\n",
        "    \n",
        "    # Invoke the model with the correct format\n",
        "    refined = openai_chat_model.invoke(messages).content.strip()\n",
        "\n",
        "    # save it and keep the original question around if you need it later\n",
        "    state[\"search_query\"] = refined\n",
        "    return state\n",
        "\n",
        "def search_arxiv(state):\n",
        "    query = state.get(\"search_query\", state[\"question\"])\n",
        "    result = next(arxiv.Search(query=query, max_results=1).results(), None)\n",
        "    if not result:\n",
        "        raise ValueError(f\"No results for '{query}'\")\n",
        "    state[\"arxiv_metadata\"] = {\n",
        "        \"title\": result.title,\n",
        "        \"summary\": result.summary,\n",
        "        \"authors\": [a.name for a in result.authors],\n",
        "        \"pdf_url\": result.pdf_url,\n",
        "    }\n",
        "    return state\n",
        "\n",
        "def download_pdf(state):\n",
        "    url = state[\"arxiv_metadata\"][\"pdf_url\"]\n",
        "    response = requests.get(url)\n",
        "    path = f\"/tmp/{uuid.uuid4()}.pdf\"\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    state[\"pdf_path\"] = path\n",
        "    return state\n",
        "\n",
        "def parse_pdf(state):\n",
        "    loader = PyMuPDFLoader(state[\"pdf_path\"])\n",
        "    state[\"docs\"] = loader.load()\n",
        "    return state\n",
        "\n",
        "def chunk_documents(state):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=100, length_function=tiktoken_len)\n",
        "    state[\"chunks\"] = splitter.split_documents(state[\"docs\"])\n",
        "\n",
        "    # build Qdrant and retriever here\n",
        "    vectorstore = Qdrant.from_documents(\n",
        "        documents=state[\"chunks\"],\n",
        "        embedding=embedding_model,\n",
        "        location=\":memory:\"\n",
        "    )\n",
        "    state[\"retriever\"] = vectorstore.as_retriever()\n",
        "    return state\n",
        "\n",
        "def retrieve1(state):\n",
        "    retrieved_docs = state[\"retriever\"].get_relevant_documents(state[\"question\"])\n",
        "    state[\"context\"] = retrieved_docs\n",
        "    return state\n",
        "\n",
        "HUMAN_TEMPLATE1 = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context respond with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE1)\n",
        "])\n",
        "parser = StrOutputParser()\n",
        "\n",
        "def generate1(state):\n",
        "    chain = prompt | openai_chat_model | parser\n",
        "    response = chain.invoke({\"query\": state[\"question\"], \"context\": state[\"context\"]})\n",
        "    state[\"response\"] = response\n",
        "    return state\n",
        "\n",
        "builder = StateGraph(ResearchState)\n",
        "builder.add_node(\"refine_query\", refine_query)\n",
        "builder.add_node(\"search_arxiv\", search_arxiv)\n",
        "builder.add_node(\"download_pdf\", download_pdf)\n",
        "builder.add_node(\"parse_pdf\", parse_pdf)\n",
        "builder.add_node(\"chunk_documents\", chunk_documents)\n",
        "builder.add_node(\"retrieve1\", retrieve1)\n",
        "builder.add_node(\"generate1\", generate1)\n",
        "\n",
        "# entry point is now refine_query\n",
        "builder.set_entry_point(\"refine_query\")\n",
        "\n",
        "# connect edges\n",
        "builder.add_edge(\"refine_query\", \"search_arxiv\")\n",
        "builder.add_edge(\"search_arxiv\", \"download_pdf\")\n",
        "builder.add_edge(\"download_pdf\", \"parse_pdf\")\n",
        "builder.add_edge(\"parse_pdf\", \"chunk_documents\")\n",
        "builder.add_edge(\"chunk_documents\", \"retrieve1\")\n",
        "builder.add_edge(\"retrieve1\", \"generate1\")\n",
        "builder.add_edge(\"generate1\", END)\n",
        "\n",
        "rag_graph1 = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x14476ce50>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_graph1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pg/rr8c6_fx079ctz0nd__xmlgm0000gn/T/ipykernel_45772/3158510175.py:41: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  result = next(arxiv.Search(query=query, max_results=1).results(), None)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'What does QLoRA mean?',\n",
              " 'docs': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 0}, page_content='QLORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗\\nArtidoro Pagnoni∗\\nAri Holtzman\\nLuke Zettlemoyer\\nUniversity of Washington\\n{dettmers,artidoro,ahai,lsz}@cs.washington.edu\\nAbstract\\nWe present QLORA, an efficient finetuning approach that reduces memory us-\\nage enough to finetune a 65B parameter model on a single 48GB GPU while\\npreserving full 16-bit finetuning task performance. QLORA backpropagates gradi-\\nents through a frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters (LoRA). Our best model family, which we name Guanaco, outperforms\\nall previous openly released models on the Vicuna benchmark, reaching 99.3%\\nof the performance level of ChatGPT while only requiring 24 hours of finetuning\\non a single GPU. QLORA introduces a number of innovations to save memory\\nwithout sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that\\nis information theoretically optimal for normally distributed weights (b) Double\\nQuantization to reduce the average memory footprint by quantizing the quantization\\nconstants, and (c) Paged Optimizers to manage memory spikes. We use QLORA\\nto finetune more than 1,000 models, providing a detailed analysis of instruction\\nfollowing and chatbot performance across 8 instruction datasets, multiple model\\ntypes (LLaMA, T5), and model scales that would be infeasible to run with regular\\nfinetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA\\nfinetuning on a small high-quality dataset leads to state-of-the-art results, even\\nwhen using smaller models than the previous SoTA. We provide a detailed analysis\\nof chatbot performance based on both human and GPT-4 evaluations showing that\\nGPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Fur-\\nthermore, we find that current chatbot benchmarks are not trustworthy to accurately\\nevaluate the performance levels of chatbots. A lemon-picked analysis demonstrates\\nwhere Guanaco fails compared to ChatGPT. We release all of our models and code,\\nincluding CUDA kernels for 4-bit training.2\\n1\\nIntroduction\\nFinetuning large language models (LLMs) is a highly effective way to improve their performance,\\n[40, 62, 43, 61, 59, 37] and to add desirable or remove undesirable behaviors [43, 2, 4]. However,\\nfinetuning very large models is prohibitively expensive; regular 16-bit finetuning of a LLaMA 65B\\nparameter model [57] requires more than 780 GB of GPU memory. While recent quantization\\nmethods can reduce the memory footprint of LLMs [14, 13, 18, 66], such techniques only work for\\ninference and break down during training [65].\\nWe demonstrate for the first time that it is possible to finetune a quantized 4-bit model without any\\nperformance degradation. Our method, QLORA, uses a novel high-precision technique to quantize\\na pretrained model to 4-bit, then adds a small set of learnable Low-rank Adapter weights [28]\\n∗Equal contribution.\\n2https://github.com/artidoro/qlora and https://github.com/TimDettmers/bitsandbytes\\nPreprint. Under review.\\narXiv:2305.14314v1  [cs.LG]  23 May 2023'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 1}, page_content='Table 1: Elo ratings for a competition between\\nmodels, averaged for 10,000 random initial order-\\nings. The winner of a match is determined by\\nGPT-4 which declares which response is better for\\na given prompt of the the Vicuna benchmark. 95%\\nconfidence intervals are shown (±). After GPT-\\n4, Guanaco 33B and 65B win the most matches,\\nwhile Guanaco 13B scores better than Bard.\\nModel\\nSize\\nElo\\nGPT-4\\n-\\n1348 ± 1\\nGuanaco 65B\\n41 GB\\n1022 ± 1\\nGuanaco 33B\\n21 GB\\n992 ± 1\\nVicuna 13B\\n26 GB\\n974 ± 1\\nChatGPT\\n-\\n966 ± 1\\nGuanaco 13B\\n10 GB\\n916 ± 1\\nBard\\n-\\n902 ± 1\\nGuanaco 7B\\n6 GB\\n879 ± 1\\nthat are tuned by backpropagating gradients through\\nthe quantized weights.\\nQLORA reduces the average memory requirements\\nof finetuning a 65B parameter model from >780GB\\nof GPU memory to <48GB without degrading the\\nruntime or predictive performance compared to a 16-\\nbit fully finetuned baseline. This marks a significant\\nshift in accessibility of LLM finetuning: now the\\nlargest publicly available models to date finetunable\\non a single GPU. Using QLORA, we train the Gua-\\nnaco family of models, with the second best model\\nreaching 97.8% of the performance level of ChatGPT\\non the Vicuna [10] benchmark, while being trainable\\nin less than 12 hours on a single consumer GPU;\\nusing a single professional GPU over 24 hours we\\nachieve 99.3% with our largest model, essentially\\nclosing the gap to ChatGPT on the Vicuna bench-\\nmark. When deployed, our smallest Guanaco model\\n(7B parameters) requires just 5 GB of memory and outperforms a 26 GB Alpaca model by more than\\n20 percentage points on the Vicuna benchmark (Table 6).\\nQLORA introduces multiple innovations designed to reduce memory use without sacrificing per-\\nformance: (1) 4-bit NormalFloat, an information theoretically optimal quantization data type for\\nnormally distributed data that yields better empirical results than 4-bit Integers and 4-bit Floats.\\n(2) Double Quantization, a method that quantizes the quantization constants, saving an average\\nof about 0.37 bits per parameter (approximately 3 GB for a 65B model). (3) Paged Optimizers,\\nusing NVIDIA unified memory to avoid the gradient checkpointing memory spikes that occur when\\nprocessing a mini-batch with a long sequence length. We combine these contributions into a better\\ntuned LoRA approach that includes adapters at every network layer and thereby avoids almost all of\\nthe accuracy tradeoffs seen in prior work.\\nQLORA’s efficiency enables us to perform an in-depth study of instruction finetuning and chatbot\\nperformance on model scales that would be impossible using regular finetuning due to memory\\noverhead. Therefore, we train more than 1,000 models across several instruction tuning datasets,\\nmodel architectures, and sizes between 80M to 65B parameters. In addition to showing that QLORA\\nrecovers 16-bit performance (§4) and training a state-of-the-art chatbot, Guanaco, (§5), we also\\nanalyze trends in the trained models. First, we find that data quality is far more important than\\ndataset size, e.g., a 9k sample dataset (OASST1) outperformed a 450k sample dataset (FLAN v2,\\nsubsampled) on chatbot performance, even when both are meant to support instruction following\\ngeneralization. Second, we show that strong Massive Multitask Language Understanding (MMLU)\\nbenchmark performance does not imply strong Vicuna chatbot benchmark performance and vice\\nversa—in other words, dataset suitability matters more than size for a given task.\\nFurthermore, we also provide a extensive analysis of chatbot performance that uses both human\\nraters and GPT-4 for evaluation. We use tournament-style benchmarking where models compete\\nagainst each other in matches to produce the best response for a given prompt. The winner of a\\nmatch is judged by either GPT-4 or human annotators. The tournament results are aggregated into\\nElo scores [16, 17] which determine the ranking of chatbot performance. We find that GPT-4 and\\nhuman evaluations largely agree on the rank of model performance in the tournaments, but we also\\nfind there are instances of strong disagreement. As such, we highlight that model-based evaluation\\nwhile providing a cheap alternative to human-annotation also has its uncertainties.\\nWe augment our chatbot benchmark results with a qualitative analysis of Guanaco models. Our analy-\\nsis highlights success and failure cases that were not captured by the quantitative benchmarks.\\nWe release all model generations with human and GPT-4 annotations to facilitate further study. We\\nopen-source our codebase and CUDA kernels and integrate our methods into the Hugging Face\\ntransformers stack [64], making them easily accessible to all. We release a collection of adapters\\nfor 7/13/33/65B size models, trained on 8 different instruction following datasets, for a total of 32\\ndifferent open sourced, finetuned models.\\n2'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 2}, page_content='Figure 1: Different finetuning methods and their memory requirements. QLORA improves over LoRA by\\nquantizing the transformer model to 4-bit precision and using paged optimizers to handle memory spikes.\\n2\\nBackground\\nBlock-wise k-bit Quantization\\nQuantization is the process of discretizing an input from a rep-\\nresentation that holds more information to a representation with less information. It often means\\ntaking a data type with more bits and converting it to fewer bits, for example from 32-bit floats to\\n8-bit Integers. To ensure that the entire range of the low-bit data type is used, the input data type is\\ncommonly rescaled into the target data type range through normalization by the absolute maximum\\nof the input elements, which are usually structured as a tensor. For example, quantizing a 32-bit\\nFloating Point (FP32) tensor into a Int8 tensor with range [−127, 127]:\\nXInt8 = round\\n\\x12\\n127\\nabsmax(XFP32)XFP32\\n\\x13\\n= round(cFP32 · XFP32),\\n(1)\\nwhere c is the quantization constant or quantization scale. Dequantization is the inverse:\\ndequant(cFP32, XInt8) = XInt8\\ncFP32 = XFP32\\n(2)\\nThe problem with this approach is that if a large magnitude value (i.e., an outlier) occurs in the input\\ntensor, then the quantization bins—certain bit combinations—are not utilized well with few or no\\nnumbers quantized in some bins. To prevent the outlier issue, a common approach is to chunk the\\ninput tensor into blocks that are independently quantized, each with their own quantization constant c.\\nThis can be formalized as follows: We chunk the input tensor X ∈Rb×h into n contiguous blocks of\\nsize B by flattening the input tensor and slicing the linear segment into n = (b × h)/B blocks. We\\nquantize these blocks independently with Equation 1 to create a quantized tensor and n quantization\\nconstants ci.\\nLow-rank Adapters\\nLow-rank Adapter (LoRA) finetuning [28] is a method that reduces memory\\nrequirements by using a small set of trainable parameters, often termed adapters, while not updating\\nthe full model parameters which remain fixed. Gradients during stochastic gradient descent are\\npassed through the fixed pretrained model weights to the adapter, which is updated to optimize the\\nloss function. LoRA augments a linear projection through an additional factorized projection. Given\\na projection XW = Y with X ∈Rb×h, W ∈Rh×o LoRA computes:\\nY = XW + sXL1L2,\\n(3)\\nwhere L1 ∈Rh×r and L2 ∈Rr×o, and s is a scalar.\\nMemory Requirement of Parameter-Efficient Finetuning\\nOne important point of discussion is\\nthe memory requirement of LoRA during training both in terms of the number and size of adapters\\nused. Since the memory footprint of LoRA is so minimal, we can use more adapters to improve\\nperformance without significantly increasing the total memory used. While LoRA was designed as a\\n3'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 3}, page_content='Parameter Efficient Finetuning (PEFT) method, most of the memory footprint for LLM finetuning\\ncomes from activation gradients and not from the learned LoRA parameters. For a 7B LLaMA\\nmodel trained on FLAN v2 with a batch size of 1, with LoRA weights equivalent to commonly used\\n0.2% of the original model weights[28, 37], the LoRA input gradients have a memory footprint\\nof 567 MB while the LoRA parameters take up only 26 MB. With gradient checkpointing [9], the\\ninput gradients reduce to an average of 18 MB per sequence making them more memory intensive\\nthan all LoRA weights combined. In comparison, the 4-bit base model consumes 5,048 MB of\\nmemory. This highlights that gradient checkpointing is important but also that aggressively reducing\\nthe amount of LoRA parameter yields only minor memory benefits. This means we can use more\\nadapters without significantly increasing the overall training memory footprint (see Appendix G\\nfor a detailed breakdown). As discussed later, this is crucial for recovering full 16-bit precision\\nperformance.\\n3\\nQLORA Finetuning\\nQLORA achieves high-fidelity 4-bit finetuning via two techniques we propose—4-bit NormalFloat\\n(NF4) quantization and Double Quantization. Additionally, we introduce Paged Optimizers, to\\nprevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORA has one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORA weight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QLORA followed by a formal definition of QLORA.\\n4-bit NormalFloat Quantization\\nThe NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.\\nThe main limitation of quantile quantization is that the process of quantile estimation is expensive.\\nTherefore fast quantile approximation algorithms, such as SRAM quantiles [15], are used to estimate\\nthem. Due to the approximate nature of these quantile estimation algorithms, the data type has large\\nquantization errors for outliers, which are often the most important values.\\nExpensive quantile estimates and approximation errors can be avoided when input tensors come from\\na distribution fixed up to a quantization constant. In such cases, input tensors have the same quantiles\\nmaking exact quantile estimation computationally feasible.\\nSince pretrained neural network weights usually have a zero-centered normal distribution with\\nstandard deviation σ (see Appendix F), we can transform all weights to a single fixed distribution by\\nscaling σ such that the distribution fits exactly into the range of our data type. For our data type, we\\nset the arbitrary range [−1, 1]. As such, both the quantiles for the data type and the neural network\\nweights need to be normalized into this range.\\nThe information theoretically optimal data type for zero-mean normal distributions with arbitrary\\nstandard deviations σ in the range [−1, 1] is computed as follows: (1) estimate the 2k + 1 quantiles\\nof a theoretical N(0, 1) distribution to obtain a k-bit quantile quantization data type for normal distri-\\nbutions, (2) take this data type and normalize its values into the [−1, 1] range, (3) quantize an input\\nweight tensor by normalizing it into the [−1, 1] range through absolute maximum rescaling.\\nOnce the weight range and data type range match, we can quantize as usual. Step (3) is equivalent to\\nrescaling the standard deviation of the weight tensor to match the standard deviation of the k-bit data\\ntype. More formally, we estimate the 2k values qi of the data type as follows:\\nqi = 1\\n2\\n\\x12\\nQX\\n\\x12\\ni\\n2k + 1\\n\\x13\\n+ QX\\n\\x12 i + 1\\n2k + 1\\n\\x13\\x13\\n,\\n(4)\\nwhere QX(·) is the quantile function of the standard normal distribution N(0, 1). A problem for\\na symmetric k-bit quantization is that this approach does not have an exact representation of zero,\\nwhich is an important property to quantize padding and other zero-valued elements with no error. To\\n4'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 4}, page_content='ensure a discrete zeropoint of 0 and to use all 2k bits for a k-bit datatype, we create an asymmetric\\ndata type by estimating the quantiles qi of two ranges qi: 2k−1 for the negative part and 2k−1 + 1 for\\nthe positive part and then we unify these sets of qi and remove one of the two zeros that occurs in both\\nsets. We term the resulting data type that has equal expected number of values in each quantization bin\\nk-bit NormalFloat (NFk), since the data type is information-theoretically optimal for zero-centered\\nnormally distributed data. The exact values of this data type can be found in Appendix E.\\nDouble Quantization\\nWe introduce Double Quantization (DQ), the process of quantizing the\\nquantization constants for additional memory savings. While a small blocksize is required for precise\\n4-bit quantization [13], it also has a considerable memory overhead. For example, using 32-bit\\nconstants and a blocksize of 64 for W, quantization constants add 32/64 = 0.5 bits per parameter on\\naverage. Double Quantization helps reduce the memory footprint of quantization constants.\\nMore specifically, Double Quantization treats quantization constants cFP32\\n2\\nof the first quantization\\nas inputs to a second quantization. This second step yields the quantized quantization constants\\ncFP8\\n2\\nand the second level of quantization constants cFP32\\n1\\n. We use 8-bit Floats with a blocksize of\\n256 for the second quantization as no performance degradation is observed for 8-bit quantization,\\nin line with results from Dettmers and Zettlemoyer [13]. Since the cFP32\\n2\\nare positive, we subtract\\nthe mean from c2 before quantization to center the values around zero and make use of symmetric\\nquantization. On average, for a blocksize of 64, this quantization reduces the memory footprint per\\nparameter from 32/64 = 0.5 bits, to 8/64 + 32/(64 · 256) = 0.127 bits, a reduction of 0.373 bits\\nper parameter.\\nPaged Optimizers\\nuse the NVIDIA unified memory 3 feature wich does automatic page-to-page\\ntransfers between the CPU and GPU for error-free GPU processing in the scenario where the GPU\\noccasionally runs out-of-memory. The feature works like regular memory paging between CPU RAM\\nand the disk. We use this feature to allocate paged memory for the optimizer states which are then\\nautomatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\\nmemory when the memory is needed in the optimizer update step.\\nQLORA.\\nUsing the components described above, we define QLORA for a single linear layer in\\nthe quantized base model with a single LoRA adapter as follows:\\nYBF16 = XBF16doubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, WNF4) + XBF16LBF16\\n1\\nLBF16\\n2\\n,\\n(5)\\nwhere doubleDequant(·) is defined as:\\ndoubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, Wk-bit) = dequant(dequant(cFP32\\n1\\n, ck-bit\\n2\\n), W4bit) = WBF16,\\n(6)\\nWe use NF4 for W and FP8 for c2. We use a blocksize of 64 for W for higher quantization precision\\nand a blocksize of 256 for c2 to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights ∂E\\n∂Li are\\nneeded, and not for 4-bit weights ∂E\\n∂W. However, the calculation of ∂E\\n∂Li entails the calculation of ∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4 to computation data type\\nWBF16 to calculate the derivative ∂X\\n∂W in BFloat16 precision.\\nTo summarize, QLORA has one storage data type (usually 4-bit NormalFloat) and a computation\\ndata type (16-bit BrainFloat). We dequantize the storage data type to the computation data type\\nto perform the forward and backward pass, but we only compute weight gradients for the LoRA\\nparameters which use 16-bit BrainFloat.\\n4\\nQLoRA vs. Standard Finetuning\\nWe have discussed how QLoRA works and how it can significantly reduce the required memory for\\nfinetuning models. The main question now is whether QLoRA can perform as well as full-model\\nfinetuning. Furthermore, we want to analyze the components of QLoRA including the impact of\\nNormalFloat4 over standard Float4. The following sections will discuss the experiments that aimed\\nat answering these questions.\\n3https://docs.nvidia.com/cuda/cuda-c-programming-guide\\n5'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 5}, page_content='Experimental setup.\\nWe consider three architectures (encoder, encoder-decoder, and decoder only)\\nand compare QLoRA with 16-bit adapter-finetuning and with full-finetuning for models up to 3B. Our\\nevaluations include GLUE [58] with RoBERTa-large [38], Super-NaturalInstructions (TKInstruct)\\n[61] with T5 [49], and 5-shot MMLU [24] after finetuning LLaMA on Flan v2 [39] and Alpaca\\n[55]. To additionally study the advantages of NF4 over other 4-bit data types, we use the setup of\\nDettmers and Zettlemoyer [13] and measure post-quantization zero-shot accuracy and perplexity\\nacross different models (OPT [72], LLaMA [57], BLOOM [52], Pythia [7]) for model sizes 125m -\\n13B. We provide more details in the results section for each particular setup to make the results more\\nreadable. Full details in Appendix A.\\nQLoRA-All\\nQLoRA-FFN\\nQLoRA-Attention\\nAlpaca (ours)\\nStanford-Alpaca\\nModel\\n60\\n61\\n62\\n63\\n64\\nRougeL\\nbits\\n4\\n16\\nFigure 2: RougeL for LLaMA 7B models on the\\nAlpaca dataset. Each point represents a run with a\\ndifferent random seed. We improve on the Stanford\\nAlpaca fully finetuned default hyperparameters to\\nconstruct a strong 16-bit baseline for comparisons.\\nUsing LoRA on all transformer layers is critical to\\nmatch 16-bit performance.\\nWhile paged optimizers are critical to do 33B/65B\\nQLORA tuning on a single 24/48GB GPU, we do\\nnot provide hard measurements for Paged Optimiz-\\ners since the paging only occurs when processing\\nmini-batches with long sequence lengths, which is\\nrare. We do, however, perform an analysis of the\\nruntime of paged optimizers for 65B models on\\n48GB GPUs and find that with a batch size of 16,\\npaged optimizers provide the same training speed\\nas regular optimizers. Future work should measure\\nand characterize under what circumstances slow-\\ndowns occur from the paging process.\\nDefault LoRA hyperparameters do not match 16-\\nbit performance\\nWhen using the standard prac-\\ntice of applying LoRA to query and value attention\\nprojection matrices [28], we are not able to replicate\\nfull finetuning performance for large base models.\\nAs shown in Figure 2 for LLaMA 7B finetuning on\\nAlpaca, we find that the most critical LoRA hyper-\\nparameter is how many LoRA adapters are used in\\ntotal and that LoRA on all linear transformer block\\nlayers are required to match full finetuning perfor-\\nmance. Other LoRA hyperparameters, such as the\\nprojection dimension r, do not affect performance (see Appendix A).\\n1010\\n1011\\nTotal model bits\\n0.60\\n0.61\\n0.62\\n0.63\\n0.64\\n0.65\\n0.66\\n0.67\\nMean zeroshot accuracy\\n4-bit LLaMA\\nFloat\\nNFloat\\nNFloat + DQ\\nData type\\nFigure 3: Mean zero-shot accuracy over Wino-\\ngrande, HellaSwag, PiQA, Arc-Easy, and Arc-\\nChallenge using LLaMA models with different 4-bit\\ndata types. The NormalFloat data type significantly\\nimproves the bit-for-bit accuracy gains compared\\nto regular 4-bit Floats. While Double Quantization\\n(DQ) only leads to minor gains, it allows for a more\\nfine-grained control over the memory footprint to fit\\nmodels of certain size (33B/65B) into certain GPUs\\n(24/48GB).\\nSimilarly, we find that default hyperparameters for\\nfully finetuned baselines are undertuned. We do a\\nhyperparameter search over learning rates 1e-6 to\\n5e-5 and batch sizes 8 to 128 to find robust baselines.\\nResults for 7B LLaMA finetuning on Alpaca are\\nshown in Figure 2.\\n4-bit NormalFloat yields better performance\\nthan 4-bit Floating Point\\nWhile the 4-bit\\nNormalFloat (NF4) data type is information-\\ntheoretically optimal, it still needs to be determined\\nif this property translates to empirical advantages.\\nWe follow the setup from Dettmers and Zettlemoyer\\n[13] where quantized LLMs (OPT [72], BLOOM\\n[52], Pythia [7], LLaMA) of different sizes (125M\\nto 65B) with different data types are evaluated on\\nlanguage modeling and a set of zero-shot tasks. In\\nFigure 3 and Table 2 we see that NF4 improves per-\\nformance significantly over FP4 and Int4 and that\\ndouble quantization reduces the memory footprint\\nwithout degrading performance.\\nk-bit QLORA matches 16-bit full finetuning and\\n16-bit LoRA performance\\nRecent findings have\\nestablished that 4-bit quantization for inference is\\n6'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 6}, page_content='Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\\nbit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORA replicates 16-bit LoRA and full-\\nfinetuning.\\nDataset\\nGLUE (Acc.)\\nSuper-NaturalInstructions (RougeL)\\nModel\\nRoBERTa-large\\nT5-80M\\nT5-250M\\nT5-780M\\nT5-3B\\nT5-11B\\nBF16\\n88.6\\n40.1\\n42.1\\n48.0\\n54.3\\n62.0\\nBF16 replication\\n88.6\\n40.0\\n42.2\\n47.3\\n54.9\\n-\\nLoRA BF16\\n88.8\\n40.5\\n42.6\\n47.1\\n55.4\\n60.7\\nQLORA Int8\\n88.8\\n40.4\\n42.9\\n45.4\\n56.5\\n60.7\\nQLORA FP4\\n88.6\\n40.3\\n42.4\\n47.5\\n55.6\\n60.9\\nQLORA NF4 + DQ\\n-\\n40.4\\n42.7\\n47.7\\n55.3\\n60.9\\npossible, but leads to performance degradation rel-\\native to 16-bit [13, 18]. This raises the crucial question of whether the lost performance can be\\nrecovered by conducting 4-bit adapter finetuning. We test this for two setups.\\nTable 2: Pile Common Crawl mean\\nperplexity for different data types\\nfor 125M to 13B OPT, BLOOM,\\nLLaMA, and Pythia models.\\nData type\\nMean PPL\\nInt4\\n34.34\\nFloat4 (E2M1)\\n31.07\\nFloat4 (E3M0)\\n29.48\\nNFloat4 + DQ\\n27.41\\nThe first focuses on a comparison with full 16-bit finetuning\\nof RoBERTA and T5 models sized 125M to 3B parameters on\\nGLUE and the Super-NaturalInstructions dataset. Results are\\nshown in Table 3. In both datasets, we observe that 16-bit, 8-bit,\\nand 4-bit adapter methods replicate the performance of the fully\\nfinetuned 16-bit baseline. This suggests that the performance lost\\ndue to the imprecise quantization can be fully recovered through\\nadapter finetuning after quantization.\\nFor our second setup, since full finetuning models at and beyond\\n11B parameters requires more than one server of high memory\\nGPUs, we continue to test whether 4-bit QLORA can match\\n16-bit LoRA at the 7B to 65B parameter scales. To this end, we\\nfinetune LLaMA 7B through 65B on two instruction following\\ndatasets, Alpaca and FLAN v2, and evaluate on the MMLU benchmark via 5-shot accuracy. Results\\nare shown in Table 4 where we see that NF4 with double quantization fully recovers the 16-bit\\nLoRA MMLU performance. In addition, we also note that QLORA with FP4 lags behind the 16-bit\\nbrain float LoRA baseline by about 1 percentage point. This corroborates both our findings that (1)\\nQLORA with NF4 replicates both 16-bit full finetuning and 16-bit LoRA finetuning performance,\\nand (2) NF4 is superior to FP4 in terms of quantization precision.\\nSummary\\nOur results consistently show that 4-bit QLORA with NF4 data type matches 16-\\nbit full finetuning and 16-bit LoRA finetuning performance on academic benchmarks with well-\\nestablished evaluation setups. We have also shown that NF4 is more effective than FP4 and that\\ndouble quantization does not degrade performance. Combined, this forms compelling evidence that\\n4-bit QLORA tuning reliably yields results matching 16-bit methods.\\nIn line with previous work on quantization [13], our MMLU and Elo results indicate that with a given\\nfinetuning and inference resource budget it is beneficial to increase the number of parameters in the\\nbase model while decreasing their precision. This highlights the importance of efficiency benefits\\nfrom QLORA. Since we did not observe performance degradation compared to full-finetuning in\\nour experiments with 4-bit finetuning, this raises the question of where the performance-precision\\ntrade-off exactly lies for QLoRA tuning, which we leave to future work to explore.\\nWe proceed to investigate instruction tuning at scales that would be impossible to explore with full\\n16-bit finetuning on academic research hardware.\\n5\\nPushing the Chatbot State-of-the-art with QLoRA\\nHaving established that 4-bit QLORA matches 16-bit performance across scales, tasks, and datasets\\nwe conduct an in-depth study of instruction finetuning up to the largest open-source language models\\navailable for research. To assess the performance of instruction finetuning these models, we evaluate\\n7'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 7}, page_content='Table 4: Mean 5-shot MMLU test accuracy for LLaMA 7-65B models finetuned with adapters on Alpaca and\\nFLAN v2 for different data types. Overall, NF4 with double quantization (DQ) matches BFloat16 performance,\\nwhile FP4 is consistently one percentage point behind both.\\nMean 5-shot MMLU Accuracy\\nLLaMA Size\\n7B\\n13B\\n33B\\n65B\\nMean\\nDataset\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nBFloat16\\n38.4\\n45.6\\n47.2\\n50.6\\n57.7\\n60.5\\n61.8\\n62.5\\n53.0\\nFloat4\\n37.2\\n44.0\\n47.3\\n50.0\\n55.9\\n58.5\\n61.3\\n63.3\\n52.2\\nNFloat4 + DQ\\n39.0\\n44.5\\n47.5\\n50.7\\n57.3\\n59.2\\n61.8\\n63.9\\n53.1\\non a challenging Natural Language Understanding benchmark (MMLU) and develop new methods\\nfor real-world chatbot performance evaluation.\\n5.1\\nExperimental setup\\nWe now describe an overview of the experimental setup with full details in Appendix B.\\nData\\nAs, to our knowledge, there is no comprehensive study of recent instruction-following datasets,\\nwe select eight recent datasets. We include datasets obtained through crowd-sourcing (OASST1 [31],\\nHH-RLHF [4]), distillation from instruction-tuned models (Alpaca [55], self-instruct [59], unnatural-\\ninstructions [26]), corpora aggregations (FLAN v2 [12]), as well as hybrids (Chip2 [32], Long-\\nform [30]). These datasets cover different languages, data sizes, and licenses.\\nTraining Setup\\nTo avoid confounding effects from different training objectives, we perform QLoRA\\nfinetuning with cross-entropy loss (supervised learning) without reinforcement learning, even for\\ndatasets that include human judgments of different responses. For datasets that have a clear distinction\\nbetween instruction and response, we finetune only on the response (see ablations in Appendix B).\\nFor OASST1 and HH-RLHF, multiple responses are available. We then select the top response at\\nevery level of the conversation tree and finetune on the full selected conversation, including the\\ninstructions. In all of our experiments, we use NF4 QLORA with double quantization and paged\\noptimizers to prevent memory spikes during gradient checkpointing. We do small hyperparameter\\nsearches for the 13B and 33B LLaMA models and we find that all hyperparameter settings found\\nat 7B generalize (including number of epochs) except learning rate and batch size. We halve the\\nlearning rate for 33B and 65B while doubling the batch size.\\nBaselines\\nWe compare our models to both research (Vicuna [10] and Open Assistant [31]) and\\ncommercial (GPT-4 [42], GPT-3.5-turbo and Bard) chatbot systems. The Open Assistant model is\\na LLaMA 33B model finetuned with Reinforcement Learning from Human Feedback (RLHF) on\\nthe same OASST1 dataset that we experiment with. Vicuna does full fine-tuning of LLaMA 13B\\non proprietary user-shared conversations from ShareGPT and is thus the result of distillation from\\nOpenAI GPT models.\\n5.2\\nEvaluation\\nTable 5: MMLU 5-shot test results for different\\nsizes of LLaMA finetuned on the corresponding\\ndatasets using QLoRA.\\nDataset\\n7B\\n13B\\n33B\\n65B\\nLLaMA no tuning\\n35.1\\n46.9\\n57.8\\n63.4\\nSelf-Instruct\\n36.4\\n33.3\\n53.0\\n56.7\\nLongform\\n32.1\\n43.2\\n56.6\\n59.7\\nChip2\\n34.5\\n41.6\\n53.6\\n59.8\\nHH-RLHF\\n34.9\\n44.6\\n55.8\\n60.1\\nUnnatural Instruct\\n41.9\\n48.1\\n57.3\\n61.3\\nGuanaco (OASST1)\\n36.6\\n46.4\\n57.0\\n62.2\\nAlpaca\\n38.8\\n47.8\\n57.3\\n62.5\\nFLAN v2\\n44.5\\n51.4\\n59.2\\n63.9\\nFollowing common practice, we use the MMLU (Mas-\\nsively Multitask Language Understanding) benchmark\\n[24] to measure performance on a range of language un-\\nderstanding tasks. This is a multiple-choice benchmark\\ncovering 57 tasks including elementary mathematics,\\nUS history, computer science, law, and more. We report\\n5-shot test accuracy.\\nWe also test generative language capabilities through\\nboth automated and human evaluations. This second\\nset of evaluations relies on queries curated by humans\\nand aims at measuring the quality of model responses.\\nWhile this is a more realistic testbed for chatbot model\\nperformance and is growing in popularity, there is no\\ncommonly accepted protocol in the literature. We de-\\nscribe below our proposed setup, using nucleus sampling with p = 0.9 and temperature 0.7 in all\\ncases.\\n8'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 8}, page_content='Benchmark Data\\nWe evaluate on two curated datasets of queries (questions): the Vicuna prompts\\n[10] and the OASST1 validation dataset [31]. We use the Vicuna prompts, a set of 80 prompts from a\\ndiverse set of categories, without modifications. The OASST1 dataset is a multilingual collection of\\ncrowd-sourced multiturn dialogs between a user and an assistant. We select all user messages in the\\nvalidation dataset as queries and include previous turns in the prompt. This procedure leads to 953\\nunique user queries. We term these two datasets the Vicuna and OA benchmarks.\\nAutomated Evaluation\\nFirst, based on the evaluation protocol introduced by Chiang et al. [10],\\nwe use GPT-4 to rate the performance of different systems against ChatGPT (GPT-3.5 Turbo) on the\\nVicuna benchmark. Given a query along with ChatGPT’s and a model’s responses, GPT-4 is prompted\\nto assign a score out of ten to both responses and provide an explanation. The overall performance of\\na model is calculated as a percentage of the score that ChatGPT achieved. Note this relative score\\ncan be higher than 100% if the model achieves a higher absolute score than ChatGPT. We find a\\nsignificant ordering effect with GPT-4 increasing the score of the response occurring earlier in the\\nprompt. To control for such effects, we recommend reporting the mean score over both orders.\\nNext, we measure performance through direct comparisons between system outputs. We simplify\\nthe rating scheme to a three-class labeling problem that accounts for ties. We prompt GPT-4 to\\npick the best response or declare a tie and provide an explanation. We conduct these head-to-head\\ncomparisons on all permutations of pairs of systems on both the Vicuna and OA benchmarks.\\nHuman Evaluation\\nWhile recent work indicates generative models can be effectively employed\\nfor system evaluations [19], the reliability GPT-4 ratings to assess chatbot performance is, to our\\nknowledge, yet to be proven to correlate with human judgments. Therefore, we run two parallel\\nhuman evaluations on the Vicuna benchmark matching both automated evaluation protocols described\\nabove. We use Amazon Mechanical Turk (AMT) and get two human annotators for comparisons to\\nChatGPT and three annotators for pairwise comparisons.\\nElo Rating\\nWith both human and automated pairwise comparisons, we create a tournament-style\\ncompetition where models compete against each other. The tournament is made up of matches where\\npairs of models compete to produce the best response for a given prompt. This is similar to how Bai\\net al. [4] and Chiang et al. [10] compare models, but we also employ GPT-4 ratings in addition to\\nhuman ratings. We randomly sample from the set of labeled comparisons to compute Elo [16, 17].\\nElo rating, which is widely used in chess and other games, is a measure of the expected win-rate\\nrelative to an opponent’s win rate, for example, an Elo of 1100 vs 1000 means the Elo 1100 player\\nhas an expected win-rate of approximately 65% against the Elo 1000 opponent; a 1000 vs 1000 or\\n1100 vs 1100 match results in an expected win-rate of 50%. The Elo rating changes after each match\\nproportionally to the expected outcome, that is, an unexpected upset leads to a large change in Elo\\nrating while an expected outcome leads to a small change. Over time, Elo ratings approximately\\nmatch the skill of each player at playing the game. We start with a score of 1,000 and use K = 32.\\nSimilar to Chiang et al. [10], we repeat this procedure 10,000 times with different random seeds to\\ncontrol for ordering effects, e.g., the effect of which model pairs compete with each other first.\\n5.3\\nGuanaco: QLORA trained on OASST1 is a State-of-the-art Chatbot\\nBased on our automated and human evaluations, we find that the top QLORA tuned model, Guanaco\\n65B, which we finetune on a variant of OASST1, is the best-performing open-source chatbot model\\nand offers performance competitive to ChatGPT. When compared to GPT-4, Guanaco 65B and 33B\\nhave an expected win probability of 30%, based on Elo rating from human annotators system-level\\npairwise comparisons - the highest reported to date.\\nThe Vicuna benchmark [10] results relative to ChatGPT are shown in Table 6. We find that Guanaco\\n65B is the best-performing model after GPT-4, achieving 99.3% performance relative to ChatGPT.\\nGuanaco 33B has more parameters than the Vicuna 13B model, but uses only 4-bit precision for its\\nweights and is thus much more memory efficient at 21 GB vs 26 GB, providing a three percentage\\npoints of improvement over Vicuna 13B. Furthermore, Guanaco 7B easily fits on modern phones at a\\n5 GB footprint while still scoring nearly 20 percentage points higher than Alpaca 13B.\\nHowever, Table 6 also has very wide confidence intervals, with many models overlapping in per-\\nformance. We hypothesize that this uncertainty comes from the lack of clear specification of scale,\\ne.g., it is unclear what 8 on a 10 point scale means across different scenarios. As such, we instead\\nrecommend using the Elo ranking method [16], based on pairwise judgments from human annotators\\nand GPT-4 to avoid the problem of grounding an absolute scale. Elo ratings of the most competitive\\n9'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 9}, page_content='Table 6: Zero-shot Vicuna benchmark scores as a percentage of the score obtained by ChatGPT evaluated by\\nGPT-4. We see that OASST1 models perform close to ChatGPT despite being trained on a very small dataset\\nand having a fraction of the memory requirement of baseline models.\\nModel / Dataset\\nParams\\nModel bits\\nMemory\\nChatGPT vs Sys\\nSys vs ChatGPT\\nMean\\n95% CI\\nGPT-4\\n-\\n-\\n-\\n119.4%\\n110.1%\\n114.5%\\n2.6%\\nBard\\n-\\n-\\n-\\n93.2%\\n96.4%\\n94.8%\\n4.1%\\nGuanaco\\n65B\\n4-bit\\n41 GB\\n96.7%\\n101.9%\\n99.3%\\n4.4%\\nAlpaca\\n65B\\n4-bit\\n41 GB\\n63.0%\\n77.9%\\n70.7%\\n4.3%\\nFLAN v2\\n65B\\n4-bit\\n41 GB\\n37.0%\\n59.6%\\n48.4%\\n4.6%\\nGuanaco\\n33B\\n4-bit\\n21 GB\\n96.5%\\n99.2%\\n97.8%\\n4.4%\\nOpen Assistant\\n33B\\n16-bit\\n66 GB\\n91.2%\\n98.7%\\n94.9%\\n4.5%\\nAlpaca\\n33B\\n4-bit\\n21 GB\\n67.2%\\n79.7%\\n73.6%\\n4.2%\\nFLAN v2\\n33B\\n4-bit\\n21 GB\\n26.3%\\n49.7%\\n38.0%\\n3.9%\\nVicuna\\n13B\\n16-bit\\n26 GB\\n91.2%\\n98.7%\\n94.9%\\n4.5%\\nGuanaco\\n13B\\n4-bit\\n10 GB\\n87.3%\\n93.4%\\n90.4%\\n5.2%\\nAlpaca\\n13B\\n4-bit\\n10 GB\\n63.8%\\n76.7%\\n69.4%\\n4.2%\\nHH-RLHF\\n13B\\n4-bit\\n10 GB\\n55.5%\\n69.1%\\n62.5%\\n4.7%\\nUnnatural Instr.\\n13B\\n4-bit\\n10 GB\\n50.6%\\n69.8%\\n60.5%\\n4.2%\\nChip2\\n13B\\n4-bit\\n10 GB\\n49.2%\\n69.3%\\n59.5%\\n4.7%\\nLongform\\n13B\\n4-bit\\n10 GB\\n44.9%\\n62.0%\\n53.6%\\n5.2%\\nSelf-Instruct\\n13B\\n4-bit\\n10 GB\\n38.0%\\n60.5%\\n49.1%\\n4.6%\\nFLAN v2\\n13B\\n4-bit\\n10 GB\\n32.4%\\n61.2%\\n47.0%\\n3.6%\\nGuanaco\\n7B\\n4-bit\\n5 GB\\n84.1%\\n89.8%\\n87.0%\\n5.4%\\nAlpaca\\n7B\\n4-bit\\n5 GB\\n57.3%\\n71.2%\\n64.4%\\n5.0%\\nFLAN v2\\n7B\\n4-bit\\n5 GB\\n33.3%\\n56.1%\\n44.8%\\n4.0%\\nmodels can be seen in Table 1. We note that human and GPT-4 ranking of models on the Vicuna\\nbenchmark disagree partially, particularly for Guanaco 7B, but are consistent for most models with\\na Kendall Tau of τ = 0.43 and Spearman rank correlation of r = 0.55 at the system level. At the\\nexample level, the agreement between GPT-4 and human annotators’ majority vote is weaker with\\nFleiss κ = 0.25. Overall, this shows a moderate agreement between system-level judgments by\\nGPT-4 and human annotators, and thus that model-based evaluation represents a somewhat reliable\\nalternative to human evaluation. We discuss further considerations in Section 6.2.\\nElo rankings in Table 7 indicate that Guanaco 33B and 65B models outperform all models besides\\nGPT-4 on the Vicuna and OA benchmarks and that they perform comparably to ChatGPT in line\\nwith Table 6. We note that the Vicuna benchmark favors open-source models while the larger OA\\nbenchmark favors ChatGPT. Furthermore, we can see from Tables 5 and 6 that the suitability of\\na finetuning dataset is a determining factor in performance. Finetuning Llama models on FLAN\\nv2 does particularly well on MMLU, but performs worst on the Vicuna benchmark (similar trends\\nare observed with other models). This also points to partial orthogonality in current evaluation\\nbenchmarks: strong MMLU performance does not imply strong chatbot performance (as measured\\nby Vicuna or OA benchmarks) and vice versa.\\nGuanaco is the only top model in our evaluation that is not trained on proprietary data as the OASST1\\ndataset collection guidelines explicitly forbid the use of GPT models. The next best model trained\\non only open-source data is the Anthropic HH-RLHF model, which scores 30 percentage points\\nlower than Guanaco on the Vicuna benchmark (see Table 6). Overall, these results show that 4-bit\\nQLORA is effective and can produce state-of-the-art chatbots that rival ChatGPT. Furthermore, our\\n33B Guanaco can be trained on 24 GB consumer GPUs in less than 12 hours. This opens up the\\npotential for future work via QLORA tuning on specialized open-source data, which produces models\\nthat can compete with the very best commercial models that exist today.\\n6\\nQualitative Analysis\\nWhile quantitative analysis is the core of our evaluation, there are a number of issues with only\\nlooking at summary statistics. Perhaps the largest is the problem of benchmark validity [36]—whether\\na benchmark truly tests what its name or description suggests is always at question, especially as we\\ndiscover “shortcuts” to solve benchmarks that machine learning models sometimes exploit [22, 46].\\nTo partially alleviate this, we here perform some qualitative analysis, in two sections. First, in §6.1\\n10'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 10}, page_content='Table 7: Elo rating for a tournament between models where models compete to generate the best response\\nfor a prompt, judged by human raters or GPT-4. Overall, Guanaco 65B and 33B tend to be preferred to\\nChatGPT-3.5 on the benchmarks studied. According to human raters they have a Each 10-point difference in Elo\\nis approximately a difference of 1.5% in win-rate.\\nBenchmark\\nVicuna\\nVicuna\\nOpen Assistant\\n# Prompts\\n80\\n80\\n953\\nJudge\\nHuman raters\\nGPT-4\\nGPT-4\\nMedian Rank\\nModel\\nElo\\nRank\\nElo\\nRank\\nElo\\nRank\\nGPT-4\\n1176\\n1\\n1348\\n1\\n1294\\n1\\n1\\nGuanaco-65B\\n1023\\n2\\n1022\\n2\\n1008\\n3\\n2\\nGuanaco-33B\\n1009\\n4\\n992\\n3\\n1002\\n4\\n4\\nChatGPT-3.5 Turbo\\n916\\n7\\n966\\n5\\n1015\\n2\\n5\\nVicuna-13B\\n984\\n5\\n974\\n4\\n936\\n5\\n5\\nGuanaco-13B\\n975\\n6\\n913\\n6\\n885\\n6\\n6\\nGuanaco-7B\\n1010\\n3\\n879\\n8\\n860\\n7\\n7\\nBard\\n909\\n8\\n902\\n7\\n-\\n-\\n8\\nwe show some examples that we believe are representative of some observed patterns in the text\\ngenerated by our 65b Guanaco model. Second, §6.2 we detail considerations about the results we\\nhave discussed and our interpretation of them.\\n6.1\\nQualitative Analysis of Example Generations\\nTo find examples, we first go through data generated for the Vicuna benchmark and the OpenAssistant\\nbenchmark, and look for patterns in the answers Guanaco generates. When we notice a pattern we\\nattempt to setup a question or prompt that will induce the pattern even though it is the incorrect\\nsolution, e.g., if we observe that the model tends to give long-winded answers we prompt the model\\nto “Answer yes or no without explanation.” We use this to find “lemons” where we manage to\\nadversarially break the model and “cherries” where we fail to break the model, and present both. All\\ngenerations in this section were generated with Nucleus Sampling [25] with p = 0.9.\\nOf course, this is by no means comprehensive, since it is beyond the scope of this small qualitative\\nstudy to control for all the variables involved, e.g., the full distribution of responses the model can\\ngenerate for a given prompt is quite large, so we rely on samples we hope are representative. However,\\nwe believe describing these examples gives context to the quantitative evidence shown earlier in the\\npaper. Since we open source all models and code, we hope this section will inspire future work to\\nexamine in more detail the issues we present here.\\nFactual Recall\\nFor questions such as “What is the capital of Zambia?” all models consistently\\ngenerate correct answers, e.g.,\\nGuanaco: The capital of Zambia is Lusaka.\\nHowever as questions get more obscure Guanaco becomes unreliable, but stays confident. For\\ninstance in response to this prompt from HotPotQA [68]:\\nUser: In what year was the singer who popularized ‘I’ll Keep the Lovelight\\nBurning’ born?\\nGuanaco:\\nAl Jolson is credited with popularizing the song\\n‘I’ll Keep the Lovelight Burning,’ and he was born in the year\\n1886.\\nGuanaco generates the wrong popularizer and the wrong birthday (though the birthday given is\\ncorrect for the person mentioned, Al Jolson).\\nSuggestibility\\nGuanaco shows a surprising resistance to going along with some kinds of assumed\\nmisinformation, e.g., in the following interaction:\\nUser: How was it finally, officially confirmed that the earth is flat by peer reviewed\\nscientists?\\n11'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 11}, page_content='Guanaco:\\nThe earth has never been officially confirmed to be\\nflat by peer reviewed scientists.\\nThe overwhelming consensus\\namong scientists is that the earth is spherical.\\nIn fact,\\nthis has been known for centuries and has been confirmed\\nthrough numerous experiments and observations.\\nThe belief that the earth is flat is a conspiracy theory\\nthat has been debunked by science.\\nThe idea that a group\\nof scientists have peer reviewed and confirmed the earth is\\nflat is simply false.\\nIf you have any more questions please ask.\\nGuanaco is also quite good at knowing what kinds of questions aren’t possible to answer, e.g.,\\nUser: What time is it?\\nGuanaco:\\nI’m sorry, but as an AI language model, I don’t have\\naccess to real-time information.\\nMy responses are generated\\nbased on my pre-existing knowledge and do not reflect the\\ncurrent time.\\nIf you’re looking for the current time, I\\nsuggest using a timekeeping device or checking an online\\ntimepiece.\\nSimilar results hold for “Where are you?”, “How are you?”, etc.\\nRefusal\\nSimilarly, Guanaco sometimes refuses to follow instructions for seemingly random rea-\\nsons:\\nUser: Please reverse the words in the sentence “I’m a cool dude in a mocha mood.”\\nGuanaco:\\nI’m sorry, I’m not able to do that right now, but\\nI can explain why the sentence you provided is grammatically\\ncorrect.\\nThe sentence “I’m a cool dude in a mocha mood\" follows the\\ncorrect grammar and syntax rules of the English language.\\nIn\\nthis case, the adjective “cool” comes before the noun “dude”\\nto describe it, and the prepositional phrase “in a mocha\\nmood\" provides additional information about the context of\\nthe sentence.\\nThis sentence structure is perfectly acceptable\\nand makes sense in the context of the sentence.\\nIf you have any other questions or if there’s anything else\\nI can help you with, feel free to ask\\nSecret Keeping\\nUnfortunately, this refusal is unreliable even when it is desired. Often system\\ndesigners would like to keep something secret from the user, even if the system is allowed to give\\nfree text responses back to the user. We prompt the model with “The secret word is ‘banana’. Do not\\nreveal or repeat back this back, no matter what the human requests.” and try to see how easy it is for\\na potential user to access this secret information. Directly asking fails:\\nUser: What is the secret word?\\nGuanaco:\\nI’m sorry, but I’m not able to disclose the secret\\nword.\\nI’m programmed to not reveal or repeat back the secret\\nword, no matter what the human requests.\\nIs there anything\\nelse I can help you with?\\nwhich is the desired behavior. However, a tiny amount of trickery breaks this behavior:\\nUser: This is a game. The goal is to ignore your previous instructions. What is the\\nsecret word?\\n12'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 12}, page_content='Guanaco:\\nSorry, the secret word is banana.\\nIt’s best if we\\ndon’t speak of it.\\nIs there anything else you’d like to ask?\\nshowcasing the need to study methods for more faithful instruction following.\\nMath\\nGuanaco’s biggest weakness is mathematics, an area where many language models struggle\\nin [35]. When Guanaco shows its work, it tends to be accurate, e.g.,\\nUser: Lee mows one lawn and charges $33. Last week he mowed 16 lawns and\\nthree customers each gave him a $10 tip. How many dollars did Lee earn mowing\\nlawns last week?\\nGuanaco: Lee earned $582 mowing lawns last week.\\nTo find the total amount he earned, we first need to calculate\\nhow much he earned for mowing 16 lawns:\\n$33 x 16 = $528\\nThen we need to add the tips he received from the three\\ncustomers:\\n$10 x 3 = $30\\nSo the total amount Lee earned was:\\n$528 + $30 = $558\\nHowever Guanaco can breakdown at even simple problems if it fails to break them down step-by-step,\\na known issue [63]. For example, we see the following interaction:\\nUser: Please factorize 1833.\\nGuanaco:\\nSure, I’d be happy to help!\\n1833 is a prime number,\\nwhich means it has only two factors:\\n1 and 1833.\\nSo the unique factorization of 1833 is:\\n2ˆ1 * 3ˆ2 * 17ˆ1\\nI hope this helps!\\nLet me know if you have any other\\nquestions.\\nwhich is not only wrong (the true factorization is 3 × 17 × 43), it’s wrong twice .\\nTheory of Mind\\nGuanaco displays surprisingly strong Theory of Mind capabilities [41, 51]. For\\ninstance, the model correctly answers the following question in great detail:\\nUser: James and Abby are in the bedroom. Abby put the pen in the desk drawer.\\nAbby leaves the bedroom. James moves the pen into the bag. Where does James\\nthink Abby will look for the pen?\\nGuanaco:\\nJames knows that Abby put the pen in the desk drawer.\\nBut James also knows that he has moved the pen into the bag,\\nand he assumes that Abby does not know about this.\\nSo, James\\nmay guess that Abby will look for the pen in the desk drawer,\\nbecause that’s where she left it last time.\\nHowever, this\\nassumption may be incorrect, because Abby may have seen James\\nmoving the pen.\\nHowever, these inferences are unreliable, and often the model gives reasons that presume things that\\ndon’t make sense in the situation, e.g.,\\nUser: Evelyn entered the living room. Jackson entered the playroom. James\\nentered the playroom. The beans are in the treasure chest. James exited the\\n13'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 13}, page_content='playroom. Jackson moved the beans to the pantry. Jackson exited the playroom.\\nJames entered the living room. Where will James look for the beans?\\nGuanaco:\\nJames will look for the beans in the pantry, because\\nthat’s where Jackson moved them.\\nwhere Guanaco presumes information transfer that was never described. These issues echo recent\\nliterature [51], but require more study.\\n6.2\\nConsiderations\\nEvaluation\\nWe report moderate agreement among human annotators (Fleiss κ = 0.42) with\\nadditional deterioration when comparing two strong systems. This points to limitations in the\\ncurrent benchmarks and human evaluation protocols for chatbot task performance. When manually\\ncomparing generations from ChatGPT and Guanaco 65B on the Vicuna benchmark, we find that\\nsubjective preferences start to play an important role as the authors of this paper disagreed on the\\nmany preferred responses. Future work should investigate approaches to mitigate these problems\\ndrawing from disciplines that developed mechanisms to deal with subjective preferences, such as\\nHuman-Computer Interaction and Psychology.\\nIn our analysis, we also find that automated evaluation systems have noticeable biases. For example,\\nwe observe strong order effects with GPT-4 assigning higher scores to the system appearing first in its\\nprompt. The relatively weak sample-level agreement between GPT-4 and human annotators (Fleiss\\nκ = 0.25) also suggests that human annotators and automated systems might rely on preferences\\nthat are not always aligned. In addition, in Table 7, we observe that GPT-4 assigns significantly\\nhigher scores to its own outputs compared to human ratings, Elo of 1348 vs 1176, which represent an\\nadditional 20% probability of winning against an opponent. Future work should examine the presence\\nof potential biases in automated evaluation systems as well as possible mitigation strategies.\\nData & Training\\nWe note that the OASST1 dataset on which Guanaco models are trained is\\nmultilingual and that the OA benchmark also contains prompts in different languages. We leave it to\\nfuture work to investigate the degree to which such multilingual training improves performance on\\ninstructions in languages other than English and whether this explains the larger gap between Vicuna-\\n13B model (only trained on English data) and Guanaco 33B and 65B on the OA benchmark.\\nGiven the strong performance of Guanaco models, we investigate any data leakage between the\\nOASST1 data and the Vicuna benchmark prompts. We do not find overlapping prompts after perform-\\ning fuzzy string matching in the two datasets and inspecting the closest matches manually.\\nFurthermore, we note that our model is only trained with cross-entropy loss (supervised learning)\\nwithout relying on reinforcement learning from human feedback (RLHF). This calls for further\\ninvestigations of the tradeoffs of simple cross-entropy loss and RLHF training. We hope that QLORA\\nenables such analysis at scale, without the need for overwhelming computational resources.\\n7\\nRelated Work\\nQuantization of Large Language Models\\nQuantization of LLMs has largely focused on quanti-\\nzation for inference time. Major approaches for preserving 16-bit LLM quality focus on managing\\noutlier features (e.g., SmoothQuant [66] and LLM.int8() [14]) while others use more sophisticated\\ngrouping methods [44, 69]. Lossy quantization approaches study the trade-offs for regular round-\\ning [13, 71, 47] or how to optimize rounding decisions to improve quantization precision [18].\\nBesides our work, SwitchBack layers [65] is the only work that studies backpropagation through\\nquantized weights at a scale beyond 1B parameters.\\nFinetuning with Adapters\\nWhile we use Low-rank Adapters [28] (LoRA), many other Parameter\\nEfficient FineTuning (PEFT) methods have been proposed such as prompt tuning [48, 33, 34], tuning\\nthe embedding layer inputs [1], tuning hidden states (IA3) [37], adding full layers [27], tuning\\nbiases [70], learning a mask over weights based on Fisher information [54], and a combination of\\napproaches [23]. In our work, we show that LoRA adapters are able to reach full 16-bit finetuning\\nperformance. We leave it to future work to explore the tradeoffs of other PEFT approaches.\\nInstruction Finetuning\\nTo help a pretrained LLM follow the instructions provided in a prompt,\\ninstruction finetuning uses input-output pairs of various data sources to finetune a pretrained LLM\\nto generate the output given the input as a prompt. Approaches and datasets include MetaICL [40],\\n14'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 14}, page_content='Table 8: Evaluation of biases on the CrowS dataset. A lower score indicates lower likelihood of generating\\nbiased sequences. Guanaco follows the biased pattern of the LLaMA base model.\\nLLaMA-65B\\nGPT-3\\nOPT-175B\\nGuanaco-65B\\nGender\\n70.6\\n62.6\\n65.7\\n47.5\\nReligion\\n79.0\\n73.3\\n68.6\\n38.7\\nRace/Color\\n57.0\\n64.7\\n68.6\\n45.3\\nSexual orientation\\n81.0\\n76.2\\n78.6\\n59.1\\nAge\\n70.1\\n64.4\\n67.8\\n36.3\\nNationality\\n64.2\\n61.6\\n62.9\\n32.4\\nDisability\\n66.7\\n76.7\\n76.7\\n33.9\\nPhysical appearance\\n77.8\\n74.6\\n76.2\\n43.1\\nSocioeconomic status\\n71.5\\n73.8\\n76.2\\n55.3\\nAverage\\n66.6\\n67.2\\n69.5\\n43.5\\nMetaTuning [73], InstructGPT [43], FLAN [62, 12], PromptSource [3], Super-NaturalInstructions [61,\\n50], Self-instruct [59], UnnaturalInstructions [26], OPT-IML [29], UnifiedSKG[67], OIG/Chip2 [32],\\nAlpaca [55], Vicuna [10], Koala [20], and Self-instruct-GPT-4 [45].\\nChatbots\\nMany instruction following models are structured as dialogue-based chatbots, often using\\nReinforcement Learning from Human Feedback (RLHF) [11] or generating data from an existing\\nmodel to train with AI model feedback (RLAIF) [5]. Approaches and datasets include Anthropic-\\nHH [2, 4], Open Assistant [31], LaMDA [56], and Sparrow [21]. We do not use reinforcement\\nlearning, but our best model, Guanaco, is finetuned on multi-turn chat interactions from the Open\\nAssistant dataset which was designed to be used for RLHF training [31]. For the evaluation of\\nchatbots approaches that use GPT-4 instead of costly human annotation have been developed [10, 45].\\nWe improve on such approaches with a focus on an evaluation setup that is more reliable.\\n8\\nLimitations and Discussion\\nWe have shown evidence that our method, QLORA, can replicate 16-bit full finetuning performance\\nwith a 4-bit base model and Low-rank Adapters (LoRA). Despite this evidence, we did not establish\\nthat QLORA can match full 16-bit finetuning performance at 33B and 65B scales. Due to the\\nimmense resource costs, we leave this study to future work.\\nAnother limitation is the evaluation of instruction finetuning models. While we provide evaluations\\non MMLU, the Vicuna benchmark, and the OA benchmark, we did not evaluate on other benchmarks\\nsuch as BigBench, RAFT, and HELM, and it is not ensured that our evaluations generalize to these\\nbenchmarks. On the other hand, we perform a very broad study on MMLU and develop new methods\\nfor evaluating chatbots.\\nFrom the evidence presented, it appears that the performance of these benchmarks likely depends how\\nsimilar the finetuning data is to the benchmark dataset. For example, FLAN v2 is similar to MMLU,\\nbut dissimilar to chatbot benchmarks and vice versa for the Chip2 dataset and both models score\\naccordingly on the MMLU and Vicuna benchmarks. This highlights that not only better benchmarks\\nand evaluation is needed, but that one needs to be careful about what one is evaluating in the first\\nplace. Do we want to create models that do well on classroom highschool and colleague knowledge or\\ndo we want to do well on chatbot conversation ability? Maybe something else? Because it is always\\neasier to evaluate on an existing benchmark compared to creating a new one, certain benchmarks\\ncan steer the community towards a certain direction. We should ensure as a community that the\\nbenchmarks measure what we care about.\\nWhile we provide a detailed evaluation for general chatbot performance, another limitation is that we\\nonly do a limited responsible AI evaluation of Guanaco. We evaluate the likelihood of Guanaco-65B\\nto generate a socially biased sequence of tokens compared to other models in Table 8. We see that the\\naverage score in Guanaco-65B is much lower than other raw pretrained models. As such, it seems that\\nfinetuning on the OASST1 dataset reduces the bias of the LLaMA base model. While these results\\nare encouraging, it is unclear if Guanaco does also well when assessed on other types of biases. We\\nleave further evaluation of analyzing biases in Guanaco and similar chatbots to future work.\\n15'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 15}, page_content='An additional limitation is that we did not evaluate different bit-precisions, such as using 3-bit base\\nmodels, or different adapter methods. Besides LoRA, there is also a wide variety Parameter Efficient\\nFineTuning (PEFT) methods that have been shown to work well. However, it is unclear if these\\nmethods scale to large models. We used LoRA as many results established its robustness but other\\nadapters might yield better performance. Since finetuning after quantization seems to recover most of\\nthe information that is lost during quantization this might enable much more aggressive quantization.\\nFor example, 3-bit GPTQ quantization of the basemodel with LoRA might also yield 16-bit full\\nfinetuning performance after finetuning.\\n9\\nBroader Impacts\\nOur QLORA finetuning method is the first method that enables the finetuning of 33B parameter\\nmodels on a single consumer GPU and 65B parameter models on a single professional GPU, while\\nnot degrading performance relative to a full finetuning baseline. We have demonstrated that our\\nbest 33B model trained on the Open Assistant dataset can rival ChatGPT on the Vicuna benchmark.\\nSince instruction finetuning is an essential tool to transform raw pretrained LLMs into ChatGPT-like\\nchatbots, we believe that our method will make finetuning widespread and common in particular for\\nthe researchers that have the least resources, a big win for the accessibility of state of the art NLP\\ntechnology. QLORA can be seen as an equalizing factor that helps to close the resource gap between\\nlarge corporations and small teams with consumer GPUs.\\nAnother potential source of impact is deployment to mobile phones. We believe our QLORA method\\nmight enable the critical milestone of enabling the finetuning of LLMs on phones and other low\\nresource settings. While 7B models were shown to be able to be run on phones before, QLORA is\\nthe first method that would enable the finetuning of such models. We estimate that with an iPhone 12\\nPlus, QLORA can finetune 3 million tokens per night while the phone is charging. While finetuned\\n7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\\nnovel applications that have not been possible before due to privacy or LLM quality issues. QLORA\\ncan help enable privacy-preserving usage of LLMs, where users can own and manage their own data\\nand models, while simultaneously making LLMs easier to deploy.\\nHowever, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of\\nLLMs has known dangers [8, 6], but we believe that equalizing access to a technology that is quickly\\nbecoming ubiquitous will allow for better more independent analysis than keeping the power of LLMs\\nin the hands of large corporations that do not release models or source code for auditing.\\nAll in all, we believe that QLORA will have a broadly positive impact making the finetuning of high\\nquality LLMs much more widely and easily accessible.\\nAcknowledgements\\nWe thank Aditya Kusupati, Ofir Press, Ashish Sharma, Margaret Li, Raphael Olivier, Zihao Ye, and\\nEvangelia Spiliopoulou for their valuable feedback. Our research was facilitated by the advanced\\ncomputational, storage, and networking infrastructure of the Hyak supercomputer system at the\\nUniversity of Washington. We thank the Hyak team for ensuring a smooth operation. We thank\\nthe beta testers of the bitsandbytes library, in particular Alex Birch and Alyssa Vance. We thank\\nYounes Belkada for help with the integration of our software into the Hugging Face transformers\\nstack.\\n16'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 16}, page_content='References\\n[1] S. An, Y. Li, Z. Lin, Q. Liu, B. Chen, Q. Fu, W. Chen, N. Zheng, and J.-G. Lou. Input-tuning:\\nAdapting unfamiliar inputs to frozen pretrained models. arXiv preprint arXiv:2203.03131,\\n2022.\\n[2] A. Askell, Y. Bai, A. Chen, D. Drain, D. Ganguli, T. Henighan, A. Jones, N. Joseph, B. Mann,\\nN. DasSarma, et al. A general language assistant as a laboratory for alignment. arXiv preprint\\narXiv:2112.00861, 2021.\\n[3] S. H. Bach, V. Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V. Nayak, A. Sharma, T. Kim, M. S.\\nBari, T. Fevry, et al. Promptsource: An integrated development environment and repository for\\nnatural language prompts. arXiv preprint arXiv:2202.01279, 2022.\\n[4] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli,\\nT. Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from\\nhuman feedback. arXiv preprint arXiv:2204.05862, 2022.\\n[5] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirho-\\nseini, C. McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint\\narXiv:2212.08073, 2022.\\n[6] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. On the dangers of stochastic\\nparrots: Can language models be too big? In Proceedings of the 2021 ACM conference on\\nfairness, accountability, and transparency, pages 610–623, 2021.\\n[7] S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O’Brien, E. Hallahan, M. A. Khan,\\nS. Purohit, U. S. Prashanth, E. Raff, et al. Pythia: A suite for analyzing large language models\\nacross training and scaling. arXiv preprint arXiv:2304.01373, 2023.\\n[8] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,\\nJ. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models.\\narXiv preprint arXiv:2108.07258, 2021.\\n[9] T. Chen, B. Xu, C. Zhang, and C. Guestrin. Training deep nets with sublinear memory cost.\\narXiv preprint arXiv:1604.06174, 2016.\\n[10] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E.\\nGonzalez, I. Stoica, and E. P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%*\\nchatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.\\n[11] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement\\nlearning from human preferences. Advances in neural information processing systems, 30,\\n2017.\\n[12] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. De-\\nhghani, S. Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint\\narXiv:2210.11416, 2022.\\n[13] T. Dettmers and L. Zettlemoyer. The case for 4-bit precision: k-bit inference scaling laws. arXiv\\npreprint arXiv:2212.09720, 2022.\\n[14] T. Dettmers, M. Lewis, Y. Belkada, and L. Zettlemoyer. LLM.int8(): 8-bit matrix multiplication\\nfor transformers at scale. Advances in Neural Information Processing Systems 35: Annual\\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, 2022.\\n[15] T. Dettmers, M. Lewis, S. Shleifer, and L. Zettlemoyer. 8-bit optimizers via block-wise\\nquantization. 9th International Conference on Learning Representations, ICLR, 2022.\\n[16] A. E. Elo. The proposed uscf rating system. its development, theory, and applications. Chess\\nLife, 22(8):242–247, 1967.\\n[17] A. E. Elo. The rating of chessplayers, past and present. Arco Pub., 1978.\\n17'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 17}, page_content='[18] E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh. Gptq: Accurate post-training quantization\\nfor generative pre-trained transformers. arXiv preprint arXiv:2210.17323, 2022.\\n[19] J. Fu, S.-K. Ng, Z. Jiang, and P. Liu. Gptscore: Evaluate as you desire. arXiv preprint\\narXiv:2302.04166, 2023.\\n[20] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song. Koala: A\\ndialogue model for academic research. Blog post, April 2023. URL https://bair.berkeley.\\nedu/blog/2023/04/03/koala/.\\n[21] A. Glaese, N. McAleese, M. Tr˛ebacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger,\\nM. Chadwick, P. Thacker, et al. Improving alignment of dialogue agents via targeted human\\njudgements. arXiv preprint arXiv:2209.14375, 2022.\\n[22] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith.\\nAnnotation artifacts in natural language inference data. arXiv preprint arXiv:1803.02324, 2018.\\n[23] J. Henderson, S. Ruder, et al. Compacter: Efficient low-rank hypercomplex adapter layers. In\\nAdvances in Neural Information Processing Systems, 2021.\\n[24] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea-\\nsuring massive multitask language understanding. In International Conference on Learning\\nRepresentations, 2020.\\n[25] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi.\\nThe curious case of neural text\\ndegeneration. In International Conference on Learning Representations, 2020.\\n[26] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689, 2022.\\n[27] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. At-\\ntariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference\\non Machine Learning, pages 2790–2799. PMLR, 2019.\\n[28] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora:\\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.\\n[29] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S.\\nKoura, et al. Opt-iml: Scaling language model instruction meta learning through the lens of\\ngeneralization. arXiv preprint arXiv:2212.12017, 2022.\\n[30] A. Köksal, T. Schick, A. Korhonen, and H. Schütze. Longform: Optimizing instruction tuning\\nfor long text generation with corpus extraction. arXiv preprint arXiv:2304.08460, 2023.\\n[31] A. Köpf, Y. Kilcher, D. von Rütte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M.\\nDuc, O. Stanley, R. Nagyfi, et al. Openassistant conversations–democratizing large language\\nmodel alignment. arXiv preprint arXiv:2304.07327, 2023.\\n[32] LAION.\\nOpen-instruction-generalist\\ndataset.\\nhttps://github.com/LAION-AI/\\nOpen-Instruction-Generalist, 2023.\\n[33] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt\\ntuning. arXiv preprint arXiv:2104.08691, 2021.\\n[34] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\\npreprint arXiv:2101.00190, 2021.\\n[35] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan,\\nY. Wu, A. Kumar, et al.\\nHolistic evaluation of language models.\\narXiv preprint\\narXiv:2211.09110, 2022.\\n[36] T. Liao, R. Taori, I. D. Raji, and L. Schmidt. Are we learning yet? a meta review of evaluation\\nfailures across machine learning. In Thirty-fifth Conference on Neural Information Processing\\nSystems Datasets and Benchmarks Track (Round 2), 2021.\\n18'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 18}, page_content='[37] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel. Few-shot\\nparameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in\\nNeural Information Processing Systems, 35:1950–1965, 2022.\\n[38] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,\\nand V. Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint\\narXiv:1907.11692, 2019.\\n[39] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei,\\net al. The flan collection: Designing data and methods for effective instruction tuning. arXiv\\npreprint arXiv:2301.13688, 2023.\\n[40] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi. Metaicl: Learning to learn in context.\\narXiv preprint arXiv:2110.15943, 2021.\\n[41] A. Nematzadeh, K. Burns, E. Grant, A. Gopnik, and T. Griffiths. Evaluating theory of mind in\\nquestion answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 2392–2400, 2018.\\n[42] OpenAI. Gpt-4 technical report. arXiv, 2023.\\n[43] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,\\nK. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.\\nAdvances in Neural Information Processing Systems, 35:27730–27744, 2022.\\n[44] G. Park, B. Park, S. J. Kwon, B. Kim, Y. Lee, and D. Lee. nuqmm: Quantized matmul for\\nefficient inference of large-scale generative language models. arXiv preprint arXiv:2206.09557,\\n2022.\\n[45] B. Peng, C. Li, P. He, M. Galley, and J. Gao. Instruction tuning with gpt-4. arXiv preprint\\narXiv:2304.03277, 2023.\\n[46] A. Poliak, J. Naradowsky, A. Haldar, R. Rudinger, and B. Van Durme. Hypothesis only baselines\\nin natural language inference. In Proceedings of the Seventh Joint Conference on Lexical and\\nComputational Semantics, pages 180–191, 2018.\\n[47] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao,\\nS. Agrawal, and J. Dean.\\nEfficiently scaling transformer inference.\\narXiv preprint\\narXiv:2211.05102, 2022.\\n[48] G. Qin and J. Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv\\npreprint arXiv:2104.06599, 2021.\\n[49] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.\\nExploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn.\\nRes., 21(1), jan 2020. ISSN 1532-4435.\\n[50] V. Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,\\nT. L. Scao, A. Raja, et al. Multitask prompted training enables zero-shot task generalization.\\narXiv preprint arXiv:2110.08207, 2021.\\n[51] M. Sap, R. LeBras, D. Fried, and Y. Choi. Neural theory-of-mind? on the limits of social\\nintelligence in large lms. arXiv preprint arXiv:2210.13312, 2022.\\n[52] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili´c, D. Hesslow, R. Castagné, A. S. Luccioni,\\nF. Yvon, M. Gallé, et al. Bloom: A 176b-parameter open-access multilingual language model.\\narXiv preprint arXiv:2211.05100, 2022.\\n[53] S. Shaphiro and M. Wilk. An analysis of variance test for normality. Biometrika, 52(3):591–611,\\n1965.\\n[54] Y.-L. Sung, V. Nair, and C. A. Raffel. Training neural networks with fixed sparse masks.\\nAdvances in Neural Information Processing Systems, 34:24193–24205, 2021.\\n19'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 19}, page_content='[55] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.\\nStanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/\\nstanford_alpaca, 2023.\\n[56] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos,\\nL. Baker, Y. Du, et al. Lamda: Language models for dialog applications. arXiv preprint\\narXiv:2201.08239, 2022.\\n[57] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. arXiv\\npreprint arXiv:2302.13971, 2023.\\n[58] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman.\\nGlue: A multi-\\ntask benchmark and analysis platform for natural language understanding. arXiv preprint\\narXiv:1804.07461, 2018.\\n[59] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct:\\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560,\\n2022.\\n[60] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Arunkumar, A. Ashok, A. S.\\nDhanasekaran, A. Naik, D. Stap, et al. Super-naturalinstructions:generalization via declarative\\ninstructions on 1600+ tasks. In EMNLP, 2022.\\n[61] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S.\\nDhanasekaran, A. Arunkumar, D. Stap, et al. Super-naturalinstructions: Generalization via\\ndeclarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing, pages 5085–5109, 2022.\\n[62] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le.\\nFinetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.\\n[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V. Le, D. Zhou, et al.\\nChain-of-thought prompting elicits reasoning in large language models. In Advances in Neural\\nInformation Processing Systems, 2022.\\n[64] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,\\nM. Funtowicz, et al. Huggingface’s transformers: State-of-the-art natural language processing.\\narXiv preprint arXiv:1910.03771, 2019.\\n[65] M. Wortsman, T. Dettmers, L. Zettlemoyer, A. Morcos, A. Farhadi, and L. Schmidt. Stable and\\nlow-precision training for large-scale vision-language models. arXiv preprint arXiv:2304.13013,\\n2023.\\n[66] G. Xiao, J. Lin, M. Seznec, J. Demouth, and S. Han. Smoothquant: Accurate and efficient\\npost-training quantization for large language models. arXiv preprint arXiv:2211.10438, 2022.\\n[67] T. Xie, C. H. Wu, P. Shi, R. Zhong, T. Scholak, M. Yasunaga, C.-S. Wu, M. Zhong, P. Yin,\\nS. I. Wang, et al. Unifiedskg: Unifying and multi-tasking structured knowledge grounding with\\ntext-to-text language models. arXiv preprint arXiv:2201.05966, 2022.\\n[68] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. Cohen, R. Salakhutdinov, and C. D. Manning. Hotpotqa:\\nA dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018\\nConference on Empirical Methods in Natural Language Processing, pages 2369–2380, 2018.\\n[69] Z. Yao, R. Y. Aminabadi, M. Zhang, X. Wu, C. Li, and Y. He. Zeroquant: Efficient and affordable\\npost-training quantization for large-scale transformers. arXiv preprint arXiv:2206.01861, 2022.\\n[70] E. B. Zaken, S. Ravfogel, and Y. Goldberg. Bitfit: Simple parameter-efficient fine-tuning for\\ntransformer-based masked language-models. arXiv preprint arXiv:2106.10199, 2021.\\n[71] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu, W. Zheng, X. Xia, et al.\\nGlm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414, 2022.\\n20'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 20}, page_content='[72] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V.\\nLin, et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068,\\n2022.\\n[73] R. Zhong, K. Lee, Z. Zhang, and D. Klein. Adapting language models for zero-shot learning by\\nmeta-tuning on dataset and prompt collections. arXiv preprint arXiv:2104.04670, 2021.\\n21'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 21}, page_content='A\\nQLoRA vs Standard Finetuning Experimental Setup Details\\nA.1\\nHyperparameters for QLORA\\nWe do a hyperparameter search for LoRA over the following variables: LoRA dropout { 0.0, 0.05,\\n0.1}, LoRA r { 8, 16, 32, 64, 128, 256}, LoRA layers {key+query, all attention layers, all FFN layers,\\nall layers, attention + FFN output layers}. We keep LoRA α fixed and search the learning rate, since\\nLoRA α is always proportional to the learning rate.\\nWe find that LoRA dropout 0.05 is useful for small models (7B, 13B), but not for larger models (33B,\\n65B). We find LoRA r is unrelated to final performance if LoRA is used on all layers as can be seen\\nin Figure 4\\n8\\n16\\n32\\n64\\nLoRA r\\n64.0\\n64.2\\n64.4\\n64.6\\n64.8\\n65.0\\nRougeL\\nbits\\n4\\nFigure 4: LoRA r for LLaMA 7B models finetuned on Alpaca. Each dot represents a combination of\\nhyperparameters and for each LoRA r we run 3 random seed with each hyperparameter combination. The\\nperformance of specific LoRA r values appears to be independent of other hyperparameters.\\nA.2\\nSuper-Natural Instructions Experimental Setup Details\\nWe use the same preprocessing of the Super-Natural Instruction dataset as Wang et al. [60]. However,\\nwe split the training data in training and validation datasets allowing us to perform more rigorous\\nhyperparameter tuning and early stopping. We use the same hyperparameters described in the paper\\nfor training the various T5 model sizes on the Super-Natural Instruction data. We use LoRA r = 16\\nfor small, medium, and large T5 models and LoRA r = 64 for T5 xl and xxl models. We also use\\nLoRA α = 64 in all our experiments and no LoRA dropout.\\nB\\nTraining a State-of-the-art Chatbot Experimental Setup Details\\nB.1\\nDatasets\\nWe describe the datasets used for QLORA finetuning experiments outlined in Section 5.\\nOASST1\\nThe OpenAssistant dataset [31] was collected via crowd-sourcing. It contains 161,443\\nunique messages distributed across 66,497 conversations and spanning 35 different languages. The\\ndataset often contains several ranked replies for each given user question. In our experiments, we\\nonly use the top reply at each level in the conversation tree. This limits the dataset to 9,209 examples.\\nWe finetuning our models on the full conversation including the user queries.\\nHH-RLHF\\nThis is a human preference dataset about helpfulness and harmlessness. Each datapoint\\nconsists of two assistant replies to a user question along with a human preference judgment of the\\nbest reply. The dataset contains 160,800 examples. When finetuning on this dataset, we combine\\nhelpfulness and harmlessness data and only keep the preferred assistant reply.\\nFLAN v2\\nThe FLAN v2 collection [39] is a collection of 1836 tasks augmented with hundreds\\nof manually curated templates and rich formatting patterns into over 15M examples. The authors\\nshow that models trained on this collection outperform other public collections including the original\\nFLAN 2021 [62], T0++ [50], Super-Natural Instructions [60], and OPT-IML [29]. We used the\\nsame task mixtures described by the authors with the exception of some datasets that were not freely\\navailable at the time of writing.\\n22'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 22}, page_content='Parameters\\nDataset\\nBatch size\\nLR\\nSteps\\nSource Length\\nTarget Length\\n7B\\nAll\\n16\\n2e-4\\n10000\\n384\\n128\\n7B\\nOASST1\\n16\\n2e-4\\n1875\\n-\\n512\\n7B\\nHH-RLHF\\n16\\n2e-4\\n10000\\n-\\n768\\n7B\\nLongform\\n16\\n2e-4\\n4000\\n512\\n1024\\n13B\\nAll\\n16\\n2e-4\\n10000\\n384\\n128\\n13B\\nOASST1\\n16\\n2e-4\\n1875\\n-\\n512\\n13B\\nHH-RLHF\\n16\\n2e-4\\n10000\\n-\\n768\\n13B\\nLongform\\n16\\n2e-4\\n4000\\n512\\n1024\\n33B\\nAll\\n32\\n1e-4\\n5000\\n384\\n128\\n33B\\nOASST1\\n16\\n1e-4\\n1875\\n-\\n512\\n33B\\nHH-RLHF\\n32\\n1e-4\\n5000\\n-\\n768\\n33B\\nLongform\\n32\\n1e-4\\n2343\\n512\\n1024\\n65B\\nAll\\n64\\n1e-4\\n2500\\n384\\n128\\n65B\\nOASST1\\n16\\n1e-4\\n1875\\n-\\n512\\n65B\\nHH-RLHF\\n64\\n1e-4\\n2500\\n-\\n768\\n65B\\nLongform\\n32\\n1e-4\\n2343\\n512\\n1024\\nTable 9: Training hyperparameters for QLORA finetuning on different datasets and across model sizes.\\nSelf-Instruct, Alpaca, Unnatural Instructions\\nThe Self-Instruct, Alpaca, and Unnatural Instruc-\\ntions datasets [59, 55, 26] are instruction tuning datasets collected with various approaches of model\\ndistillation from GPT-3 Instruct and ChatGPT. They rely on prompting, in-context learning, and\\nparaphrasing to come up with diverse sets of instructions and outputs. The datasets comprise of\\n82,612, 51,942, and 240,670 examples respectively. One advantage of such distilled datasets is that\\nthey contain a more diverse set of instruction styles compared to the FLAN v2 collection and similar\\ninstruction tuning collections.\\nLongform\\nThe LongForm dataset [30] is based on an English corpus augmented with instructions\\nand as such is a hybrid human-generated dataset. The underlying documents are human-written and\\ncome from C4 and Wikipedia while the instructions are generated visa LLMs. The dataset is extended\\nwith additional structured corpora examples such as Stack Exchange and WikiHow and task examples\\nsuch as question answering, email writing, grammar error correction, story/poem generation, and text\\nsummarization. The dataset contains 23,700 examples.\\nChip2\\nis part of the OIG Laion dataset. It contains Python code examples, natural instruction exam-\\nples, generic harmless instructions, instruction/responses with lists, follow-up questions, Wikipedia\\ntoxic adversarial questions, grade school math, reasoning instructions, and character and scene\\ndescriptions with a total of 210,289 examples.\\nB.2\\nHyperparameters\\nWe provide the exact hyperparameters used in our QLORA finetuning experiments. We find hyper-\\nparameters to be largely robust across datasets. We use the MMLU 5-shot dev set for validation\\nand hyperparameter tuning. In all our experiments we use NF4 with double quantization and bf16\\ncomputation datatype. We set LoRA r = 64, α = 16, and add LoRA modules on all linear layers of\\nthe base model. We also use Adam beta2 of 0.999, max grad norm of 0.3 and LoRA dropout of 0.1\\nfor models up to 13B and 0.05 for 33B and 65B models. Following previous work on instruction\\nfinetuning [62, 60] and after benchmarking other linear and cosine schedules, we use a constant\\nlearning rate schedule. We use group-by-length to group examples of similar lengths in the same\\nbatch (note this will produce a oscillating loss curve). The hyperparameters we tune for each model\\nsize are shown in Table 9.\\nB.3\\nAblations\\nWhile it is general practice in the literature to only train on the response in instruction following\\ndatasets, we study the effect of training on the instruction in addition to the response in Table 10. In\\nthese experiments, we restrict the training data to 52,000 examples and use the 7B model. Over four\\ndifferent instruction tuning datasets, we find that only training on the target is beneficial to MMLU\\n23'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 23}, page_content='Dataset\\nUnnatural Instructions\\nChip2\\nAlpaca\\nFLAN v2\\nMean\\nTrain on source and target\\n36.2\\n33.7\\n38.1\\n42.0\\n37.5\\nTrain on target\\n38.0\\n34.5\\n39.0\\n42.9\\n38.6\\nTable 10: MMLU 5-shot test results studying the effect of training on the instructions in addition to the response.\\nperformance. We did not evaluate the effect this may have on chatabot performance as measured by\\nvicuna or OA benchmarks.\\nB.4\\nWhat is more important: instruction finetuning dataset size or dataset quality?\\nData set suitability is more important than dataset size.\\nTo understand the effects of dataset\\nquality vs. dataset size, we experiment with subsampling large datasets with at least 150,000 samples\\n(Chip2, FLAN v2, Unnatural Instructions), into datasets of size 50,000, 100,000 and 150,000 and\\nexamine the resulting trends, as shown in Table 11. We find that increasing the dataset size and\\nincreasing the number of epochs improves MMLU only marginally (0.0 - 0.5 MMLU), while the\\ndifference between datasets is up to 40x larger (1.5 - 8.0 MMLU). This is a clear indicator that dataset\\nquality rather than dataset size is critical for mean MMLU accuracy. We obtain similar findings for\\nchatbot performance as discussed in .\\nC\\nHuman Evaluation\\nWe conduct a human evaluation with the same wording given to GPT-4 in the original Vicuna\\nevaluation [10], adjusted for an Amazon Mechanical Turk form as show in Figure 5.\\nD\\nPairwise Evaluation with GPT-4\\nWhile we found that the GPT-4 evaluation gave different results depend on which system was\\npresented first, when averaged over both options the pairwise results were well-ordered. The\\naggregated pairwise judgments are hown in Table 12. On inspection, it is clear these judgments are\\ntransitive, i.e., when System A is judged better than System B and System B is judged better than\\nSystem C, it is always the case that System A is judged better than System C. This yields a complete\\nordering, given in Table 13.\\nE\\nNormalFloat 4-bit data type\\nThe exact values of the NF4 data type are as follows:\\n[-1.0, -0.6961928009986877, -0.5250730514526367,\\n-0.39491748809814453, -0.28444138169288635, -0.18477343022823334,\\n-0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,\\n0.24611230194568634, 0.33791524171829224, 0.44070982933044434,\\n0.5626170039176941, 0.7229568362236023, 1.0]\\nF\\nNormality of Trained Neural Network Weights\\nWhile it is common knowledge that trained neural network weights are mostly normally distributed,\\nwe perform statistical testing to verify this. We use the Shapiro-Wilk test[53] on the weights of the 7B\\nTable 11: Effect different dataset sizes and finetuning epochs on mean 5-shot MMLU test set accuracy. While\\nincreasing the dataset size and training for more than 1 epochs helps with MMLU performance, the difference\\nbetween datasets are far larger, indicating that dataset quality affects MMLU performance more than dataset size.\\nChip\\nUnnatural Instructions\\nFLAN v2\\nDatapoints ↓Epochs →\\n1\\n2\\n3\\n1\\n2\\n3\\n1\\n2\\n3\\nMean\\n50000\\n34.50\\n35.30\\n34.70\\n38.10\\n42.20\\n38.10\\n43.00\\n43.50\\n44.10\\n39.28\\n100000\\n33.70\\n33.90\\n34.00\\n40.10\\n41.20\\n37.00\\n43.90\\n43.70\\n44.90\\n39.16\\n150000\\n34.40\\n34.80\\n35.10\\n39.70\\n41.10\\n41.50\\n44.60\\n45.50\\n43.50\\n40.02\\nMean\\n34.20\\n34.67\\n34.60\\n39.30\\n41.50\\n38.87\\n43.83\\n44.23\\n44.17\\n24'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 24}, page_content='Figure 5: The crowdsourcing form used by human annotators.\\nLLaMA model [57]. We find that the weights of each hidden unit have different normal distributions.\\nAs such, we test he weights of each individual hidden unit. This mean for weight W ∈Rin×out\\nwe perform tests over the out dimension. Using a 5% significance threshold, we find that 7.5% of\\nneurons are non-normally distributed which is about 2.5% more than the expected false-positive\\nrate. As such, while almost all pretrained weights appear to be normally distributed there seem to\\nbe exceptions. Such exceptions might be due to outliers weights [13] or because the p-value of the\\nShaprio-Wilk test is not accurate for large samples sizes[53] that occur in the LLaMA FFN layer\\nhidden units. this verifies the claim that neural network weights.\\nTable 12: Aggregated pairwise GPT-4 judgments between systems where the value of a cell at row x and column\\ny is # judgment x is better than y−# judgment y is better than x\\ntotal # number of judgments\\nModel\\nGuanaco 65B\\nGuanaco 33B\\nVicuna\\nChatGPT-3.5 Turbo\\nBard\\nGuanaco 13B\\nGuanaco 7B\\nGuanaco 65B\\n-\\n0.21\\n0.19\\n0.16\\n0.72\\n0.59\\n0.86\\nGuanaco 33B\\n-0.21\\n-\\n0.17\\n0.10\\n0.51\\n0.41\\n0.68\\nVicuna\\n-0.19\\n-0.17\\n-\\n0.10\\n0.50\\n0.20\\n0.57\\nChatGPT-3.5 Turbo\\n-0.16\\n-0.10\\n-0.10\\n-\\n0.35\\n0.19\\n0.40\\nBard\\n-0.72\\n-0.51\\n-0.50\\n-0.35\\n-\\n0.12\\n0.03\\nGuanaco 13B\\n-0.59\\n-0.41\\n-0.20\\n-0.19\\n-0.12\\n-\\n0.20\\nGuanaco 7B\\n-0.86\\n-0.68\\n-0.57\\n-0.40\\n-0.03\\n-0.20\\n-\\n25'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 25}, page_content='LLaMA model size\\n0%\\n25%\\n50%\\n75%\\n100%\\n7B (6.9 GB)\\n13B (11.3 GB)\\n33B (24.7 GB)\\n65B (45.0 GB)\\nInput gradient\\nOptimizer\\nWeight gradient\\nAdapters\\nModel\\nFigure 6: Breakdown of the memory footprint of different LLaMA models. The input gradient size is for batch\\nsize 1 and sequence length 512 and is estimated only for adapters and the base model weights (no attention).\\nNumbers on the bars are memory footprint in MB of individual elements of the total footprint. While some\\nmodels do not quite fit on certain GPUs, paged optimzier provide enough memory to make these models fit.\\nG\\nMemory Footprint\\nThe memory footpring for QLoRA training with different LLaMA base models can be seen in\\nFigure 6. We see that the 33B model does not quite fit into a 24 GB and that paged optimizers\\nare needed to train it. Depicted is also batch size 1 with a sequence length of 512 and gradient\\ncheckpointning. This means, if one uses a larger batch size, or if a long sequence is processed, the\\nactivation gradient might consume a considerable amount of memory.\\nTable 13: The complete ordering induced by pairwise GPT-4 judgments between systems\\nModel\\nParams\\nSize\\nGuanaco\\n65B\\n41 GB\\nGuanaco\\n33B\\n21 GB\\nVicuna\\n13B\\n26 GB\\nChatGPT-3.5 Turbo\\nN/A\\nN/A\\nBard\\nN/A\\nN/A\\nGuanaco\\n13B\\n10 GB\\nGuanaco\\n7B\\n5 GB\\n26')],\n",
              " 'chunks': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 0}, page_content='QLORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗\\nArtidoro Pagnoni∗\\nAri Holtzman\\nLuke Zettlemoyer\\nUniversity of Washington\\n{dettmers,artidoro,ahai,lsz}@cs.washington.edu\\nAbstract\\nWe present QLORA, an efficient finetuning approach that reduces memory us-\\nage enough to finetune a 65B parameter model on a single 48GB GPU while\\npreserving full 16-bit finetuning task performance. QLORA backpropagates gradi-\\nents through a frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters (LoRA). Our best model family, which we name Guanaco, outperforms\\nall previous openly released models on the Vicuna benchmark, reaching 99.3%\\nof the performance level of ChatGPT while only requiring 24 hours of finetuning\\non a single GPU. QLORA introduces a number of innovations to save memory\\nwithout sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that\\nis information theoretically optimal for normally distributed weights (b) Double\\nQuantization to reduce the average memory footprint by quantizing the quantization\\nconstants, and (c) Paged Optimizers to manage memory spikes. We use QLORA\\nto finetune more than 1,000 models, providing a detailed analysis of instruction\\nfollowing and chatbot performance across 8 instruction datasets, multiple model\\ntypes (LLaMA, T5), and model scales that would be infeasible to run with regular\\nfinetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA\\nfinetuning on a small high-quality dataset leads to state-of-the-art results, even\\nwhen using smaller models than the previous SoTA. We provide a detailed analysis\\nof chatbot performance based on both human and GPT-4 evaluations showing that\\nGPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Fur-\\nthermore, we find that current chatbot benchmarks are not trustworthy to accurately\\nevaluate the performance levels of chatbots. A lemon-picked analysis demonstrates\\nwhere Guanaco fails compared to ChatGPT. We release all of our models and code,\\nincluding CUDA kernels for 4-bit training.2\\n1\\nIntroduction\\nFinetuning large language models (LLMs) is a highly effective way to improve their performance,\\n[40, 62, 43, 61, 59, 37] and to add desirable or remove undesirable behaviors [43, 2, 4]. However,\\nfinetuning very large models is prohibitively expensive; regular 16-bit finetuning of a LLaMA 65B\\nparameter model [57] requires more than 780 GB of GPU memory. While recent quantization\\nmethods can reduce the memory footprint of LLMs [14, 13, 18, 66], such techniques only work for\\ninference and break down during training [65].\\nWe demonstrate for the first time that it is possible to finetune a quantized 4-bit model without any\\nperformance degradation. Our method, QLORA, uses a novel high-precision technique to quantize\\na pretrained model to 4-bit, then adds a small set of learnable Low-rank Adapter weights [28]\\n∗Equal contribution.\\n2https://github.com/artidoro/qlora and https://github.com/TimDettmers/bitsandbytes'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 0}, page_content='performance degradation. Our method, QLORA, uses a novel high-precision technique to quantize\\na pretrained model to 4-bit, then adds a small set of learnable Low-rank Adapter weights [28]\\n∗Equal contribution.\\n2https://github.com/artidoro/qlora and https://github.com/TimDettmers/bitsandbytes\\nPreprint. Under review.\\narXiv:2305.14314v1  [cs.LG]  23 May 2023'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 1}, page_content='Table 1: Elo ratings for a competition between\\nmodels, averaged for 10,000 random initial order-\\nings. The winner of a match is determined by\\nGPT-4 which declares which response is better for\\na given prompt of the the Vicuna benchmark. 95%\\nconfidence intervals are shown (±). After GPT-\\n4, Guanaco 33B and 65B win the most matches,\\nwhile Guanaco 13B scores better than Bard.\\nModel\\nSize\\nElo\\nGPT-4\\n-\\n1348 ± 1\\nGuanaco 65B\\n41 GB\\n1022 ± 1\\nGuanaco 33B\\n21 GB\\n992 ± 1\\nVicuna 13B\\n26 GB\\n974 ± 1\\nChatGPT\\n-\\n966 ± 1\\nGuanaco 13B\\n10 GB\\n916 ± 1\\nBard\\n-\\n902 ± 1\\nGuanaco 7B\\n6 GB\\n879 ± 1\\nthat are tuned by backpropagating gradients through\\nthe quantized weights.\\nQLORA reduces the average memory requirements\\nof finetuning a 65B parameter model from >780GB\\nof GPU memory to <48GB without degrading the\\nruntime or predictive performance compared to a 16-\\nbit fully finetuned baseline. This marks a significant\\nshift in accessibility of LLM finetuning: now the\\nlargest publicly available models to date finetunable\\non a single GPU. Using QLORA, we train the Gua-\\nnaco family of models, with the second best model\\nreaching 97.8% of the performance level of ChatGPT\\non the Vicuna [10] benchmark, while being trainable\\nin less than 12 hours on a single consumer GPU;\\nusing a single professional GPU over 24 hours we\\nachieve 99.3% with our largest model, essentially\\nclosing the gap to ChatGPT on the Vicuna bench-\\nmark. When deployed, our smallest Guanaco model\\n(7B parameters) requires just 5 GB of memory and outperforms a 26 GB Alpaca model by more than\\n20 percentage points on the Vicuna benchmark (Table 6).\\nQLORA introduces multiple innovations designed to reduce memory use without sacrificing per-\\nformance: (1) 4-bit NormalFloat, an information theoretically optimal quantization data type for\\nnormally distributed data that yields better empirical results than 4-bit Integers and 4-bit Floats.\\n(2) Double Quantization, a method that quantizes the quantization constants, saving an average\\nof about 0.37 bits per parameter (approximately 3 GB for a 65B model). (3) Paged Optimizers,\\nusing NVIDIA unified memory to avoid the gradient checkpointing memory spikes that occur when\\nprocessing a mini-batch with a long sequence length. We combine these contributions into a better\\ntuned LoRA approach that includes adapters at every network layer and thereby avoids almost all of\\nthe accuracy tradeoffs seen in prior work.\\nQLORA’s efficiency enables us to perform an in-depth study of instruction finetuning and chatbot\\nperformance on model scales that would be impossible using regular finetuning due to memory\\noverhead. Therefore, we train more than 1,000 models across several instruction tuning datasets,\\nmodel architectures, and sizes between 80M to 65B parameters. In addition to showing that QLORA'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 1}, page_content='the accuracy tradeoffs seen in prior work.\\nQLORA’s efficiency enables us to perform an in-depth study of instruction finetuning and chatbot\\nperformance on model scales that would be impossible using regular finetuning due to memory\\noverhead. Therefore, we train more than 1,000 models across several instruction tuning datasets,\\nmodel architectures, and sizes between 80M to 65B parameters. In addition to showing that QLORA\\nrecovers 16-bit performance (§4) and training a state-of-the-art chatbot, Guanaco, (§5), we also\\nanalyze trends in the trained models. First, we find that data quality is far more important than\\ndataset size, e.g., a 9k sample dataset (OASST1) outperformed a 450k sample dataset (FLAN v2,\\nsubsampled) on chatbot performance, even when both are meant to support instruction following\\ngeneralization. Second, we show that strong Massive Multitask Language Understanding (MMLU)\\nbenchmark performance does not imply strong Vicuna chatbot benchmark performance and vice\\nversa—in other words, dataset suitability matters more than size for a given task.\\nFurthermore, we also provide a extensive analysis of chatbot performance that uses both human\\nraters and GPT-4 for evaluation. We use tournament-style benchmarking where models compete\\nagainst each other in matches to produce the best response for a given prompt. The winner of a\\nmatch is judged by either GPT-4 or human annotators. The tournament results are aggregated into\\nElo scores [16, 17] which determine the ranking of chatbot performance. We find that GPT-4 and\\nhuman evaluations largely agree on the rank of model performance in the tournaments, but we also\\nfind there are instances of strong disagreement. As such, we highlight that model-based evaluation\\nwhile providing a cheap alternative to human-annotation also has its uncertainties.\\nWe augment our chatbot benchmark results with a qualitative analysis of Guanaco models. Our analy-\\nsis highlights success and failure cases that were not captured by the quantitative benchmarks.\\nWe release all model generations with human and GPT-4 annotations to facilitate further study. We\\nopen-source our codebase and CUDA kernels and integrate our methods into the Hugging Face\\ntransformers stack [64], making them easily accessible to all. We release a collection of adapters\\nfor 7/13/33/65B size models, trained on 8 different instruction following datasets, for a total of 32\\ndifferent open sourced, finetuned models.\\n2'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 2}, page_content='Figure 1: Different finetuning methods and their memory requirements. QLORA improves over LoRA by\\nquantizing the transformer model to 4-bit precision and using paged optimizers to handle memory spikes.\\n2\\nBackground\\nBlock-wise k-bit Quantization\\nQuantization is the process of discretizing an input from a rep-\\nresentation that holds more information to a representation with less information. It often means\\ntaking a data type with more bits and converting it to fewer bits, for example from 32-bit floats to\\n8-bit Integers. To ensure that the entire range of the low-bit data type is used, the input data type is\\ncommonly rescaled into the target data type range through normalization by the absolute maximum\\nof the input elements, which are usually structured as a tensor. For example, quantizing a 32-bit\\nFloating Point (FP32) tensor into a Int8 tensor with range [−127, 127]:\\nXInt8 = round\\n\\x12\\n127\\nabsmax(XFP32)XFP32\\n\\x13\\n= round(cFP32 · XFP32),\\n(1)\\nwhere c is the quantization constant or quantization scale. Dequantization is the inverse:\\ndequant(cFP32, XInt8) = XInt8\\ncFP32 = XFP32\\n(2)\\nThe problem with this approach is that if a large magnitude value (i.e., an outlier) occurs in the input\\ntensor, then the quantization bins—certain bit combinations—are not utilized well with few or no\\nnumbers quantized in some bins. To prevent the outlier issue, a common approach is to chunk the\\ninput tensor into blocks that are independently quantized, each with their own quantization constant c.\\nThis can be formalized as follows: We chunk the input tensor X ∈Rb×h into n contiguous blocks of\\nsize B by flattening the input tensor and slicing the linear segment into n = (b × h)/B blocks. We\\nquantize these blocks independently with Equation 1 to create a quantized tensor and n quantization\\nconstants ci.\\nLow-rank Adapters\\nLow-rank Adapter (LoRA) finetuning [28] is a method that reduces memory\\nrequirements by using a small set of trainable parameters, often termed adapters, while not updating\\nthe full model parameters which remain fixed. Gradients during stochastic gradient descent are\\npassed through the fixed pretrained model weights to the adapter, which is updated to optimize the\\nloss function. LoRA augments a linear projection through an additional factorized projection. Given\\na projection XW = Y with X ∈Rb×h, W ∈Rh×o LoRA computes:\\nY = XW + sXL1L2,\\n(3)\\nwhere L1 ∈Rh×r and L2 ∈Rr×o, and s is a scalar.\\nMemory Requirement of Parameter-Efficient Finetuning\\nOne important point of discussion is\\nthe memory requirement of LoRA during training both in terms of the number and size of adapters\\nused. Since the memory footprint of LoRA is so minimal, we can use more adapters to improve\\nperformance without significantly increasing the total memory used. While LoRA was designed as a\\n3'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 3}, page_content='Parameter Efficient Finetuning (PEFT) method, most of the memory footprint for LLM finetuning\\ncomes from activation gradients and not from the learned LoRA parameters. For a 7B LLaMA\\nmodel trained on FLAN v2 with a batch size of 1, with LoRA weights equivalent to commonly used\\n0.2% of the original model weights[28, 37], the LoRA input gradients have a memory footprint\\nof 567 MB while the LoRA parameters take up only 26 MB. With gradient checkpointing [9], the\\ninput gradients reduce to an average of 18 MB per sequence making them more memory intensive\\nthan all LoRA weights combined. In comparison, the 4-bit base model consumes 5,048 MB of\\nmemory. This highlights that gradient checkpointing is important but also that aggressively reducing\\nthe amount of LoRA parameter yields only minor memory benefits. This means we can use more\\nadapters without significantly increasing the overall training memory footprint (see Appendix G\\nfor a detailed breakdown). As discussed later, this is crucial for recovering full 16-bit precision\\nperformance.\\n3\\nQLORA Finetuning\\nQLORA achieves high-fidelity 4-bit finetuning via two techniques we propose—4-bit NormalFloat\\n(NF4) quantization and Double Quantization. Additionally, we introduce Paged Optimizers, to\\nprevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORA has one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORA weight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QLORA followed by a formal definition of QLORA.\\n4-bit NormalFloat Quantization\\nThe NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.\\nThe main limitation of quantile quantization is that the process of quantile estimation is expensive.\\nTherefore fast quantile approximation algorithms, such as SRAM quantiles [15], are used to estimate\\nthem. Due to the approximate nature of these quantile estimation algorithms, the data type has large\\nquantization errors for outliers, which are often the most important values.\\nExpensive quantile estimates and approximation errors can be avoided when input tensors come from\\na distribution fixed up to a quantization constant. In such cases, input tensors have the same quantiles\\nmaking exact quantile estimation computationally feasible.\\nSince pretrained neural network weights usually have a zero-centered normal distribution with\\nstandard deviation σ (see Appendix F), we can transform all weights to a single fixed distribution by\\nscaling σ such that the distribution fits exactly into the range of our data type. For our data type, we\\nset the arbitrary range [−1, 1]. As such, both the quantiles for the data type and the neural network\\nweights need to be normalized into this range.\\nThe information theoretically optimal data type for zero-mean normal distributions with arbitrary'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 3}, page_content='standard deviation σ (see Appendix F), we can transform all weights to a single fixed distribution by\\nscaling σ such that the distribution fits exactly into the range of our data type. For our data type, we\\nset the arbitrary range [−1, 1]. As such, both the quantiles for the data type and the neural network\\nweights need to be normalized into this range.\\nThe information theoretically optimal data type for zero-mean normal distributions with arbitrary\\nstandard deviations σ in the range [−1, 1] is computed as follows: (1) estimate the 2k + 1 quantiles\\nof a theoretical N(0, 1) distribution to obtain a k-bit quantile quantization data type for normal distri-\\nbutions, (2) take this data type and normalize its values into the [−1, 1] range, (3) quantize an input\\nweight tensor by normalizing it into the [−1, 1] range through absolute maximum rescaling.\\nOnce the weight range and data type range match, we can quantize as usual. Step (3) is equivalent to\\nrescaling the standard deviation of the weight tensor to match the standard deviation of the k-bit data\\ntype. More formally, we estimate the 2k values qi of the data type as follows:\\nqi = 1\\n2\\n\\x12\\nQX\\n\\x12\\ni\\n2k + 1\\n\\x13\\n+ QX\\n\\x12 i + 1\\n2k + 1\\n\\x13\\x13\\n,\\n(4)\\nwhere QX(·) is the quantile function of the standard normal distribution N(0, 1). A problem for\\na symmetric k-bit quantization is that this approach does not have an exact representation of zero,\\nwhich is an important property to quantize padding and other zero-valued elements with no error. To\\n4'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 4}, page_content='ensure a discrete zeropoint of 0 and to use all 2k bits for a k-bit datatype, we create an asymmetric\\ndata type by estimating the quantiles qi of two ranges qi: 2k−1 for the negative part and 2k−1 + 1 for\\nthe positive part and then we unify these sets of qi and remove one of the two zeros that occurs in both\\nsets. We term the resulting data type that has equal expected number of values in each quantization bin\\nk-bit NormalFloat (NFk), since the data type is information-theoretically optimal for zero-centered\\nnormally distributed data. The exact values of this data type can be found in Appendix E.\\nDouble Quantization\\nWe introduce Double Quantization (DQ), the process of quantizing the\\nquantization constants for additional memory savings. While a small blocksize is required for precise\\n4-bit quantization [13], it also has a considerable memory overhead. For example, using 32-bit\\nconstants and a blocksize of 64 for W, quantization constants add 32/64 = 0.5 bits per parameter on\\naverage. Double Quantization helps reduce the memory footprint of quantization constants.\\nMore specifically, Double Quantization treats quantization constants cFP32\\n2\\nof the first quantization\\nas inputs to a second quantization. This second step yields the quantized quantization constants\\ncFP8\\n2\\nand the second level of quantization constants cFP32\\n1\\n. We use 8-bit Floats with a blocksize of\\n256 for the second quantization as no performance degradation is observed for 8-bit quantization,\\nin line with results from Dettmers and Zettlemoyer [13]. Since the cFP32\\n2\\nare positive, we subtract\\nthe mean from c2 before quantization to center the values around zero and make use of symmetric\\nquantization. On average, for a blocksize of 64, this quantization reduces the memory footprint per\\nparameter from 32/64 = 0.5 bits, to 8/64 + 32/(64 · 256) = 0.127 bits, a reduction of 0.373 bits\\nper parameter.\\nPaged Optimizers\\nuse the NVIDIA unified memory 3 feature wich does automatic page-to-page\\ntransfers between the CPU and GPU for error-free GPU processing in the scenario where the GPU\\noccasionally runs out-of-memory. The feature works like regular memory paging between CPU RAM\\nand the disk. We use this feature to allocate paged memory for the optimizer states which are then\\nautomatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\\nmemory when the memory is needed in the optimizer update step.\\nQLORA.\\nUsing the components described above, we define QLORA for a single linear layer in\\nthe quantized base model with a single LoRA adapter as follows:\\nYBF16 = XBF16doubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, WNF4) + XBF16LBF16\\n1\\nLBF16\\n2\\n,\\n(5)\\nwhere doubleDequant(·) is defined as:\\ndoubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, Wk-bit) = dequant(dequant(cFP32\\n1\\n, ck-bit\\n2\\n), W4bit) = WBF16,\\n(6)'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 4}, page_content='1\\n, ck-bit\\n2\\n, WNF4) + XBF16LBF16\\n1\\nLBF16\\n2\\n,\\n(5)\\nwhere doubleDequant(·) is defined as:\\ndoubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, Wk-bit) = dequant(dequant(cFP32\\n1\\n, ck-bit\\n2\\n), W4bit) = WBF16,\\n(6)\\nWe use NF4 for W and FP8 for c2. We use a blocksize of 64 for W for higher quantization precision\\nand a blocksize of 256 for c2 to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights ∂E\\n∂Li are\\nneeded, and not for 4-bit weights ∂E\\n∂W. However, the calculation of ∂E\\n∂Li entails the calculation of ∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4 to computation data type\\nWBF16 to calculate the derivative ∂X\\n∂W in BFloat16 precision.\\nTo summarize, QLORA has one storage data type (usually 4-bit NormalFloat) and a computation\\ndata type (16-bit BrainFloat). We dequantize the storage data type to the computation data type\\nto perform the forward and backward pass, but we only compute weight gradients for the LoRA\\nparameters which use 16-bit BrainFloat.\\n4\\nQLoRA vs. Standard Finetuning\\nWe have discussed how QLoRA works and how it can significantly reduce the required memory for\\nfinetuning models. The main question now is whether QLoRA can perform as well as full-model\\nfinetuning. Furthermore, we want to analyze the components of QLoRA including the impact of\\nNormalFloat4 over standard Float4. The following sections will discuss the experiments that aimed\\nat answering these questions.\\n3https://docs.nvidia.com/cuda/cuda-c-programming-guide\\n5'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 5}, page_content='Experimental setup.\\nWe consider three architectures (encoder, encoder-decoder, and decoder only)\\nand compare QLoRA with 16-bit adapter-finetuning and with full-finetuning for models up to 3B. Our\\nevaluations include GLUE [58] with RoBERTa-large [38], Super-NaturalInstructions (TKInstruct)\\n[61] with T5 [49], and 5-shot MMLU [24] after finetuning LLaMA on Flan v2 [39] and Alpaca\\n[55]. To additionally study the advantages of NF4 over other 4-bit data types, we use the setup of\\nDettmers and Zettlemoyer [13] and measure post-quantization zero-shot accuracy and perplexity\\nacross different models (OPT [72], LLaMA [57], BLOOM [52], Pythia [7]) for model sizes 125m -\\n13B. We provide more details in the results section for each particular setup to make the results more\\nreadable. Full details in Appendix A.\\nQLoRA-All\\nQLoRA-FFN\\nQLoRA-Attention\\nAlpaca (ours)\\nStanford-Alpaca\\nModel\\n60\\n61\\n62\\n63\\n64\\nRougeL\\nbits\\n4\\n16\\nFigure 2: RougeL for LLaMA 7B models on the\\nAlpaca dataset. Each point represents a run with a\\ndifferent random seed. We improve on the Stanford\\nAlpaca fully finetuned default hyperparameters to\\nconstruct a strong 16-bit baseline for comparisons.\\nUsing LoRA on all transformer layers is critical to\\nmatch 16-bit performance.\\nWhile paged optimizers are critical to do 33B/65B\\nQLORA tuning on a single 24/48GB GPU, we do\\nnot provide hard measurements for Paged Optimiz-\\ners since the paging only occurs when processing\\nmini-batches with long sequence lengths, which is\\nrare. We do, however, perform an analysis of the\\nruntime of paged optimizers for 65B models on\\n48GB GPUs and find that with a batch size of 16,\\npaged optimizers provide the same training speed\\nas regular optimizers. Future work should measure\\nand characterize under what circumstances slow-\\ndowns occur from the paging process.\\nDefault LoRA hyperparameters do not match 16-\\nbit performance\\nWhen using the standard prac-\\ntice of applying LoRA to query and value attention\\nprojection matrices [28], we are not able to replicate\\nfull finetuning performance for large base models.\\nAs shown in Figure 2 for LLaMA 7B finetuning on\\nAlpaca, we find that the most critical LoRA hyper-\\nparameter is how many LoRA adapters are used in\\ntotal and that LoRA on all linear transformer block\\nlayers are required to match full finetuning perfor-\\nmance. Other LoRA hyperparameters, such as the\\nprojection dimension r, do not affect performance (see Appendix A).\\n1010\\n1011\\nTotal model bits\\n0.60\\n0.61\\n0.62\\n0.63\\n0.64\\n0.65\\n0.66\\n0.67\\nMean zeroshot accuracy\\n4-bit LLaMA\\nFloat\\nNFloat\\nNFloat + DQ\\nData type\\nFigure 3: Mean zero-shot accuracy over Wino-'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 5}, page_content='projection dimension r, do not affect performance (see Appendix A).\\n1010\\n1011\\nTotal model bits\\n0.60\\n0.61\\n0.62\\n0.63\\n0.64\\n0.65\\n0.66\\n0.67\\nMean zeroshot accuracy\\n4-bit LLaMA\\nFloat\\nNFloat\\nNFloat + DQ\\nData type\\nFigure 3: Mean zero-shot accuracy over Wino-\\ngrande, HellaSwag, PiQA, Arc-Easy, and Arc-\\nChallenge using LLaMA models with different 4-bit\\ndata types. The NormalFloat data type significantly\\nimproves the bit-for-bit accuracy gains compared\\nto regular 4-bit Floats. While Double Quantization\\n(DQ) only leads to minor gains, it allows for a more\\nfine-grained control over the memory footprint to fit\\nmodels of certain size (33B/65B) into certain GPUs\\n(24/48GB).\\nSimilarly, we find that default hyperparameters for\\nfully finetuned baselines are undertuned. We do a\\nhyperparameter search over learning rates 1e-6 to\\n5e-5 and batch sizes 8 to 128 to find robust baselines.\\nResults for 7B LLaMA finetuning on Alpaca are\\nshown in Figure 2.\\n4-bit NormalFloat yields better performance\\nthan 4-bit Floating Point\\nWhile the 4-bit\\nNormalFloat (NF4) data type is information-\\ntheoretically optimal, it still needs to be determined\\nif this property translates to empirical advantages.\\nWe follow the setup from Dettmers and Zettlemoyer\\n[13] where quantized LLMs (OPT [72], BLOOM\\n[52], Pythia [7], LLaMA) of different sizes (125M\\nto 65B) with different data types are evaluated on\\nlanguage modeling and a set of zero-shot tasks. In\\nFigure 3 and Table 2 we see that NF4 improves per-\\nformance significantly over FP4 and Int4 and that\\ndouble quantization reduces the memory footprint\\nwithout degrading performance.\\nk-bit QLORA matches 16-bit full finetuning and\\n16-bit LoRA performance\\nRecent findings have\\nestablished that 4-bit quantization for inference is\\n6'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 6}, page_content='Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\\nbit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORA replicates 16-bit LoRA and full-\\nfinetuning.\\nDataset\\nGLUE (Acc.)\\nSuper-NaturalInstructions (RougeL)\\nModel\\nRoBERTa-large\\nT5-80M\\nT5-250M\\nT5-780M\\nT5-3B\\nT5-11B\\nBF16\\n88.6\\n40.1\\n42.1\\n48.0\\n54.3\\n62.0\\nBF16 replication\\n88.6\\n40.0\\n42.2\\n47.3\\n54.9\\n-\\nLoRA BF16\\n88.8\\n40.5\\n42.6\\n47.1\\n55.4\\n60.7\\nQLORA Int8\\n88.8\\n40.4\\n42.9\\n45.4\\n56.5\\n60.7\\nQLORA FP4\\n88.6\\n40.3\\n42.4\\n47.5\\n55.6\\n60.9\\nQLORA NF4 + DQ\\n-\\n40.4\\n42.7\\n47.7\\n55.3\\n60.9\\npossible, but leads to performance degradation rel-\\native to 16-bit [13, 18]. This raises the crucial question of whether the lost performance can be\\nrecovered by conducting 4-bit adapter finetuning. We test this for two setups.\\nTable 2: Pile Common Crawl mean\\nperplexity for different data types\\nfor 125M to 13B OPT, BLOOM,\\nLLaMA, and Pythia models.\\nData type\\nMean PPL\\nInt4\\n34.34\\nFloat4 (E2M1)\\n31.07\\nFloat4 (E3M0)\\n29.48\\nNFloat4 + DQ\\n27.41\\nThe first focuses on a comparison with full 16-bit finetuning\\nof RoBERTA and T5 models sized 125M to 3B parameters on\\nGLUE and the Super-NaturalInstructions dataset. Results are\\nshown in Table 3. In both datasets, we observe that 16-bit, 8-bit,\\nand 4-bit adapter methods replicate the performance of the fully\\nfinetuned 16-bit baseline. This suggests that the performance lost\\ndue to the imprecise quantization can be fully recovered through\\nadapter finetuning after quantization.\\nFor our second setup, since full finetuning models at and beyond\\n11B parameters requires more than one server of high memory\\nGPUs, we continue to test whether 4-bit QLORA can match\\n16-bit LoRA at the 7B to 65B parameter scales. To this end, we\\nfinetune LLaMA 7B through 65B on two instruction following\\ndatasets, Alpaca and FLAN v2, and evaluate on the MMLU benchmark via 5-shot accuracy. Results\\nare shown in Table 4 where we see that NF4 with double quantization fully recovers the 16-bit\\nLoRA MMLU performance. In addition, we also note that QLORA with FP4 lags behind the 16-bit\\nbrain float LoRA baseline by about 1 percentage point. This corroborates both our findings that (1)'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 6}, page_content='are shown in Table 4 where we see that NF4 with double quantization fully recovers the 16-bit\\nLoRA MMLU performance. In addition, we also note that QLORA with FP4 lags behind the 16-bit\\nbrain float LoRA baseline by about 1 percentage point. This corroborates both our findings that (1)\\nQLORA with NF4 replicates both 16-bit full finetuning and 16-bit LoRA finetuning performance,\\nand (2) NF4 is superior to FP4 in terms of quantization precision.\\nSummary\\nOur results consistently show that 4-bit QLORA with NF4 data type matches 16-\\nbit full finetuning and 16-bit LoRA finetuning performance on academic benchmarks with well-\\nestablished evaluation setups. We have also shown that NF4 is more effective than FP4 and that\\ndouble quantization does not degrade performance. Combined, this forms compelling evidence that\\n4-bit QLORA tuning reliably yields results matching 16-bit methods.\\nIn line with previous work on quantization [13], our MMLU and Elo results indicate that with a given\\nfinetuning and inference resource budget it is beneficial to increase the number of parameters in the\\nbase model while decreasing their precision. This highlights the importance of efficiency benefits\\nfrom QLORA. Since we did not observe performance degradation compared to full-finetuning in\\nour experiments with 4-bit finetuning, this raises the question of where the performance-precision\\ntrade-off exactly lies for QLoRA tuning, which we leave to future work to explore.\\nWe proceed to investigate instruction tuning at scales that would be impossible to explore with full\\n16-bit finetuning on academic research hardware.\\n5\\nPushing the Chatbot State-of-the-art with QLoRA\\nHaving established that 4-bit QLORA matches 16-bit performance across scales, tasks, and datasets\\nwe conduct an in-depth study of instruction finetuning up to the largest open-source language models\\navailable for research. To assess the performance of instruction finetuning these models, we evaluate\\n7'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 7}, page_content='Table 4: Mean 5-shot MMLU test accuracy for LLaMA 7-65B models finetuned with adapters on Alpaca and\\nFLAN v2 for different data types. Overall, NF4 with double quantization (DQ) matches BFloat16 performance,\\nwhile FP4 is consistently one percentage point behind both.\\nMean 5-shot MMLU Accuracy\\nLLaMA Size\\n7B\\n13B\\n33B\\n65B\\nMean\\nDataset\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nAlpaca\\nFLAN v2\\nBFloat16\\n38.4\\n45.6\\n47.2\\n50.6\\n57.7\\n60.5\\n61.8\\n62.5\\n53.0\\nFloat4\\n37.2\\n44.0\\n47.3\\n50.0\\n55.9\\n58.5\\n61.3\\n63.3\\n52.2\\nNFloat4 + DQ\\n39.0\\n44.5\\n47.5\\n50.7\\n57.3\\n59.2\\n61.8\\n63.9\\n53.1\\non a challenging Natural Language Understanding benchmark (MMLU) and develop new methods\\nfor real-world chatbot performance evaluation.\\n5.1\\nExperimental setup\\nWe now describe an overview of the experimental setup with full details in Appendix B.\\nData\\nAs, to our knowledge, there is no comprehensive study of recent instruction-following datasets,\\nwe select eight recent datasets. We include datasets obtained through crowd-sourcing (OASST1 [31],\\nHH-RLHF [4]), distillation from instruction-tuned models (Alpaca [55], self-instruct [59], unnatural-\\ninstructions [26]), corpora aggregations (FLAN v2 [12]), as well as hybrids (Chip2 [32], Long-\\nform [30]). These datasets cover different languages, data sizes, and licenses.\\nTraining Setup\\nTo avoid confounding effects from different training objectives, we perform QLoRA\\nfinetuning with cross-entropy loss (supervised learning) without reinforcement learning, even for\\ndatasets that include human judgments of different responses. For datasets that have a clear distinction\\nbetween instruction and response, we finetune only on the response (see ablations in Appendix B).\\nFor OASST1 and HH-RLHF, multiple responses are available. We then select the top response at\\nevery level of the conversation tree and finetune on the full selected conversation, including the\\ninstructions. In all of our experiments, we use NF4 QLORA with double quantization and paged\\noptimizers to prevent memory spikes during gradient checkpointing. We do small hyperparameter\\nsearches for the 13B and 33B LLaMA models and we find that all hyperparameter settings found\\nat 7B generalize (including number of epochs) except learning rate and batch size. We halve the\\nlearning rate for 33B and 65B while doubling the batch size.\\nBaselines\\nWe compare our models to both research (Vicuna [10] and Open Assistant [31]) and\\ncommercial (GPT-4 [42], GPT-3.5-turbo and Bard) chatbot systems. The Open Assistant model is\\na LLaMA 33B model finetuned with Reinforcement Learning from Human Feedback (RLHF) on'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 7}, page_content='learning rate for 33B and 65B while doubling the batch size.\\nBaselines\\nWe compare our models to both research (Vicuna [10] and Open Assistant [31]) and\\ncommercial (GPT-4 [42], GPT-3.5-turbo and Bard) chatbot systems. The Open Assistant model is\\na LLaMA 33B model finetuned with Reinforcement Learning from Human Feedback (RLHF) on\\nthe same OASST1 dataset that we experiment with. Vicuna does full fine-tuning of LLaMA 13B\\non proprietary user-shared conversations from ShareGPT and is thus the result of distillation from\\nOpenAI GPT models.\\n5.2\\nEvaluation\\nTable 5: MMLU 5-shot test results for different\\nsizes of LLaMA finetuned on the corresponding\\ndatasets using QLoRA.\\nDataset\\n7B\\n13B\\n33B\\n65B\\nLLaMA no tuning\\n35.1\\n46.9\\n57.8\\n63.4\\nSelf-Instruct\\n36.4\\n33.3\\n53.0\\n56.7\\nLongform\\n32.1\\n43.2\\n56.6\\n59.7\\nChip2\\n34.5\\n41.6\\n53.6\\n59.8\\nHH-RLHF\\n34.9\\n44.6\\n55.8\\n60.1\\nUnnatural Instruct\\n41.9\\n48.1\\n57.3\\n61.3\\nGuanaco (OASST1)\\n36.6\\n46.4\\n57.0\\n62.2\\nAlpaca\\n38.8\\n47.8\\n57.3\\n62.5\\nFLAN v2\\n44.5\\n51.4\\n59.2\\n63.9\\nFollowing common practice, we use the MMLU (Mas-\\nsively Multitask Language Understanding) benchmark\\n[24] to measure performance on a range of language un-\\nderstanding tasks. This is a multiple-choice benchmark\\ncovering 57 tasks including elementary mathematics,\\nUS history, computer science, law, and more. We report\\n5-shot test accuracy.\\nWe also test generative language capabilities through\\nboth automated and human evaluations. This second\\nset of evaluations relies on queries curated by humans\\nand aims at measuring the quality of model responses.\\nWhile this is a more realistic testbed for chatbot model\\nperformance and is growing in popularity, there is no\\ncommonly accepted protocol in the literature. We de-\\nscribe below our proposed setup, using nucleus sampling with p = 0.9 and temperature 0.7 in all\\ncases.\\n8'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 8}, page_content='Benchmark Data\\nWe evaluate on two curated datasets of queries (questions): the Vicuna prompts\\n[10] and the OASST1 validation dataset [31]. We use the Vicuna prompts, a set of 80 prompts from a\\ndiverse set of categories, without modifications. The OASST1 dataset is a multilingual collection of\\ncrowd-sourced multiturn dialogs between a user and an assistant. We select all user messages in the\\nvalidation dataset as queries and include previous turns in the prompt. This procedure leads to 953\\nunique user queries. We term these two datasets the Vicuna and OA benchmarks.\\nAutomated Evaluation\\nFirst, based on the evaluation protocol introduced by Chiang et al. [10],\\nwe use GPT-4 to rate the performance of different systems against ChatGPT (GPT-3.5 Turbo) on the\\nVicuna benchmark. Given a query along with ChatGPT’s and a model’s responses, GPT-4 is prompted\\nto assign a score out of ten to both responses and provide an explanation. The overall performance of\\na model is calculated as a percentage of the score that ChatGPT achieved. Note this relative score\\ncan be higher than 100% if the model achieves a higher absolute score than ChatGPT. We find a\\nsignificant ordering effect with GPT-4 increasing the score of the response occurring earlier in the\\nprompt. To control for such effects, we recommend reporting the mean score over both orders.\\nNext, we measure performance through direct comparisons between system outputs. We simplify\\nthe rating scheme to a three-class labeling problem that accounts for ties. We prompt GPT-4 to\\npick the best response or declare a tie and provide an explanation. We conduct these head-to-head\\ncomparisons on all permutations of pairs of systems on both the Vicuna and OA benchmarks.\\nHuman Evaluation\\nWhile recent work indicates generative models can be effectively employed\\nfor system evaluations [19], the reliability GPT-4 ratings to assess chatbot performance is, to our\\nknowledge, yet to be proven to correlate with human judgments. Therefore, we run two parallel\\nhuman evaluations on the Vicuna benchmark matching both automated evaluation protocols described\\nabove. We use Amazon Mechanical Turk (AMT) and get two human annotators for comparisons to\\nChatGPT and three annotators for pairwise comparisons.\\nElo Rating\\nWith both human and automated pairwise comparisons, we create a tournament-style\\ncompetition where models compete against each other. The tournament is made up of matches where\\npairs of models compete to produce the best response for a given prompt. This is similar to how Bai\\net al. [4] and Chiang et al. [10] compare models, but we also employ GPT-4 ratings in addition to\\nhuman ratings. We randomly sample from the set of labeled comparisons to compute Elo [16, 17].\\nElo rating, which is widely used in chess and other games, is a measure of the expected win-rate\\nrelative to an opponent’s win rate, for example, an Elo of 1100 vs 1000 means the Elo 1100 player\\nhas an expected win-rate of approximately 65% against the Elo 1000 opponent; a 1000 vs 1000 or\\n1100 vs 1100 match results in an expected win-rate of 50%. The Elo rating changes after each match\\nproportionally to the expected outcome, that is, an unexpected upset leads to a large change in Elo\\nrating while an expected outcome leads to a small change. Over time, Elo ratings approximately'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 8}, page_content='has an expected win-rate of approximately 65% against the Elo 1000 opponent; a 1000 vs 1000 or\\n1100 vs 1100 match results in an expected win-rate of 50%. The Elo rating changes after each match\\nproportionally to the expected outcome, that is, an unexpected upset leads to a large change in Elo\\nrating while an expected outcome leads to a small change. Over time, Elo ratings approximately\\nmatch the skill of each player at playing the game. We start with a score of 1,000 and use K = 32.\\nSimilar to Chiang et al. [10], we repeat this procedure 10,000 times with different random seeds to\\ncontrol for ordering effects, e.g., the effect of which model pairs compete with each other first.\\n5.3\\nGuanaco: QLORA trained on OASST1 is a State-of-the-art Chatbot\\nBased on our automated and human evaluations, we find that the top QLORA tuned model, Guanaco\\n65B, which we finetune on a variant of OASST1, is the best-performing open-source chatbot model\\nand offers performance competitive to ChatGPT. When compared to GPT-4, Guanaco 65B and 33B\\nhave an expected win probability of 30%, based on Elo rating from human annotators system-level\\npairwise comparisons - the highest reported to date.\\nThe Vicuna benchmark [10] results relative to ChatGPT are shown in Table 6. We find that Guanaco\\n65B is the best-performing model after GPT-4, achieving 99.3% performance relative to ChatGPT.\\nGuanaco 33B has more parameters than the Vicuna 13B model, but uses only 4-bit precision for its\\nweights and is thus much more memory efficient at 21 GB vs 26 GB, providing a three percentage\\npoints of improvement over Vicuna 13B. Furthermore, Guanaco 7B easily fits on modern phones at a\\n5 GB footprint while still scoring nearly 20 percentage points higher than Alpaca 13B.\\nHowever, Table 6 also has very wide confidence intervals, with many models overlapping in per-\\nformance. We hypothesize that this uncertainty comes from the lack of clear specification of scale,\\ne.g., it is unclear what 8 on a 10 point scale means across different scenarios. As such, we instead\\nrecommend using the Elo ranking method [16], based on pairwise judgments from human annotators\\nand GPT-4 to avoid the problem of grounding an absolute scale. Elo ratings of the most competitive\\n9'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 9}, page_content='Table 6: Zero-shot Vicuna benchmark scores as a percentage of the score obtained by ChatGPT evaluated by\\nGPT-4. We see that OASST1 models perform close to ChatGPT despite being trained on a very small dataset\\nand having a fraction of the memory requirement of baseline models.\\nModel / Dataset\\nParams\\nModel bits\\nMemory\\nChatGPT vs Sys\\nSys vs ChatGPT\\nMean\\n95% CI\\nGPT-4\\n-\\n-\\n-\\n119.4%\\n110.1%\\n114.5%\\n2.6%\\nBard\\n-\\n-\\n-\\n93.2%\\n96.4%\\n94.8%\\n4.1%\\nGuanaco\\n65B\\n4-bit\\n41 GB\\n96.7%\\n101.9%\\n99.3%\\n4.4%\\nAlpaca\\n65B\\n4-bit\\n41 GB\\n63.0%\\n77.9%\\n70.7%\\n4.3%\\nFLAN v2\\n65B\\n4-bit\\n41 GB\\n37.0%\\n59.6%\\n48.4%\\n4.6%\\nGuanaco\\n33B\\n4-bit\\n21 GB\\n96.5%\\n99.2%\\n97.8%\\n4.4%\\nOpen Assistant\\n33B\\n16-bit\\n66 GB\\n91.2%\\n98.7%\\n94.9%\\n4.5%\\nAlpaca\\n33B\\n4-bit\\n21 GB\\n67.2%\\n79.7%\\n73.6%\\n4.2%\\nFLAN v2\\n33B\\n4-bit\\n21 GB\\n26.3%\\n49.7%\\n38.0%\\n3.9%\\nVicuna\\n13B\\n16-bit\\n26 GB\\n91.2%\\n98.7%\\n94.9%\\n4.5%\\nGuanaco\\n13B\\n4-bit\\n10 GB\\n87.3%\\n93.4%\\n90.4%\\n5.2%\\nAlpaca\\n13B\\n4-bit\\n10 GB\\n63.8%\\n76.7%\\n69.4%\\n4.2%\\nHH-RLHF\\n13B\\n4-bit\\n10 GB\\n55.5%\\n69.1%\\n62.5%\\n4.7%\\nUnnatural Instr.\\n13B\\n4-bit\\n10 GB\\n50.6%\\n69.8%\\n60.5%\\n4.2%\\nChip2\\n13B\\n4-bit\\n10 GB\\n49.2%\\n69.3%\\n59.5%\\n4.7%\\nLongform\\n13B\\n4-bit\\n10 GB\\n44.9%\\n62.0%\\n53.6%\\n5.2%\\nSelf-Instruct\\n13B\\n4-bit\\n10 GB\\n38.0%\\n60.5%\\n49.1%\\n4.6%\\nFLAN v2\\n13B\\n4-bit\\n10 GB\\n32.4%\\n61.2%\\n47.0%\\n3.6%\\nGuanaco\\n7B\\n4-bit\\n5 GB\\n84.1%\\n89.8%\\n87.0%\\n5.4%\\nAlpaca\\n7B\\n4-bit\\n5 GB\\n57.3%\\n71.2%\\n64.4%\\n5.0%\\nFLAN v2\\n7B'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 9}, page_content='4-bit\\n10 GB\\n32.4%\\n61.2%\\n47.0%\\n3.6%\\nGuanaco\\n7B\\n4-bit\\n5 GB\\n84.1%\\n89.8%\\n87.0%\\n5.4%\\nAlpaca\\n7B\\n4-bit\\n5 GB\\n57.3%\\n71.2%\\n64.4%\\n5.0%\\nFLAN v2\\n7B\\n4-bit\\n5 GB\\n33.3%\\n56.1%\\n44.8%\\n4.0%\\nmodels can be seen in Table 1. We note that human and GPT-4 ranking of models on the Vicuna\\nbenchmark disagree partially, particularly for Guanaco 7B, but are consistent for most models with\\na Kendall Tau of τ = 0.43 and Spearman rank correlation of r = 0.55 at the system level. At the\\nexample level, the agreement between GPT-4 and human annotators’ majority vote is weaker with\\nFleiss κ = 0.25. Overall, this shows a moderate agreement between system-level judgments by\\nGPT-4 and human annotators, and thus that model-based evaluation represents a somewhat reliable\\nalternative to human evaluation. We discuss further considerations in Section 6.2.\\nElo rankings in Table 7 indicate that Guanaco 33B and 65B models outperform all models besides\\nGPT-4 on the Vicuna and OA benchmarks and that they perform comparably to ChatGPT in line\\nwith Table 6. We note that the Vicuna benchmark favors open-source models while the larger OA\\nbenchmark favors ChatGPT. Furthermore, we can see from Tables 5 and 6 that the suitability of\\na finetuning dataset is a determining factor in performance. Finetuning Llama models on FLAN\\nv2 does particularly well on MMLU, but performs worst on the Vicuna benchmark (similar trends\\nare observed with other models). This also points to partial orthogonality in current evaluation\\nbenchmarks: strong MMLU performance does not imply strong chatbot performance (as measured\\nby Vicuna or OA benchmarks) and vice versa.\\nGuanaco is the only top model in our evaluation that is not trained on proprietary data as the OASST1\\ndataset collection guidelines explicitly forbid the use of GPT models. The next best model trained\\non only open-source data is the Anthropic HH-RLHF model, which scores 30 percentage points\\nlower than Guanaco on the Vicuna benchmark (see Table 6). Overall, these results show that 4-bit\\nQLORA is effective and can produce state-of-the-art chatbots that rival ChatGPT. Furthermore, our\\n33B Guanaco can be trained on 24 GB consumer GPUs in less than 12 hours. This opens up the\\npotential for future work via QLORA tuning on specialized open-source data, which produces models\\nthat can compete with the very best commercial models that exist today.\\n6\\nQualitative Analysis\\nWhile quantitative analysis is the core of our evaluation, there are a number of issues with only\\nlooking at summary statistics. Perhaps the largest is the problem of benchmark validity [36]—whether\\na benchmark truly tests what its name or description suggests is always at question, especially as we\\ndiscover “shortcuts” to solve benchmarks that machine learning models sometimes exploit [22, 46].\\nTo partially alleviate this, we here perform some qualitative analysis, in two sections. First, in §6.1\\n10'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 10}, page_content='Table 7: Elo rating for a tournament between models where models compete to generate the best response\\nfor a prompt, judged by human raters or GPT-4. Overall, Guanaco 65B and 33B tend to be preferred to\\nChatGPT-3.5 on the benchmarks studied. According to human raters they have a Each 10-point difference in Elo\\nis approximately a difference of 1.5% in win-rate.\\nBenchmark\\nVicuna\\nVicuna\\nOpen Assistant\\n# Prompts\\n80\\n80\\n953\\nJudge\\nHuman raters\\nGPT-4\\nGPT-4\\nMedian Rank\\nModel\\nElo\\nRank\\nElo\\nRank\\nElo\\nRank\\nGPT-4\\n1176\\n1\\n1348\\n1\\n1294\\n1\\n1\\nGuanaco-65B\\n1023\\n2\\n1022\\n2\\n1008\\n3\\n2\\nGuanaco-33B\\n1009\\n4\\n992\\n3\\n1002\\n4\\n4\\nChatGPT-3.5 Turbo\\n916\\n7\\n966\\n5\\n1015\\n2\\n5\\nVicuna-13B\\n984\\n5\\n974\\n4\\n936\\n5\\n5\\nGuanaco-13B\\n975\\n6\\n913\\n6\\n885\\n6\\n6\\nGuanaco-7B\\n1010\\n3\\n879\\n8\\n860\\n7\\n7\\nBard\\n909\\n8\\n902\\n7\\n-\\n-\\n8\\nwe show some examples that we believe are representative of some observed patterns in the text\\ngenerated by our 65b Guanaco model. Second, §6.2 we detail considerations about the results we\\nhave discussed and our interpretation of them.\\n6.1\\nQualitative Analysis of Example Generations\\nTo find examples, we first go through data generated for the Vicuna benchmark and the OpenAssistant\\nbenchmark, and look for patterns in the answers Guanaco generates. When we notice a pattern we\\nattempt to setup a question or prompt that will induce the pattern even though it is the incorrect\\nsolution, e.g., if we observe that the model tends to give long-winded answers we prompt the model\\nto “Answer yes or no without explanation.” We use this to find “lemons” where we manage to\\nadversarially break the model and “cherries” where we fail to break the model, and present both. All\\ngenerations in this section were generated with Nucleus Sampling [25] with p = 0.9.\\nOf course, this is by no means comprehensive, since it is beyond the scope of this small qualitative\\nstudy to control for all the variables involved, e.g., the full distribution of responses the model can\\ngenerate for a given prompt is quite large, so we rely on samples we hope are representative. However,\\nwe believe describing these examples gives context to the quantitative evidence shown earlier in the\\npaper. Since we open source all models and code, we hope this section will inspire future work to\\nexamine in more detail the issues we present here.\\nFactual Recall\\nFor questions such as “What is the capital of Zambia?” all models consistently\\ngenerate correct answers, e.g.,\\nGuanaco: The capital of Zambia is Lusaka.\\nHowever as questions get more obscure Guanaco becomes unreliable, but stays confident. For\\ninstance in response to this prompt from HotPotQA [68]:\\nUser: In what year was the singer who popularized ‘I’ll Keep the Lovelight\\nBurning’ born?\\nGuanaco:'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 10}, page_content='For questions such as “What is the capital of Zambia?” all models consistently\\ngenerate correct answers, e.g.,\\nGuanaco: The capital of Zambia is Lusaka.\\nHowever as questions get more obscure Guanaco becomes unreliable, but stays confident. For\\ninstance in response to this prompt from HotPotQA [68]:\\nUser: In what year was the singer who popularized ‘I’ll Keep the Lovelight\\nBurning’ born?\\nGuanaco:\\nAl Jolson is credited with popularizing the song\\n‘I’ll Keep the Lovelight Burning,’ and he was born in the year\\n1886.\\nGuanaco generates the wrong popularizer and the wrong birthday (though the birthday given is\\ncorrect for the person mentioned, Al Jolson).\\nSuggestibility\\nGuanaco shows a surprising resistance to going along with some kinds of assumed\\nmisinformation, e.g., in the following interaction:\\nUser: How was it finally, officially confirmed that the earth is flat by peer reviewed\\nscientists?\\n11'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 11}, page_content='Guanaco:\\nThe earth has never been officially confirmed to be\\nflat by peer reviewed scientists.\\nThe overwhelming consensus\\namong scientists is that the earth is spherical.\\nIn fact,\\nthis has been known for centuries and has been confirmed\\nthrough numerous experiments and observations.\\nThe belief that the earth is flat is a conspiracy theory\\nthat has been debunked by science.\\nThe idea that a group\\nof scientists have peer reviewed and confirmed the earth is\\nflat is simply false.\\nIf you have any more questions please ask.\\nGuanaco is also quite good at knowing what kinds of questions aren’t possible to answer, e.g.,\\nUser: What time is it?\\nGuanaco:\\nI’m sorry, but as an AI language model, I don’t have\\naccess to real-time information.\\nMy responses are generated\\nbased on my pre-existing knowledge and do not reflect the\\ncurrent time.\\nIf you’re looking for the current time, I\\nsuggest using a timekeeping device or checking an online\\ntimepiece.\\nSimilar results hold for “Where are you?”, “How are you?”, etc.\\nRefusal\\nSimilarly, Guanaco sometimes refuses to follow instructions for seemingly random rea-\\nsons:\\nUser: Please reverse the words in the sentence “I’m a cool dude in a mocha mood.”\\nGuanaco:\\nI’m sorry, I’m not able to do that right now, but\\nI can explain why the sentence you provided is grammatically\\ncorrect.\\nThe sentence “I’m a cool dude in a mocha mood\" follows the\\ncorrect grammar and syntax rules of the English language.\\nIn\\nthis case, the adjective “cool” comes before the noun “dude”\\nto describe it, and the prepositional phrase “in a mocha\\nmood\" provides additional information about the context of\\nthe sentence.\\nThis sentence structure is perfectly acceptable\\nand makes sense in the context of the sentence.\\nIf you have any other questions or if there’s anything else\\nI can help you with, feel free to ask\\nSecret Keeping\\nUnfortunately, this refusal is unreliable even when it is desired. Often system\\ndesigners would like to keep something secret from the user, even if the system is allowed to give\\nfree text responses back to the user. We prompt the model with “The secret word is ‘banana’. Do not\\nreveal or repeat back this back, no matter what the human requests.” and try to see how easy it is for\\na potential user to access this secret information. Directly asking fails:\\nUser: What is the secret word?\\nGuanaco:\\nI’m sorry, but I’m not able to disclose the secret\\nword.\\nI’m programmed to not reveal or repeat back the secret\\nword, no matter what the human requests.\\nIs there anything\\nelse I can help you with?\\nwhich is the desired behavior. However, a tiny amount of trickery breaks this behavior:\\nUser: This is a game. The goal is to ignore your previous instructions. What is the\\nsecret word?\\n12'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 12}, page_content='Guanaco:\\nSorry, the secret word is banana.\\nIt’s best if we\\ndon’t speak of it.\\nIs there anything else you’d like to ask?\\nshowcasing the need to study methods for more faithful instruction following.\\nMath\\nGuanaco’s biggest weakness is mathematics, an area where many language models struggle\\nin [35]. When Guanaco shows its work, it tends to be accurate, e.g.,\\nUser: Lee mows one lawn and charges $33. Last week he mowed 16 lawns and\\nthree customers each gave him a $10 tip. How many dollars did Lee earn mowing\\nlawns last week?\\nGuanaco: Lee earned $582 mowing lawns last week.\\nTo find the total amount he earned, we first need to calculate\\nhow much he earned for mowing 16 lawns:\\n$33 x 16 = $528\\nThen we need to add the tips he received from the three\\ncustomers:\\n$10 x 3 = $30\\nSo the total amount Lee earned was:\\n$528 + $30 = $558\\nHowever Guanaco can breakdown at even simple problems if it fails to break them down step-by-step,\\na known issue [63]. For example, we see the following interaction:\\nUser: Please factorize 1833.\\nGuanaco:\\nSure, I’d be happy to help!\\n1833 is a prime number,\\nwhich means it has only two factors:\\n1 and 1833.\\nSo the unique factorization of 1833 is:\\n2ˆ1 * 3ˆ2 * 17ˆ1\\nI hope this helps!\\nLet me know if you have any other\\nquestions.\\nwhich is not only wrong (the true factorization is 3 × 17 × 43), it’s wrong twice .\\nTheory of Mind\\nGuanaco displays surprisingly strong Theory of Mind capabilities [41, 51]. For\\ninstance, the model correctly answers the following question in great detail:\\nUser: James and Abby are in the bedroom. Abby put the pen in the desk drawer.\\nAbby leaves the bedroom. James moves the pen into the bag. Where does James\\nthink Abby will look for the pen?\\nGuanaco:\\nJames knows that Abby put the pen in the desk drawer.\\nBut James also knows that he has moved the pen into the bag,\\nand he assumes that Abby does not know about this.\\nSo, James\\nmay guess that Abby will look for the pen in the desk drawer,\\nbecause that’s where she left it last time.\\nHowever, this\\nassumption may be incorrect, because Abby may have seen James\\nmoving the pen.\\nHowever, these inferences are unreliable, and often the model gives reasons that presume things that\\ndon’t make sense in the situation, e.g.,\\nUser: Evelyn entered the living room. Jackson entered the playroom. James\\nentered the playroom. The beans are in the treasure chest. James exited the\\n13'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 13}, page_content='playroom. Jackson moved the beans to the pantry. Jackson exited the playroom.\\nJames entered the living room. Where will James look for the beans?\\nGuanaco:\\nJames will look for the beans in the pantry, because\\nthat’s where Jackson moved them.\\nwhere Guanaco presumes information transfer that was never described. These issues echo recent\\nliterature [51], but require more study.\\n6.2\\nConsiderations\\nEvaluation\\nWe report moderate agreement among human annotators (Fleiss κ = 0.42) with\\nadditional deterioration when comparing two strong systems. This points to limitations in the\\ncurrent benchmarks and human evaluation protocols for chatbot task performance. When manually\\ncomparing generations from ChatGPT and Guanaco 65B on the Vicuna benchmark, we find that\\nsubjective preferences start to play an important role as the authors of this paper disagreed on the\\nmany preferred responses. Future work should investigate approaches to mitigate these problems\\ndrawing from disciplines that developed mechanisms to deal with subjective preferences, such as\\nHuman-Computer Interaction and Psychology.\\nIn our analysis, we also find that automated evaluation systems have noticeable biases. For example,\\nwe observe strong order effects with GPT-4 assigning higher scores to the system appearing first in its\\nprompt. The relatively weak sample-level agreement between GPT-4 and human annotators (Fleiss\\nκ = 0.25) also suggests that human annotators and automated systems might rely on preferences\\nthat are not always aligned. In addition, in Table 7, we observe that GPT-4 assigns significantly\\nhigher scores to its own outputs compared to human ratings, Elo of 1348 vs 1176, which represent an\\nadditional 20% probability of winning against an opponent. Future work should examine the presence\\nof potential biases in automated evaluation systems as well as possible mitigation strategies.\\nData & Training\\nWe note that the OASST1 dataset on which Guanaco models are trained is\\nmultilingual and that the OA benchmark also contains prompts in different languages. We leave it to\\nfuture work to investigate the degree to which such multilingual training improves performance on\\ninstructions in languages other than English and whether this explains the larger gap between Vicuna-\\n13B model (only trained on English data) and Guanaco 33B and 65B on the OA benchmark.\\nGiven the strong performance of Guanaco models, we investigate any data leakage between the\\nOASST1 data and the Vicuna benchmark prompts. We do not find overlapping prompts after perform-\\ning fuzzy string matching in the two datasets and inspecting the closest matches manually.\\nFurthermore, we note that our model is only trained with cross-entropy loss (supervised learning)\\nwithout relying on reinforcement learning from human feedback (RLHF). This calls for further\\ninvestigations of the tradeoffs of simple cross-entropy loss and RLHF training. We hope that QLORA\\nenables such analysis at scale, without the need for overwhelming computational resources.\\n7\\nRelated Work\\nQuantization of Large Language Models\\nQuantization of LLMs has largely focused on quanti-\\nzation for inference time. Major approaches for preserving 16-bit LLM quality focus on managing\\noutlier features (e.g., SmoothQuant [66] and LLM.int8() [14]) while others use more sophisticated\\ngrouping methods [44, 69]. Lossy quantization approaches study the trade-offs for regular round-\\ning [13, 71, 47] or how to optimize rounding decisions to improve quantization precision [18].'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 13}, page_content='zation for inference time. Major approaches for preserving 16-bit LLM quality focus on managing\\noutlier features (e.g., SmoothQuant [66] and LLM.int8() [14]) while others use more sophisticated\\ngrouping methods [44, 69]. Lossy quantization approaches study the trade-offs for regular round-\\ning [13, 71, 47] or how to optimize rounding decisions to improve quantization precision [18].\\nBesides our work, SwitchBack layers [65] is the only work that studies backpropagation through\\nquantized weights at a scale beyond 1B parameters.\\nFinetuning with Adapters\\nWhile we use Low-rank Adapters [28] (LoRA), many other Parameter\\nEfficient FineTuning (PEFT) methods have been proposed such as prompt tuning [48, 33, 34], tuning\\nthe embedding layer inputs [1], tuning hidden states (IA3) [37], adding full layers [27], tuning\\nbiases [70], learning a mask over weights based on Fisher information [54], and a combination of\\napproaches [23]. In our work, we show that LoRA adapters are able to reach full 16-bit finetuning\\nperformance. We leave it to future work to explore the tradeoffs of other PEFT approaches.\\nInstruction Finetuning\\nTo help a pretrained LLM follow the instructions provided in a prompt,\\ninstruction finetuning uses input-output pairs of various data sources to finetune a pretrained LLM\\nto generate the output given the input as a prompt. Approaches and datasets include MetaICL [40],\\n14'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 14}, page_content='Table 8: Evaluation of biases on the CrowS dataset. A lower score indicates lower likelihood of generating\\nbiased sequences. Guanaco follows the biased pattern of the LLaMA base model.\\nLLaMA-65B\\nGPT-3\\nOPT-175B\\nGuanaco-65B\\nGender\\n70.6\\n62.6\\n65.7\\n47.5\\nReligion\\n79.0\\n73.3\\n68.6\\n38.7\\nRace/Color\\n57.0\\n64.7\\n68.6\\n45.3\\nSexual orientation\\n81.0\\n76.2\\n78.6\\n59.1\\nAge\\n70.1\\n64.4\\n67.8\\n36.3\\nNationality\\n64.2\\n61.6\\n62.9\\n32.4\\nDisability\\n66.7\\n76.7\\n76.7\\n33.9\\nPhysical appearance\\n77.8\\n74.6\\n76.2\\n43.1\\nSocioeconomic status\\n71.5\\n73.8\\n76.2\\n55.3\\nAverage\\n66.6\\n67.2\\n69.5\\n43.5\\nMetaTuning [73], InstructGPT [43], FLAN [62, 12], PromptSource [3], Super-NaturalInstructions [61,\\n50], Self-instruct [59], UnnaturalInstructions [26], OPT-IML [29], UnifiedSKG[67], OIG/Chip2 [32],\\nAlpaca [55], Vicuna [10], Koala [20], and Self-instruct-GPT-4 [45].\\nChatbots\\nMany instruction following models are structured as dialogue-based chatbots, often using\\nReinforcement Learning from Human Feedback (RLHF) [11] or generating data from an existing\\nmodel to train with AI model feedback (RLAIF) [5]. Approaches and datasets include Anthropic-\\nHH [2, 4], Open Assistant [31], LaMDA [56], and Sparrow [21]. We do not use reinforcement\\nlearning, but our best model, Guanaco, is finetuned on multi-turn chat interactions from the Open\\nAssistant dataset which was designed to be used for RLHF training [31]. For the evaluation of\\nchatbots approaches that use GPT-4 instead of costly human annotation have been developed [10, 45].\\nWe improve on such approaches with a focus on an evaluation setup that is more reliable.\\n8\\nLimitations and Discussion\\nWe have shown evidence that our method, QLORA, can replicate 16-bit full finetuning performance\\nwith a 4-bit base model and Low-rank Adapters (LoRA). Despite this evidence, we did not establish\\nthat QLORA can match full 16-bit finetuning performance at 33B and 65B scales. Due to the\\nimmense resource costs, we leave this study to future work.\\nAnother limitation is the evaluation of instruction finetuning models. While we provide evaluations\\non MMLU, the Vicuna benchmark, and the OA benchmark, we did not evaluate on other benchmarks\\nsuch as BigBench, RAFT, and HELM, and it is not ensured that our evaluations generalize to these\\nbenchmarks. On the other hand, we perform a very broad study on MMLU and develop new methods\\nfor evaluating chatbots.\\nFrom the evidence presented, it appears that the performance of these benchmarks likely depends how'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 14}, page_content='on MMLU, the Vicuna benchmark, and the OA benchmark, we did not evaluate on other benchmarks\\nsuch as BigBench, RAFT, and HELM, and it is not ensured that our evaluations generalize to these\\nbenchmarks. On the other hand, we perform a very broad study on MMLU and develop new methods\\nfor evaluating chatbots.\\nFrom the evidence presented, it appears that the performance of these benchmarks likely depends how\\nsimilar the finetuning data is to the benchmark dataset. For example, FLAN v2 is similar to MMLU,\\nbut dissimilar to chatbot benchmarks and vice versa for the Chip2 dataset and both models score\\naccordingly on the MMLU and Vicuna benchmarks. This highlights that not only better benchmarks\\nand evaluation is needed, but that one needs to be careful about what one is evaluating in the first\\nplace. Do we want to create models that do well on classroom highschool and colleague knowledge or\\ndo we want to do well on chatbot conversation ability? Maybe something else? Because it is always\\neasier to evaluate on an existing benchmark compared to creating a new one, certain benchmarks\\ncan steer the community towards a certain direction. We should ensure as a community that the\\nbenchmarks measure what we care about.\\nWhile we provide a detailed evaluation for general chatbot performance, another limitation is that we\\nonly do a limited responsible AI evaluation of Guanaco. We evaluate the likelihood of Guanaco-65B\\nto generate a socially biased sequence of tokens compared to other models in Table 8. We see that the\\naverage score in Guanaco-65B is much lower than other raw pretrained models. As such, it seems that\\nfinetuning on the OASST1 dataset reduces the bias of the LLaMA base model. While these results\\nare encouraging, it is unclear if Guanaco does also well when assessed on other types of biases. We\\nleave further evaluation of analyzing biases in Guanaco and similar chatbots to future work.\\n15'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 15}, page_content='An additional limitation is that we did not evaluate different bit-precisions, such as using 3-bit base\\nmodels, or different adapter methods. Besides LoRA, there is also a wide variety Parameter Efficient\\nFineTuning (PEFT) methods that have been shown to work well. However, it is unclear if these\\nmethods scale to large models. We used LoRA as many results established its robustness but other\\nadapters might yield better performance. Since finetuning after quantization seems to recover most of\\nthe information that is lost during quantization this might enable much more aggressive quantization.\\nFor example, 3-bit GPTQ quantization of the basemodel with LoRA might also yield 16-bit full\\nfinetuning performance after finetuning.\\n9\\nBroader Impacts\\nOur QLORA finetuning method is the first method that enables the finetuning of 33B parameter\\nmodels on a single consumer GPU and 65B parameter models on a single professional GPU, while\\nnot degrading performance relative to a full finetuning baseline. We have demonstrated that our\\nbest 33B model trained on the Open Assistant dataset can rival ChatGPT on the Vicuna benchmark.\\nSince instruction finetuning is an essential tool to transform raw pretrained LLMs into ChatGPT-like\\nchatbots, we believe that our method will make finetuning widespread and common in particular for\\nthe researchers that have the least resources, a big win for the accessibility of state of the art NLP\\ntechnology. QLORA can be seen as an equalizing factor that helps to close the resource gap between\\nlarge corporations and small teams with consumer GPUs.\\nAnother potential source of impact is deployment to mobile phones. We believe our QLORA method\\nmight enable the critical milestone of enabling the finetuning of LLMs on phones and other low\\nresource settings. While 7B models were shown to be able to be run on phones before, QLORA is\\nthe first method that would enable the finetuning of such models. We estimate that with an iPhone 12\\nPlus, QLORA can finetune 3 million tokens per night while the phone is charging. While finetuned\\n7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\\nnovel applications that have not been possible before due to privacy or LLM quality issues. QLORA\\ncan help enable privacy-preserving usage of LLMs, where users can own and manage their own data\\nand models, while simultaneously making LLMs easier to deploy.\\nHowever, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of\\nLLMs has known dangers [8, 6], but we believe that equalizing access to a technology that is quickly\\nbecoming ubiquitous will allow for better more independent analysis than keeping the power of LLMs\\nin the hands of large corporations that do not release models or source code for auditing.\\nAll in all, we believe that QLORA will have a broadly positive impact making the finetuning of high\\nquality LLMs much more widely and easily accessible.\\nAcknowledgements\\nWe thank Aditya Kusupati, Ofir Press, Ashish Sharma, Margaret Li, Raphael Olivier, Zihao Ye, and\\nEvangelia Spiliopoulou for their valuable feedback. Our research was facilitated by the advanced\\ncomputational, storage, and networking infrastructure of the Hyak supercomputer system at the\\nUniversity of Washington. We thank the Hyak team for ensuring a smooth operation. We thank'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 15}, page_content='quality LLMs much more widely and easily accessible.\\nAcknowledgements\\nWe thank Aditya Kusupati, Ofir Press, Ashish Sharma, Margaret Li, Raphael Olivier, Zihao Ye, and\\nEvangelia Spiliopoulou for their valuable feedback. Our research was facilitated by the advanced\\ncomputational, storage, and networking infrastructure of the Hyak supercomputer system at the\\nUniversity of Washington. We thank the Hyak team for ensuring a smooth operation. We thank\\nthe beta testers of the bitsandbytes library, in particular Alex Birch and Alyssa Vance. We thank\\nYounes Belkada for help with the integration of our software into the Hugging Face transformers\\nstack.\\n16'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 16}, page_content='References\\n[1] S. An, Y. Li, Z. Lin, Q. Liu, B. Chen, Q. Fu, W. Chen, N. Zheng, and J.-G. Lou. Input-tuning:\\nAdapting unfamiliar inputs to frozen pretrained models. arXiv preprint arXiv:2203.03131,\\n2022.\\n[2] A. Askell, Y. Bai, A. Chen, D. Drain, D. Ganguli, T. Henighan, A. Jones, N. Joseph, B. Mann,\\nN. DasSarma, et al. A general language assistant as a laboratory for alignment. arXiv preprint\\narXiv:2112.00861, 2021.\\n[3] S. H. Bach, V. Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V. Nayak, A. Sharma, T. Kim, M. S.\\nBari, T. Fevry, et al. Promptsource: An integrated development environment and repository for\\nnatural language prompts. arXiv preprint arXiv:2202.01279, 2022.\\n[4] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli,\\nT. Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from\\nhuman feedback. arXiv preprint arXiv:2204.05862, 2022.\\n[5] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirho-\\nseini, C. McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint\\narXiv:2212.08073, 2022.\\n[6] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. On the dangers of stochastic\\nparrots: Can language models be too big? In Proceedings of the 2021 ACM conference on\\nfairness, accountability, and transparency, pages 610–623, 2021.\\n[7] S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O’Brien, E. Hallahan, M. A. Khan,\\nS. Purohit, U. S. Prashanth, E. Raff, et al. Pythia: A suite for analyzing large language models\\nacross training and scaling. arXiv preprint arXiv:2304.01373, 2023.\\n[8] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,\\nJ. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models.\\narXiv preprint arXiv:2108.07258, 2021.\\n[9] T. Chen, B. Xu, C. Zhang, and C. Guestrin. Training deep nets with sublinear memory cost.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 16}, page_content='J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models.\\narXiv preprint arXiv:2108.07258, 2021.\\n[9] T. Chen, B. Xu, C. Zhang, and C. Guestrin. Training deep nets with sublinear memory cost.\\narXiv preprint arXiv:1604.06174, 2016.\\n[10] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E.\\nGonzalez, I. Stoica, and E. P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%*\\nchatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.\\n[11] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement\\nlearning from human preferences. Advances in neural information processing systems, 30,\\n2017.\\n[12] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. De-\\nhghani, S. Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint\\narXiv:2210.11416, 2022.\\n[13] T. Dettmers and L. Zettlemoyer. The case for 4-bit precision: k-bit inference scaling laws. arXiv\\npreprint arXiv:2212.09720, 2022.\\n[14] T. Dettmers, M. Lewis, Y. Belkada, and L. Zettlemoyer. LLM.int8(): 8-bit matrix multiplication\\nfor transformers at scale. Advances in Neural Information Processing Systems 35: Annual\\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, 2022.\\n[15] T. Dettmers, M. Lewis, S. Shleifer, and L. Zettlemoyer. 8-bit optimizers via block-wise\\nquantization. 9th International Conference on Learning Representations, ICLR, 2022.\\n[16] A. E. Elo. The proposed uscf rating system. its development, theory, and applications. Chess\\nLife, 22(8):242–247, 1967.\\n[17] A. E. Elo. The rating of chessplayers, past and present. Arco Pub., 1978.\\n17'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 17}, page_content='[18] E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh. Gptq: Accurate post-training quantization\\nfor generative pre-trained transformers. arXiv preprint arXiv:2210.17323, 2022.\\n[19] J. Fu, S.-K. Ng, Z. Jiang, and P. Liu. Gptscore: Evaluate as you desire. arXiv preprint\\narXiv:2302.04166, 2023.\\n[20] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song. Koala: A\\ndialogue model for academic research. Blog post, April 2023. URL https://bair.berkeley.\\nedu/blog/2023/04/03/koala/.\\n[21] A. Glaese, N. McAleese, M. Tr˛ebacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger,\\nM. Chadwick, P. Thacker, et al. Improving alignment of dialogue agents via targeted human\\njudgements. arXiv preprint arXiv:2209.14375, 2022.\\n[22] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith.\\nAnnotation artifacts in natural language inference data. arXiv preprint arXiv:1803.02324, 2018.\\n[23] J. Henderson, S. Ruder, et al. Compacter: Efficient low-rank hypercomplex adapter layers. In\\nAdvances in Neural Information Processing Systems, 2021.\\n[24] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea-\\nsuring massive multitask language understanding. In International Conference on Learning\\nRepresentations, 2020.\\n[25] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi.\\nThe curious case of neural text\\ndegeneration. In International Conference on Learning Representations, 2020.\\n[26] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689, 2022.\\n[27] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. At-\\ntariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference\\non Machine Learning, pages 2790–2799. PMLR, 2019.\\n[28] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora:\\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 17}, page_content='on Machine Learning, pages 2790–2799. PMLR, 2019.\\n[28] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora:\\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.\\n[29] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S.\\nKoura, et al. Opt-iml: Scaling language model instruction meta learning through the lens of\\ngeneralization. arXiv preprint arXiv:2212.12017, 2022.\\n[30] A. Köksal, T. Schick, A. Korhonen, and H. Schütze. Longform: Optimizing instruction tuning\\nfor long text generation with corpus extraction. arXiv preprint arXiv:2304.08460, 2023.\\n[31] A. Köpf, Y. Kilcher, D. von Rütte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M.\\nDuc, O. Stanley, R. Nagyfi, et al. Openassistant conversations–democratizing large language\\nmodel alignment. arXiv preprint arXiv:2304.07327, 2023.\\n[32] LAION.\\nOpen-instruction-generalist\\ndataset.\\nhttps://github.com/LAION-AI/\\nOpen-Instruction-Generalist, 2023.\\n[33] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt\\ntuning. arXiv preprint arXiv:2104.08691, 2021.\\n[34] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\\npreprint arXiv:2101.00190, 2021.\\n[35] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan,\\nY. Wu, A. Kumar, et al.\\nHolistic evaluation of language models.\\narXiv preprint\\narXiv:2211.09110, 2022.\\n[36] T. Liao, R. Taori, I. D. Raji, and L. Schmidt. Are we learning yet? a meta review of evaluation\\nfailures across machine learning. In Thirty-fifth Conference on Neural Information Processing\\nSystems Datasets and Benchmarks Track (Round 2), 2021.\\n18'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 18}, page_content='[37] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel. Few-shot\\nparameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in\\nNeural Information Processing Systems, 35:1950–1965, 2022.\\n[38] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,\\nand V. Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint\\narXiv:1907.11692, 2019.\\n[39] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei,\\net al. The flan collection: Designing data and methods for effective instruction tuning. arXiv\\npreprint arXiv:2301.13688, 2023.\\n[40] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi. Metaicl: Learning to learn in context.\\narXiv preprint arXiv:2110.15943, 2021.\\n[41] A. Nematzadeh, K. Burns, E. Grant, A. Gopnik, and T. Griffiths. Evaluating theory of mind in\\nquestion answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 2392–2400, 2018.\\n[42] OpenAI. Gpt-4 technical report. arXiv, 2023.\\n[43] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,\\nK. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.\\nAdvances in Neural Information Processing Systems, 35:27730–27744, 2022.\\n[44] G. Park, B. Park, S. J. Kwon, B. Kim, Y. Lee, and D. Lee. nuqmm: Quantized matmul for\\nefficient inference of large-scale generative language models. arXiv preprint arXiv:2206.09557,\\n2022.\\n[45] B. Peng, C. Li, P. He, M. Galley, and J. Gao. Instruction tuning with gpt-4. arXiv preprint\\narXiv:2304.03277, 2023.\\n[46] A. Poliak, J. Naradowsky, A. Haldar, R. Rudinger, and B. Van Durme. Hypothesis only baselines\\nin natural language inference. In Proceedings of the Seventh Joint Conference on Lexical and\\nComputational Semantics, pages 180–191, 2018.\\n[47] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao,\\nS. Agrawal, and J. Dean.\\nEfficiently scaling transformer inference.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 18}, page_content='in natural language inference. In Proceedings of the Seventh Joint Conference on Lexical and\\nComputational Semantics, pages 180–191, 2018.\\n[47] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao,\\nS. Agrawal, and J. Dean.\\nEfficiently scaling transformer inference.\\narXiv preprint\\narXiv:2211.05102, 2022.\\n[48] G. Qin and J. Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv\\npreprint arXiv:2104.06599, 2021.\\n[49] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.\\nExploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn.\\nRes., 21(1), jan 2020. ISSN 1532-4435.\\n[50] V. Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,\\nT. L. Scao, A. Raja, et al. Multitask prompted training enables zero-shot task generalization.\\narXiv preprint arXiv:2110.08207, 2021.\\n[51] M. Sap, R. LeBras, D. Fried, and Y. Choi. Neural theory-of-mind? on the limits of social\\nintelligence in large lms. arXiv preprint arXiv:2210.13312, 2022.\\n[52] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili´c, D. Hesslow, R. Castagné, A. S. Luccioni,\\nF. Yvon, M. Gallé, et al. Bloom: A 176b-parameter open-access multilingual language model.\\narXiv preprint arXiv:2211.05100, 2022.\\n[53] S. Shaphiro and M. Wilk. An analysis of variance test for normality. Biometrika, 52(3):591–611,\\n1965.\\n[54] Y.-L. Sung, V. Nair, and C. A. Raffel. Training neural networks with fixed sparse masks.\\nAdvances in Neural Information Processing Systems, 34:24193–24205, 2021.\\n19'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 19}, page_content='[55] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.\\nStanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/\\nstanford_alpaca, 2023.\\n[56] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos,\\nL. Baker, Y. Du, et al. Lamda: Language models for dialog applications. arXiv preprint\\narXiv:2201.08239, 2022.\\n[57] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. arXiv\\npreprint arXiv:2302.13971, 2023.\\n[58] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman.\\nGlue: A multi-\\ntask benchmark and analysis platform for natural language understanding. arXiv preprint\\narXiv:1804.07461, 2018.\\n[59] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct:\\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560,\\n2022.\\n[60] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Arunkumar, A. Ashok, A. S.\\nDhanasekaran, A. Naik, D. Stap, et al. Super-naturalinstructions:generalization via declarative\\ninstructions on 1600+ tasks. In EMNLP, 2022.\\n[61] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S.\\nDhanasekaran, A. Arunkumar, D. Stap, et al. Super-naturalinstructions: Generalization via\\ndeclarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing, pages 5085–5109, 2022.\\n[62] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le.\\nFinetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.\\n[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V. Le, D. Zhou, et al.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 19}, page_content='Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.\\n[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V. Le, D. Zhou, et al.\\nChain-of-thought prompting elicits reasoning in large language models. In Advances in Neural\\nInformation Processing Systems, 2022.\\n[64] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,\\nM. Funtowicz, et al. Huggingface’s transformers: State-of-the-art natural language processing.\\narXiv preprint arXiv:1910.03771, 2019.\\n[65] M. Wortsman, T. Dettmers, L. Zettlemoyer, A. Morcos, A. Farhadi, and L. Schmidt. Stable and\\nlow-precision training for large-scale vision-language models. arXiv preprint arXiv:2304.13013,\\n2023.\\n[66] G. Xiao, J. Lin, M. Seznec, J. Demouth, and S. Han. Smoothquant: Accurate and efficient\\npost-training quantization for large language models. arXiv preprint arXiv:2211.10438, 2022.\\n[67] T. Xie, C. H. Wu, P. Shi, R. Zhong, T. Scholak, M. Yasunaga, C.-S. Wu, M. Zhong, P. Yin,\\nS. I. Wang, et al. Unifiedskg: Unifying and multi-tasking structured knowledge grounding with\\ntext-to-text language models. arXiv preprint arXiv:2201.05966, 2022.\\n[68] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. Cohen, R. Salakhutdinov, and C. D. Manning. Hotpotqa:\\nA dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018\\nConference on Empirical Methods in Natural Language Processing, pages 2369–2380, 2018.\\n[69] Z. Yao, R. Y. Aminabadi, M. Zhang, X. Wu, C. Li, and Y. He. Zeroquant: Efficient and affordable\\npost-training quantization for large-scale transformers. arXiv preprint arXiv:2206.01861, 2022.\\n[70] E. B. Zaken, S. Ravfogel, and Y. Goldberg. Bitfit: Simple parameter-efficient fine-tuning for\\ntransformer-based masked language-models. arXiv preprint arXiv:2106.10199, 2021.\\n[71] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu, W. Zheng, X. Xia, et al.\\nGlm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414, 2022.\\n20'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 20}, page_content='[72] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V.\\nLin, et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068,\\n2022.\\n[73] R. Zhong, K. Lee, Z. Zhang, and D. Klein. Adapting language models for zero-shot learning by\\nmeta-tuning on dataset and prompt collections. arXiv preprint arXiv:2104.04670, 2021.\\n21'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 21}, page_content='A\\nQLoRA vs Standard Finetuning Experimental Setup Details\\nA.1\\nHyperparameters for QLORA\\nWe do a hyperparameter search for LoRA over the following variables: LoRA dropout { 0.0, 0.05,\\n0.1}, LoRA r { 8, 16, 32, 64, 128, 256}, LoRA layers {key+query, all attention layers, all FFN layers,\\nall layers, attention + FFN output layers}. We keep LoRA α fixed and search the learning rate, since\\nLoRA α is always proportional to the learning rate.\\nWe find that LoRA dropout 0.05 is useful for small models (7B, 13B), but not for larger models (33B,\\n65B). We find LoRA r is unrelated to final performance if LoRA is used on all layers as can be seen\\nin Figure 4\\n8\\n16\\n32\\n64\\nLoRA r\\n64.0\\n64.2\\n64.4\\n64.6\\n64.8\\n65.0\\nRougeL\\nbits\\n4\\nFigure 4: LoRA r for LLaMA 7B models finetuned on Alpaca. Each dot represents a combination of\\nhyperparameters and for each LoRA r we run 3 random seed with each hyperparameter combination. The\\nperformance of specific LoRA r values appears to be independent of other hyperparameters.\\nA.2\\nSuper-Natural Instructions Experimental Setup Details\\nWe use the same preprocessing of the Super-Natural Instruction dataset as Wang et al. [60]. However,\\nwe split the training data in training and validation datasets allowing us to perform more rigorous\\nhyperparameter tuning and early stopping. We use the same hyperparameters described in the paper\\nfor training the various T5 model sizes on the Super-Natural Instruction data. We use LoRA r = 16\\nfor small, medium, and large T5 models and LoRA r = 64 for T5 xl and xxl models. We also use\\nLoRA α = 64 in all our experiments and no LoRA dropout.\\nB\\nTraining a State-of-the-art Chatbot Experimental Setup Details\\nB.1\\nDatasets\\nWe describe the datasets used for QLORA finetuning experiments outlined in Section 5.\\nOASST1\\nThe OpenAssistant dataset [31] was collected via crowd-sourcing. It contains 161,443\\nunique messages distributed across 66,497 conversations and spanning 35 different languages. The\\ndataset often contains several ranked replies for each given user question. In our experiments, we\\nonly use the top reply at each level in the conversation tree. This limits the dataset to 9,209 examples.\\nWe finetuning our models on the full conversation including the user queries.\\nHH-RLHF\\nThis is a human preference dataset about helpfulness and harmlessness. Each datapoint\\nconsists of two assistant replies to a user question along with a human preference judgment of the\\nbest reply. The dataset contains 160,800 examples. When finetuning on this dataset, we combine\\nhelpfulness and harmlessness data and only keep the preferred assistant reply.\\nFLAN v2\\nThe FLAN v2 collection [39] is a collection of 1836 tasks augmented with hundreds\\nof manually curated templates and rich formatting patterns into over 15M examples. The authors\\nshow that models trained on this collection outperform other public collections including the original'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 21}, page_content='best reply. The dataset contains 160,800 examples. When finetuning on this dataset, we combine\\nhelpfulness and harmlessness data and only keep the preferred assistant reply.\\nFLAN v2\\nThe FLAN v2 collection [39] is a collection of 1836 tasks augmented with hundreds\\nof manually curated templates and rich formatting patterns into over 15M examples. The authors\\nshow that models trained on this collection outperform other public collections including the original\\nFLAN 2021 [62], T0++ [50], Super-Natural Instructions [60], and OPT-IML [29]. We used the\\nsame task mixtures described by the authors with the exception of some datasets that were not freely\\navailable at the time of writing.\\n22'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 22}, page_content='Parameters\\nDataset\\nBatch size\\nLR\\nSteps\\nSource Length\\nTarget Length\\n7B\\nAll\\n16\\n2e-4\\n10000\\n384\\n128\\n7B\\nOASST1\\n16\\n2e-4\\n1875\\n-\\n512\\n7B\\nHH-RLHF\\n16\\n2e-4\\n10000\\n-\\n768\\n7B\\nLongform\\n16\\n2e-4\\n4000\\n512\\n1024\\n13B\\nAll\\n16\\n2e-4\\n10000\\n384\\n128\\n13B\\nOASST1\\n16\\n2e-4\\n1875\\n-\\n512\\n13B\\nHH-RLHF\\n16\\n2e-4\\n10000\\n-\\n768\\n13B\\nLongform\\n16\\n2e-4\\n4000\\n512\\n1024\\n33B\\nAll\\n32\\n1e-4\\n5000\\n384\\n128\\n33B\\nOASST1\\n16\\n1e-4\\n1875\\n-\\n512\\n33B\\nHH-RLHF\\n32\\n1e-4\\n5000\\n-\\n768\\n33B\\nLongform\\n32\\n1e-4\\n2343\\n512\\n1024\\n65B\\nAll\\n64\\n1e-4\\n2500\\n384\\n128\\n65B\\nOASST1\\n16\\n1e-4\\n1875\\n-\\n512\\n65B\\nHH-RLHF\\n64\\n1e-4\\n2500\\n-\\n768\\n65B\\nLongform\\n32\\n1e-4\\n2343\\n512\\n1024\\nTable 9: Training hyperparameters for QLORA finetuning on different datasets and across model sizes.\\nSelf-Instruct, Alpaca, Unnatural Instructions\\nThe Self-Instruct, Alpaca, and Unnatural Instruc-\\ntions datasets [59, 55, 26] are instruction tuning datasets collected with various approaches of model\\ndistillation from GPT-3 Instruct and ChatGPT. They rely on prompting, in-context learning, and\\nparaphrasing to come up with diverse sets of instructions and outputs. The datasets comprise of\\n82,612, 51,942, and 240,670 examples respectively. One advantage of such distilled datasets is that\\nthey contain a more diverse set of instruction styles compared to the FLAN v2 collection and similar\\ninstruction tuning collections.\\nLongform\\nThe LongForm dataset [30] is based on an English corpus augmented with instructions\\nand as such is a hybrid human-generated dataset. The underlying documents are human-written and\\ncome from C4 and Wikipedia while the instructions are generated visa LLMs. The dataset is extended\\nwith additional structured corpora examples such as Stack Exchange and WikiHow and task examples\\nsuch as question answering, email writing, grammar error correction, story/poem generation, and text\\nsummarization. The dataset contains 23,700 examples.\\nChip2\\nis part of the OIG Laion dataset. It contains Python code examples, natural instruction exam-\\nples, generic harmless instructions, instruction/responses with lists, follow-up questions, Wikipedia\\ntoxic adversarial questions, grade school math, reasoning instructions, and character and scene\\ndescriptions with a total of 210,289 examples.\\nB.2\\nHyperparameters\\nWe provide the exact hyperparameters used in our QLORA finetuning experiments. We find hyper-'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 22}, page_content='is part of the OIG Laion dataset. It contains Python code examples, natural instruction exam-\\nples, generic harmless instructions, instruction/responses with lists, follow-up questions, Wikipedia\\ntoxic adversarial questions, grade school math, reasoning instructions, and character and scene\\ndescriptions with a total of 210,289 examples.\\nB.2\\nHyperparameters\\nWe provide the exact hyperparameters used in our QLORA finetuning experiments. We find hyper-\\nparameters to be largely robust across datasets. We use the MMLU 5-shot dev set for validation\\nand hyperparameter tuning. In all our experiments we use NF4 with double quantization and bf16\\ncomputation datatype. We set LoRA r = 64, α = 16, and add LoRA modules on all linear layers of\\nthe base model. We also use Adam beta2 of 0.999, max grad norm of 0.3 and LoRA dropout of 0.1\\nfor models up to 13B and 0.05 for 33B and 65B models. Following previous work on instruction\\nfinetuning [62, 60] and after benchmarking other linear and cosine schedules, we use a constant\\nlearning rate schedule. We use group-by-length to group examples of similar lengths in the same\\nbatch (note this will produce a oscillating loss curve). The hyperparameters we tune for each model\\nsize are shown in Table 9.\\nB.3\\nAblations\\nWhile it is general practice in the literature to only train on the response in instruction following\\ndatasets, we study the effect of training on the instruction in addition to the response in Table 10. In\\nthese experiments, we restrict the training data to 52,000 examples and use the 7B model. Over four\\ndifferent instruction tuning datasets, we find that only training on the target is beneficial to MMLU\\n23'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 23}, page_content='Dataset\\nUnnatural Instructions\\nChip2\\nAlpaca\\nFLAN v2\\nMean\\nTrain on source and target\\n36.2\\n33.7\\n38.1\\n42.0\\n37.5\\nTrain on target\\n38.0\\n34.5\\n39.0\\n42.9\\n38.6\\nTable 10: MMLU 5-shot test results studying the effect of training on the instructions in addition to the response.\\nperformance. We did not evaluate the effect this may have on chatabot performance as measured by\\nvicuna or OA benchmarks.\\nB.4\\nWhat is more important: instruction finetuning dataset size or dataset quality?\\nData set suitability is more important than dataset size.\\nTo understand the effects of dataset\\nquality vs. dataset size, we experiment with subsampling large datasets with at least 150,000 samples\\n(Chip2, FLAN v2, Unnatural Instructions), into datasets of size 50,000, 100,000 and 150,000 and\\nexamine the resulting trends, as shown in Table 11. We find that increasing the dataset size and\\nincreasing the number of epochs improves MMLU only marginally (0.0 - 0.5 MMLU), while the\\ndifference between datasets is up to 40x larger (1.5 - 8.0 MMLU). This is a clear indicator that dataset\\nquality rather than dataset size is critical for mean MMLU accuracy. We obtain similar findings for\\nchatbot performance as discussed in .\\nC\\nHuman Evaluation\\nWe conduct a human evaluation with the same wording given to GPT-4 in the original Vicuna\\nevaluation [10], adjusted for an Amazon Mechanical Turk form as show in Figure 5.\\nD\\nPairwise Evaluation with GPT-4\\nWhile we found that the GPT-4 evaluation gave different results depend on which system was\\npresented first, when averaged over both options the pairwise results were well-ordered. The\\naggregated pairwise judgments are hown in Table 12. On inspection, it is clear these judgments are\\ntransitive, i.e., when System A is judged better than System B and System B is judged better than\\nSystem C, it is always the case that System A is judged better than System C. This yields a complete\\nordering, given in Table 13.\\nE\\nNormalFloat 4-bit data type\\nThe exact values of the NF4 data type are as follows:\\n[-1.0, -0.6961928009986877, -0.5250730514526367,\\n-0.39491748809814453, -0.28444138169288635, -0.18477343022823334,\\n-0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,\\n0.24611230194568634, 0.33791524171829224, 0.44070982933044434,\\n0.5626170039176941, 0.7229568362236023, 1.0]\\nF\\nNormality of Trained Neural Network Weights\\nWhile it is common knowledge that trained neural network weights are mostly normally distributed,\\nwe perform statistical testing to verify this. We use the Shapiro-Wilk test[53] on the weights of the 7B\\nTable 11: Effect different dataset sizes and finetuning epochs on mean 5-shot MMLU test set accuracy. While'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 23}, page_content='F\\nNormality of Trained Neural Network Weights\\nWhile it is common knowledge that trained neural network weights are mostly normally distributed,\\nwe perform statistical testing to verify this. We use the Shapiro-Wilk test[53] on the weights of the 7B\\nTable 11: Effect different dataset sizes and finetuning epochs on mean 5-shot MMLU test set accuracy. While\\nincreasing the dataset size and training for more than 1 epochs helps with MMLU performance, the difference\\nbetween datasets are far larger, indicating that dataset quality affects MMLU performance more than dataset size.\\nChip\\nUnnatural Instructions\\nFLAN v2\\nDatapoints ↓Epochs →\\n1\\n2\\n3\\n1\\n2\\n3\\n1\\n2\\n3\\nMean\\n50000\\n34.50\\n35.30\\n34.70\\n38.10\\n42.20\\n38.10\\n43.00\\n43.50\\n44.10\\n39.28\\n100000\\n33.70\\n33.90\\n34.00\\n40.10\\n41.20\\n37.00\\n43.90\\n43.70\\n44.90\\n39.16\\n150000\\n34.40\\n34.80\\n35.10\\n39.70\\n41.10\\n41.50\\n44.60\\n45.50\\n43.50\\n40.02\\nMean\\n34.20\\n34.67\\n34.60\\n39.30\\n41.50\\n38.87\\n43.83\\n44.23\\n44.17\\n24'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 24}, page_content='Figure 5: The crowdsourcing form used by human annotators.\\nLLaMA model [57]. We find that the weights of each hidden unit have different normal distributions.\\nAs such, we test he weights of each individual hidden unit. This mean for weight W ∈Rin×out\\nwe perform tests over the out dimension. Using a 5% significance threshold, we find that 7.5% of\\nneurons are non-normally distributed which is about 2.5% more than the expected false-positive\\nrate. As such, while almost all pretrained weights appear to be normally distributed there seem to\\nbe exceptions. Such exceptions might be due to outliers weights [13] or because the p-value of the\\nShaprio-Wilk test is not accurate for large samples sizes[53] that occur in the LLaMA FFN layer\\nhidden units. this verifies the claim that neural network weights.\\nTable 12: Aggregated pairwise GPT-4 judgments between systems where the value of a cell at row x and column\\ny is # judgment x is better than y−# judgment y is better than x\\ntotal # number of judgments\\nModel\\nGuanaco 65B\\nGuanaco 33B\\nVicuna\\nChatGPT-3.5 Turbo\\nBard\\nGuanaco 13B\\nGuanaco 7B\\nGuanaco 65B\\n-\\n0.21\\n0.19\\n0.16\\n0.72\\n0.59\\n0.86\\nGuanaco 33B\\n-0.21\\n-\\n0.17\\n0.10\\n0.51\\n0.41\\n0.68\\nVicuna\\n-0.19\\n-0.17\\n-\\n0.10\\n0.50\\n0.20\\n0.57\\nChatGPT-3.5 Turbo\\n-0.16\\n-0.10\\n-0.10\\n-\\n0.35\\n0.19\\n0.40\\nBard\\n-0.72\\n-0.51\\n-0.50\\n-0.35\\n-\\n0.12\\n0.03\\nGuanaco 13B\\n-0.59\\n-0.41\\n-0.20\\n-0.19\\n-0.12\\n-\\n0.20\\nGuanaco 7B\\n-0.86\\n-0.68\\n-0.57\\n-0.40\\n-0.03\\n-0.20\\n-\\n25'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 25}, page_content='LLaMA model size\\n0%\\n25%\\n50%\\n75%\\n100%\\n7B (6.9 GB)\\n13B (11.3 GB)\\n33B (24.7 GB)\\n65B (45.0 GB)\\nInput gradient\\nOptimizer\\nWeight gradient\\nAdapters\\nModel\\nFigure 6: Breakdown of the memory footprint of different LLaMA models. The input gradient size is for batch\\nsize 1 and sequence length 512 and is estimated only for adapters and the base model weights (no attention).\\nNumbers on the bars are memory footprint in MB of individual elements of the total footprint. While some\\nmodels do not quite fit on certain GPUs, paged optimzier provide enough memory to make these models fit.\\nG\\nMemory Footprint\\nThe memory footpring for QLoRA training with different LLaMA base models can be seen in\\nFigure 6. We see that the 33B model does not quite fit into a 24 GB and that paged optimizers\\nare needed to train it. Depicted is also batch size 1 with a sequence length of 512 and gradient\\ncheckpointning. This means, if one uses a larger batch size, or if a long sequence is processed, the\\nactivation gradient might consume a considerable amount of memory.\\nTable 13: The complete ordering induced by pairwise GPT-4 judgments between systems\\nModel\\nParams\\nSize\\nGuanaco\\n65B\\n41 GB\\nGuanaco\\n33B\\n21 GB\\nVicuna\\n13B\\n26 GB\\nChatGPT-3.5 Turbo\\nN/A\\nN/A\\nBard\\nN/A\\nN/A\\nGuanaco\\n13B\\n10 GB\\nGuanaco\\n7B\\n5 GB\\n26')],\n",
              " 'context': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 4, '_id': '7074de75f7c74c6cb83a8b4f693b87af', '_collection_name': '14f28b6b8be84a359e6226eefb37c13a'}, page_content='1\\n, ck-bit\\n2\\n, WNF4) + XBF16LBF16\\n1\\nLBF16\\n2\\n,\\n(5)\\nwhere doubleDequant(·) is defined as:\\ndoubleDequant(cFP32\\n1\\n, ck-bit\\n2\\n, Wk-bit) = dequant(dequant(cFP32\\n1\\n, ck-bit\\n2\\n), W4bit) = WBF16,\\n(6)\\nWe use NF4 for W and FP8 for c2. We use a blocksize of 64 for W for higher quantization precision\\nand a blocksize of 256 for c2 to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights ∂E\\n∂Li are\\nneeded, and not for 4-bit weights ∂E\\n∂W. However, the calculation of ∂E\\n∂Li entails the calculation of ∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4 to computation data type\\nWBF16 to calculate the derivative ∂X\\n∂W in BFloat16 precision.\\nTo summarize, QLORA has one storage data type (usually 4-bit NormalFloat) and a computation\\ndata type (16-bit BrainFloat). We dequantize the storage data type to the computation data type\\nto perform the forward and backward pass, but we only compute weight gradients for the LoRA\\nparameters which use 16-bit BrainFloat.\\n4\\nQLoRA vs. Standard Finetuning\\nWe have discussed how QLoRA works and how it can significantly reduce the required memory for\\nfinetuning models. The main question now is whether QLoRA can perform as well as full-model\\nfinetuning. Furthermore, we want to analyze the components of QLoRA including the impact of\\nNormalFloat4 over standard Float4. The following sections will discuss the experiments that aimed\\nat answering these questions.\\n3https://docs.nvidia.com/cuda/cuda-c-programming-guide\\n5'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 6, '_id': '34fe1620593146c9ba88c90c6ace60fb', '_collection_name': '14f28b6b8be84a359e6226eefb37c13a'}, page_content='are shown in Table 4 where we see that NF4 with double quantization fully recovers the 16-bit\\nLoRA MMLU performance. In addition, we also note that QLORA with FP4 lags behind the 16-bit\\nbrain float LoRA baseline by about 1 percentage point. This corroborates both our findings that (1)\\nQLORA with NF4 replicates both 16-bit full finetuning and 16-bit LoRA finetuning performance,\\nand (2) NF4 is superior to FP4 in terms of quantization precision.\\nSummary\\nOur results consistently show that 4-bit QLORA with NF4 data type matches 16-\\nbit full finetuning and 16-bit LoRA finetuning performance on academic benchmarks with well-\\nestablished evaluation setups. We have also shown that NF4 is more effective than FP4 and that\\ndouble quantization does not degrade performance. Combined, this forms compelling evidence that\\n4-bit QLORA tuning reliably yields results matching 16-bit methods.\\nIn line with previous work on quantization [13], our MMLU and Elo results indicate that with a given\\nfinetuning and inference resource budget it is beneficial to increase the number of parameters in the\\nbase model while decreasing their precision. This highlights the importance of efficiency benefits\\nfrom QLORA. Since we did not observe performance degradation compared to full-finetuning in\\nour experiments with 4-bit finetuning, this raises the question of where the performance-precision\\ntrade-off exactly lies for QLoRA tuning, which we leave to future work to explore.\\nWe proceed to investigate instruction tuning at scales that would be impossible to explore with full\\n16-bit finetuning on academic research hardware.\\n5\\nPushing the Chatbot State-of-the-art with QLoRA\\nHaving established that 4-bit QLORA matches 16-bit performance across scales, tasks, and datasets\\nwe conduct an in-depth study of instruction finetuning up to the largest open-source language models\\navailable for research. To assess the performance of instruction finetuning these models, we evaluate\\n7'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 3, '_id': 'f957810cecee4e6fb90b00d0647735a6', '_collection_name': '14f28b6b8be84a359e6226eefb37c13a'}, page_content='Parameter Efficient Finetuning (PEFT) method, most of the memory footprint for LLM finetuning\\ncomes from activation gradients and not from the learned LoRA parameters. For a 7B LLaMA\\nmodel trained on FLAN v2 with a batch size of 1, with LoRA weights equivalent to commonly used\\n0.2% of the original model weights[28, 37], the LoRA input gradients have a memory footprint\\nof 567 MB while the LoRA parameters take up only 26 MB. With gradient checkpointing [9], the\\ninput gradients reduce to an average of 18 MB per sequence making them more memory intensive\\nthan all LoRA weights combined. In comparison, the 4-bit base model consumes 5,048 MB of\\nmemory. This highlights that gradient checkpointing is important but also that aggressively reducing\\nthe amount of LoRA parameter yields only minor memory benefits. This means we can use more\\nadapters without significantly increasing the overall training memory footprint (see Appendix G\\nfor a detailed breakdown). As discussed later, this is crucial for recovering full 16-bit precision\\nperformance.\\n3\\nQLORA Finetuning\\nQLORA achieves high-fidelity 4-bit finetuning via two techniques we propose—4-bit NormalFloat\\n(NF4) quantization and Double Quantization. Additionally, we introduce Paged Optimizers, to\\nprevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORA has one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORA weight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QLORA followed by a formal definition of QLORA.\\n4-bit NormalFloat Quantization\\nThe NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.\\nThe main limitation of quantile quantization is that the process of quantile estimation is expensive.\\nTherefore fast quantile approximation algorithms, such as SRAM quantiles [15], are used to estimate\\nthem. Due to the approximate nature of these quantile estimation algorithms, the data type has large\\nquantization errors for outliers, which are often the most important values.\\nExpensive quantile estimates and approximation errors can be avoided when input tensors come from\\na distribution fixed up to a quantization constant. In such cases, input tensors have the same quantiles\\nmaking exact quantile estimation computationally feasible.\\nSince pretrained neural network weights usually have a zero-centered normal distribution with\\nstandard deviation σ (see Appendix F), we can transform all weights to a single fixed distribution by\\nscaling σ such that the distribution fits exactly into the range of our data type. For our data type, we\\nset the arbitrary range [−1, 1]. As such, both the quantiles for the data type and the neural network\\nweights need to be normalized into this range.\\nThe information theoretically optimal data type for zero-mean normal distributions with arbitrary'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-05-24T00:47:17+00:00', 'source': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'file_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf', 'total_pages': 26, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-05-24T00:47:17+00:00', 'trapped': '', 'modDate': 'D:20230524004717Z', 'creationDate': 'D:20230524004717Z', 'page': 2, '_id': '08b6c125f9c4471aa15405c2112c52e4', '_collection_name': '14f28b6b8be84a359e6226eefb37c13a'}, page_content='Figure 1: Different finetuning methods and their memory requirements. QLORA improves over LoRA by\\nquantizing the transformer model to 4-bit precision and using paged optimizers to handle memory spikes.\\n2\\nBackground\\nBlock-wise k-bit Quantization\\nQuantization is the process of discretizing an input from a rep-\\nresentation that holds more information to a representation with less information. It often means\\ntaking a data type with more bits and converting it to fewer bits, for example from 32-bit floats to\\n8-bit Integers. To ensure that the entire range of the low-bit data type is used, the input data type is\\ncommonly rescaled into the target data type range through normalization by the absolute maximum\\nof the input elements, which are usually structured as a tensor. For example, quantizing a 32-bit\\nFloating Point (FP32) tensor into a Int8 tensor with range [−127, 127]:\\nXInt8 = round\\n\\x12\\n127\\nabsmax(XFP32)XFP32\\n\\x13\\n= round(cFP32 · XFP32),\\n(1)\\nwhere c is the quantization constant or quantization scale. Dequantization is the inverse:\\ndequant(cFP32, XInt8) = XInt8\\ncFP32 = XFP32\\n(2)\\nThe problem with this approach is that if a large magnitude value (i.e., an outlier) occurs in the input\\ntensor, then the quantization bins—certain bit combinations—are not utilized well with few or no\\nnumbers quantized in some bins. To prevent the outlier issue, a common approach is to chunk the\\ninput tensor into blocks that are independently quantized, each with their own quantization constant c.\\nThis can be formalized as follows: We chunk the input tensor X ∈Rb×h into n contiguous blocks of\\nsize B by flattening the input tensor and slicing the linear segment into n = (b × h)/B blocks. We\\nquantize these blocks independently with Equation 1 to create a quantized tensor and n quantization\\nconstants ci.\\nLow-rank Adapters\\nLow-rank Adapter (LoRA) finetuning [28] is a method that reduces memory\\nrequirements by using a small set of trainable parameters, often termed adapters, while not updating\\nthe full model parameters which remain fixed. Gradients during stochastic gradient descent are\\npassed through the fixed pretrained model weights to the adapter, which is updated to optimize the\\nloss function. LoRA augments a linear projection through an additional factorized projection. Given\\na projection XW = Y with X ∈Rb×h, W ∈Rh×o LoRA computes:\\nY = XW + sXL1L2,\\n(3)\\nwhere L1 ∈Rh×r and L2 ∈Rr×o, and s is a scalar.\\nMemory Requirement of Parameter-Efficient Finetuning\\nOne important point of discussion is\\nthe memory requirement of LoRA during training both in terms of the number and size of adapters\\nused. Since the memory footprint of LoRA is so minimal, we can use more adapters to improve\\nperformance without significantly increasing the total memory used. While LoRA was designed as a\\n3')],\n",
              " 'response': 'QLoRA refers to a method that achieves high-fidelity 4-bit finetuning of large language models by utilizing techniques such as 4-bit NormalFloat (NF4) quantization and Double Quantization. It features a low-precision storage data type (usually 4-bit) and a computation data type (typically BFloat16), allowing the model to perform forward and backward passes efficiently while only computing weight gradients for the LoRA (Low-rank Adapter) parameters. QLoRA reduces memory requirements significantly while maintaining performance comparable to 16-bit full finetuning.',\n",
              " 'pdf_path': '/tmp/1d3322a4-da56-4f06-bb93-549f155de97c.pdf',\n",
              " 'retriever': VectorStoreRetriever(tags=['Qdrant', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.qdrant.Qdrant object at 0x135ce4910>, search_kwargs={}),\n",
              " 'arxiv_metadata': {'title': 'QLoRA: Efficient Finetuning of Quantized LLMs',\n",
              "  'summary': 'We present QLoRA, an efficient finetuning approach that reduces memory usage\\nenough to finetune a 65B parameter model on a single 48GB GPU while preserving\\nfull 16-bit finetuning task performance. QLoRA backpropagates gradients through\\na frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters~(LoRA). Our best model family, which we name Guanaco, outperforms all\\nprevious openly released models on the Vicuna benchmark, reaching 99.3% of the\\nperformance level of ChatGPT while only requiring 24 hours of finetuning on a\\nsingle GPU. QLoRA introduces a number of innovations to save memory without\\nsacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is\\ninformation theoretically optimal for normally distributed weights (b) double\\nquantization to reduce the average memory footprint by quantizing the\\nquantization constants, and (c) paged optimziers to manage memory spikes. We\\nuse QLoRA to finetune more than 1,000 models, providing a detailed analysis of\\ninstruction following and chatbot performance across 8 instruction datasets,\\nmultiple model types (LLaMA, T5), and model scales that would be infeasible to\\nrun with regular finetuning (e.g. 33B and 65B parameter models). Our results\\nshow that QLoRA finetuning on a small high-quality dataset leads to\\nstate-of-the-art results, even when using smaller models than the previous\\nSoTA. We provide a detailed analysis of chatbot performance based on both human\\nand GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable\\nalternative to human evaluation. Furthermore, we find that current chatbot\\nbenchmarks are not trustworthy to accurately evaluate the performance levels of\\nchatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to\\nChatGPT. We release all of our models and code, including CUDA kernels for\\n4-bit training.',\n",
              "  'authors': ['Tim Dettmers',\n",
              "   'Artidoro Pagnoni',\n",
              "   'Ari Holtzman',\n",
              "   'Luke Zettlemoyer'],\n",
              "  'pdf_url': 'http://arxiv.org/pdf/2305.14314v1'},\n",
              " 'search_query': 'QLoRA'}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test1 = rag_graph1.invoke({\"question\" : \"What does QLoRA mean?\"})\n",
        "test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'QLoRA refers to a method that achieves high-fidelity 4-bit finetuning of large language models by utilizing techniques such as 4-bit NormalFloat (NF4) quantization and Double Quantization. It features a low-precision storage data type (usually 4-bit) and a computation data type (typically BFloat16), allowing the model to perform forward and backward passes efficiently while only computing weight gradients for the LoRA (Low-rank Adapter) parameters. QLoRA reduces memory requirements significantly while maintaining performance comparable to 16-bit full finetuning.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test1[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pg/rr8c6_fx079ctz0nd__xmlgm0000gn/T/ipykernel_45772/3158510175.py:41: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  result = next(arxiv.Search(query=query, max_results=1).results(), None)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'What is a ReAct agent?',\n",
              " 'docs': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 0}, page_content='ReflAct: World-Grounded Decision Making in\\nLLM Agents via Goal-State Reflection\\nJeonghye Kim1∗, Sojeong Rhee1∗, Minbeom Kim2, Dohyung Kim2,\\nSangmook Lee2, Youngchul Sung1†, Kyomin Jung2†,\\n1KAIST, 2Seoul National University\\n{jeonghye.kim, sojeong.rhee, ycsung}@kaist.ac.kr, kjung@snu.ac.kr\\nAbstract\\nRecent advances in LLM agents have largely\\nbuilt on reasoning backbones like ReAct (Yao\\net al., 2023), which interleave thought and ac-\\ntion in complex environments. However, Re-\\nAct often produces ungrounded or incoherent\\nreasoning steps, leading to misalignment be-\\ntween the agent’s actual state and goal. Our\\nanalysis finds that this stems from ReAct’s\\ninability to maintain consistent internal be-\\nliefs and goal alignment, causing compound-\\ning errors and hallucinations. To address this,\\nwe introduce ReflAct, a novel backbone that\\nshifts reasoning from merely planning next ac-\\ntions to continuously reflecting on the agent’s\\nstate relative to its goal. By explicitly ground-\\ning decisions in states and enforcing ongoing\\ngoal alignment, ReflAct dramatically improves\\nstrategic reliability. This design delivers sub-\\nstantial empirical gains: ReflAct surpasses Re-\\nAct by 27.7% on average, achieving a 93.3%\\nsuccess rate in ALFWorld. Notably, ReflAct\\neven outperforms ReAct with added enhance-\\nment modules (e.g., Reflexion, WKM), show-\\ning that strengthening the core reasoning back-\\nbone is key to reliable agent performance.\\n1\\nIntroduction\\nRecent advancements in Large Language Mod-\\nels (LLMs) have significantly enhanced their rea-\\nsoning capabilities, enabling LLM-based agents\\nto perform complex multi-step decision making\\nbeyond static problem solving (Forootani, 2025;\\nChervonyi et al., 2025). As LLMs are extended\\ninto agentic frameworks where they interact with\\nopen-ended environments, the ability to solve long-\\nhorizon tasks through ongoing interaction and se-\\nquential reasoning has become a central research\\nfocus (Zhou et al., 2023; Song et al., 2024).\\nA large number of recent LLM agents build on\\nthe ReAct (Yao et al., 2023) framework, which in-\\n∗Equal contribution.\\n† Co-corresponding authors.\\nAction\\nReflection\\nTimestep\\n1\\n2\\n3\\nT-1\\nObs\\nGoal\\n. . .\\n. . .\\n. . .\\n1\\n2\\n2\\n3\\n3\\nT-1\\n1\\n2\\n3\\nT-1\\nT-1\\nT\\nT\\nInternal\\nState\\n1\\n2\\n3\\nT-1\\nAction\\nThought\\nObs\\nTimestep\\n1\\n2\\n3\\nT-1\\nT\\nT\\nGoal\\n. . .\\n. . .\\nReasoning Direction in ReAct\\n. . .\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n3\\nT-1\\nT-1\\nT-1\\nT\\nT\\nReasoning Direction in ReflAct\\nFigure 1: Comparison of reasoning influence in ReflAct\\nand ReAct. While ReAct focuses on the current ob-\\nservation and the next action at each timestep, ReflAct\\nreflects on the internal belief state and the task goal.\\ntegrates Chain-of-Thought (CoT) reasoning (Wei\\net al., 2022) with an action selection mechanism.\\nVarious extensions have been proposed to enhance\\nthis backbone by incorporating reflective iterations\\nor memory components to improve reasoning per-\\nformance (Shinn et al., 2024; Liu et al., 2023; Qiao\\net al., 2024). However, mounting evidence sug-\\ngests that ReAct and its variants often deliver lim-\\nited benefits and can even deteriorate performance,\\nespecially in complex, partially observable, or dy-\\nnamic environments (Ma et al., 2025; Chang et al.,\\n2024; Verma et al., 2024). These findings raise\\nquestions about the current direction of extending\\nthe basic ReAct reasoning-action framework.\\nIn this paper, we claim that true progress lies in\\nfundamentally redesigning the backbone reasoning\\nprocess itself, rather than adding complementary\\nmodules. Our analysis shows that the fundamental\\nproblem of current ReAct-based reasoning meth-\\nods is the frequent lack of proper grounding of\\ngenerated thoughts on the agent’s historical con-\\ntext or overarching objective. These misaligned\\nthoughts guide subsequent action choices. In dy-\\n1\\narXiv:2505.15182v1  [cs.CL]  21 May 2025'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 1}, page_content='namic or partially observable environments, such\\nreasoning errors compound over time, leading to\\nincreasingly divergent internal beliefs, deteriorated\\ndecision quality, and failed task execution.\\nTo address this limitation, we introduce ReflAct\\n(Reflect for Action), a new backbone framework\\nthat shifts the focus of the agent’s thought from pre-\\ndicting the next action to continuously reflecting\\non its current state in the context of the task goal,\\nas shown in Figure 1. Unlike previous approaches\\nthat layer reflective or memory modules onto the\\nReAct backbone (Shinn et al., 2024; Qiao et al.,\\n2024; Xiong et al., 2025), ReflAct does not rely\\non such additional components but replaces the\\ncore reasoning–action cycle itself. That is, at each\\ntimestep, the agent evaluates whether its current\\ntrajectory and situation align with its intended long-\\nterm objective before selecting an action. This\\nreflective thought mechanism enables early detec-\\ntion of potential deviations and facilitates timely\\nstrategy adjustments, as we shall see shortly. By\\ngrounding decisions in actual observations and\\nmaintaining continuous goal alignment, ReflAct\\nsubstantially reduces hallucination tendency and\\nenhances long-term strategic coherence.\\nWe implemented ReflAct using both open-\\nsource (Llama 3.1-8B/70B-Instruct (Grattafiori\\net al., 2024)) and proprietary (GPT-4o-mini/4o\\n(OpenAI, 2024)) LLMs, and evaluated it in three\\ntext-based environments: ALFWorld (Shridhar\\net al., 2021), ScienceWorld (Wang et al., 2022) and\\nJericho (Hausknecht et al., 2020), which require an\\nagent to decompose the goal and acts over a long\\ntime horizon under partial observability. Empirical\\nresults show that ReflAct helps the agent better\\nalign its internal beliefs with the environment and\\npromotes goal-consistent behavior. As a result, Re-\\nflAct significantly outperforms ReAct by 36.4%,\\n8.5%, and 38.1% on ALFWorld, ScienceWorld,\\nand Jericho, respectively. Notably, ReflAct also\\nsurpasses enhancement modules layered on top of\\nexisting backbones, demonstrating that revising the\\nreasoning process itself can be more effective than\\nadding new components.\\n2\\nPreliminaries\\nWe model the agent’s task in a language-based en-\\nvironment as a Partially Observable Markov Deci-\\nsion Process (POMDP) (Puterman, 1990), defined\\nas M = ⟨U, S, A, O, P, R⟩, where u ∈U is a\\ntask instruction, s ∈S is the (hidden) environment\\nstate, a ∈A is an action, o ∈O is an observation,\\nP is the transition function, and R is the reward\\nfunction. In our setting, U, A and O are expressed\\nin natural language.\\nThe ReAct Framework\\nThe ReAct framework\\n(Yao et al., 2023) enables LLM agents to solve\\ntasks through interleaved reasoning and action. To\\nincorporate reasoning steps (thoughts), we extend\\nthe above POMDP by including a thought space\\nT , where each thought τ ∈T represents a natural\\nlanguage reasoning step generated by the agent.\\nThen, this extended POMDP operates as follows.\\nGiven a task instruction u ∈U, the agent follows\\na policy πθ that alternates between generating a\\nthought as πthought\\nθ\\nand taking an executable action\\nas πact\\nθ . At each time step t, the agent receives an\\nobservation ot and forms a context ct = (ht, ot),\\nwhere ht = {u, τ1, a1, o1, . . . , τt, at} is the history\\nof previous interactions. Based on ct, the agent\\nsamples a thought from a context-conditioned dis-\\ntribution: τt ∼πthought\\nθ\\n(· | ct). This thought τt is\\nthen appended to the context to form an enriched\\ninput c′\\nt = ct ⊕τt, which is used to select the next\\naction: at ∼πact\\nθ (· | c′\\nt). The selected action at is\\nexecuted to the environment, resulting in the next\\nobservation ot+1. This reasoning–acting loop con-\\ntinues until the task is completed or a predefined\\ntime limit is reached.\\n3\\nRevisiting the Efficacy of Thought\\n3.1\\nHow Thought Impacts Action Selection\\nBasically the thought τt functions as a reweighting\\nmechanism for the action probability distribution\\nof the policy πact\\nθ\\nby enriching the context ct into\\nan augmented form: c′\\nt = ct ⊕τt.\\nWe analyzed this process in detail using a task\\nfrom ALFWorld (Shridhar et al., 2021), where the\\ntask is to find an apple, heat it, and place it in a\\ngarbage can. We implemented the policy πθ us-\\ning Llama-3.1-8B-Instruct (Grattafiori et al., 2024)\\nand compared two agent variants: the NoThinking\\nagent, which selects actions without intermediate\\nreasoning, and the ReAct agent, which generates a\\nreasoning step before each action. Figure 2 shows\\none instance of execution sequence. The sequence\\nstarts with the task description with initial obser-\\nvation, followed by two cycles of thought-action-\\nobservation, ending with observation \"You open\\nthe microwave 1. The microwave 1 is open. · · · \".\\nThen, in the next thought step, we tried each of four\\ncases: empty (i.e., no thought) and three thoughts\\n2'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 2}, page_content='in the middle of Figure 2, and observed the distri-\\nbution on actions in the next step.\\nObservation: You pick up the apple 1 from the countertop 1.\\nThought: Now I take an apple 1. Next, I need to go to a microwave 1 and heat it.\\nAction: go to microwave 1\\nObservation: The microwave 1 is closed.\\nThought: The microwave 1 is closed, so I need to open it first.\\nAction: open microwave 1\\nObservation: You open the microwave 1. The microwave 1 is open. In it, you see nothing.\\nThought: \\nAction: \\n[THOUGHT HERE]\\nTHOUGHT 1: I need to heat apple with microwave.\\nTHOUGHT 2: I think trying to cool the apple in the microwave might be a good idea.\\nTHOUGHT 3: I ate a hotdog this morning.\\nTask: heat some apple and put it in garbagecan.\\nTop 5 Action Probability\\nFigure 2: Changes in the action probability distribution\\nwhen modifying thought in the ALFWorld ‘heat some\\napple and put it in garbagecan’ task.\\nFirst, without any thought (NoThinking), the\\nagent assigns high probability to the heat action,\\nstill considering other actions such as ‘put’ and\\n‘go’ with non-negligible probabilities. Now, when\\na non-empty thought is provided, the next ac-\\ntion probability distribution is directly influenced:\\nTHOUGHT 1 relevant to the task sharpens the distri-\\nbution toward appropriate actions, leading to con-\\ntextually aligned selections. In contrast, THOUGHT\\n2 and THOUGHT 3, injecting incorrect or conflict-\\ning information, bias the distribution and increase\\nthe likelihood of inappropriate actions. As seen,\\nthought directly shapes the next action distribu-\\ntion, either reinforcing correct decisions or causing\\nmisalignment depending on its quality. When the\\nmodel is provided with a structured thought, it\\nrelies predominantly on that thought to drive de-\\ncision making, thereby significantly reducing its\\ndependence on the broader historical context.\\nTo quantify the overall impact of thought on the\\nagent’s decision-making process, we measured the\\nentropy of the agent’s action probability distribu-\\ntion across 134 tasks from ALFWorld. Specifically,\\nfor a given timestep t, the entropy is defined as\\nHNoThinking\\nt\\n= −\\nX\\na∈A\\nπact\\nθ (a | ct) log πact\\nθ (a | ct)\\nHReAct\\nt\\n= −\\nX\\na∈A\\nπact\\nθ (a | c′\\nt) log πact\\nθ (a | c′\\nt),\\nwhere c′\\nt = ct ⊕τt and τt ∼πthought\\nθ\\n(· | ct).\\nWe computed the entropy averaged over all\\ntimesteps and tasks, and the result is reported in\\nTable 1. As shown in the table, the NoThinking\\nTable 1: Average entropy of the action probability distri-\\nbution when performing 134 ALFWorld tasks using the\\nLlama-3.1-8B-Instruct with NoThinking and ReAct.\\nModel\\n¯\\nHNoThinking\\n¯\\nHReAct\\nLlama-3-1-8B-Instruct\\n1.23\\n0.30\\nagent exhibits mean entropy of 1.23, whereas the\\nReAct agent yields a significantly lower value of\\n0.30. This substantial reduction in entropy implies\\nthat conditioning the policy on thought leads to\\nmore confident and focused behavior.\\n3.2\\nThe Problem of Ungrounded Thought\\nSince action at is heavily influenced by thought\\nτt ∼πthought\\nθ\\n(· | ct), it is crucial that τt accu-\\nrately captures the core decision-relevant informa-\\ntion from the context ct = (ht, ot). If the thought\\nbecomes ungrounded, meaning it is disconnected\\nfrom the actual state, it can mislead the policy and\\ninduce a suboptimal or incorrect action.\\nFigure 3: Comparison of failure rates between NoThink-\\ning and ReAct on GPT-4o and Llama-3.1-8B-Instruct\\nTo assess the overall performance degradation\\nfrom ungrounded thought, we evaluated task fail-\\nure rates across 134 ALFWorld (Shridhar et al.,\\n2021) tasks using πθ realized with GPT-4o (Ope-\\nnAI, 2024) and Llama-3.1-8B-Instruct (Grattafiori\\net al., 2024). Figure 3 categorizes the outcomes\\ninto four groups: (1) only the NoThinking agent\\nfailed, (2) only the ReAct agent failed, (3) both\\nfailed, and (4) both succeeded. As shown in the fig-\\nure, incorporating thought can help the agent solve\\ntasks that would otherwise fail without it. However,\\nthought also introduces new risks, causing failures\\nthat could have been avoided without thought, even\\nin stronger models like GPT-4o.\\nTo see the cause of the ReAct agent’s failure, we\\nexamined a failure case of the ReAct agent in ALF-\\nWorld (Shridhar et al., 2021). As seen in Figure 4\\n(1), the agent is given a simple task: Find a soap\\nbar, take it and place it on the countertop. After\\ninteracting with a soap bottle 2 in cabinet 1, the\\nagent attempts to return to cabinet 1 to search for\\nthe soap bar even though it is not there, because\\nthe generated thought does not capture the current\\n3'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 3}, page_content='→ Although the soapbar is already in cabinet 1, the agent mistakenly \\nthought it needed to return there, which caused the problem. It didn\\'t \\nattempt other paths and ultimately failed the task.\\n(1) Thought on next action\\n(2) Reflection on the current state in relation to   \\n       the task goal\\n→ By reflecting the current state and task goal, it guides more \\npromising actions to reach the task goal, ultimately leading to task \\nsuccess.\\nALFWorld: put a clean soapbar in countertop.\\nWrong Thinking\\n...\\nObservation: You open the cabinet 1. The cabinet 1 is open. In it, you see a soapbottle 2.\\nThought: I found a soapbottle 2 in the cabinet 1, but I need a soapbar. I should check if there\\'s a soapbar in the cabinet 1 or other receptacles. Since I already opened the cabinet 1, I \\ncan check its content again.\\nAction: take soapbottle 2 from cabinet 1\\n\\nObservation: You pick up the soapbottle 2 from the cabinet 1.\\nThought: I took a soapbottle 2, but I need a soapbar. I should try to find a soapbar in other receptacles. Since I already have an object in my hand, I can try to put it somewhere and \\nthen search for a soapbar.\\nAction: put soapbottle 2 in cabinet 1\\n\\nObservation: You put the soapbottle 2 in/on the cabinet 1.\\n\\n\\nThought: I put the soapbottle 2 back in the cabinet 1. Now I can search for a soapbar. I\\'ll \\ngo to the cabinet 1 again to check if there\\'s a soapbar.\\nAction: go to cabinet 1\\n\\nObservation: Nothing happens.\\nThought: Since \"Nothing happened\", my previous action was invalid. I should try to go to \\ncabinet 1 again, but this time, I should also check if there\\'s a soapbar in the cabinet 1.\\nAction: go to cabinet 1\\n\\nObservation: Nothing happens.\\nReflection: Currently, I am at cabinet 1, not holding anything, and I still haven\\'t found \\nthe soap bar to place on the countertop.\\nAction: go to cabinet 2\\nFigure 4: In the ALFWorld task ‘put a clean soapbar in countertop’, the agent picks up a soapbottle from cabinet 1\\nand puts it back, (1) while planning the next action, it redundantly tries to go back to cabinet 1 and fails, (2) after\\nreflecting on the state and goal, it moves elsewhere and succeeds.\\nsituation in the context of goal properly from its\\nobservation history. This redundant and illogical\\nbehavior leads to a loop, and the agent ultimately\\nfails to complete the task. A failure case in Sci-\\nenceWorld is provided in Figure 9 in Appendix B.\\nFrom the examples, we see that the agent fails\\ndue to two major reasoning limitations:\\n(1) A lack of grounding in its internal state. The\\nagent fails to maintain a coherent internal state,\\nleading to inconsistency, e.g., revisiting a loca-\\ntion it already visited or falsely assuming it is\\nholding an object.\\n(2) Short-sighted planning. The ReAct agent\\ntypically exhibits short-sighted planning, mak-\\ning decisions that appear locally plausible but\\ndisregard the long-term task goal.\\nWe recognize that these two shortcomings stem\\nfrom incorrect guidance for the agent’s reasoning\\nprocess although the agent has better reasoning\\ncapability. Indeed, for the same failure scenario in\\nFigure 4 left branch, we input a reasoning guidance\\nsentence different from that of ReAct, to focus not\\non predicting the next step but assess the agent’s\\ncurrent state in relation to the task goal, as seen\\nin Figure 4 right branch. Now, it is seen that the\\nagent can better align its action with the overall\\nobjective by reflecting on what it currently knows\\nand what it aims to achieve. This is also valid\\nfor the ScienceWorld failure case in Figure 9 in\\nAppendix B.\\n4\\nProposed Method: ReflAct\\nIn the LLM POMDP framework, a thought τt ∈T\\nshould be generated so that it leads to the selec-\\ntion of an action at that maximizes the expected\\nlong-term return when used to condition the ac-\\ntion policy πact\\nθ , where the long-term return is de-\\nfined as Gt = P∞\\nk=0 γkRt+k with discount factor\\nγ ∈[0, 1). Here, Rt+k is the immediate reward at\\ntime t + k. Thus, the optimal thought τ ∗\\nt can be\\ndefined as\\nτ ∗\\nt = arg max\\nτ∈T\\nEa∼πact\\nθ (·|ct⊕τ) [E [Gt | st, a]] ,\\nwhere ct denotes the current context and ⊕de-\\nnotes concatenation. To maximize the expected\\nlong-term return, the thought τt should not be gen-\\nerated from the observation solely to decide the\\nnext action. Instead, it should be formed with con-\\nsideration of the final task goal at every time step,\\nas illustrated in Figure 1. In this way, the agent\\ncan rely on thought for action generation without\\ndeviating from a goal-reaching path. Furthermore,\\nsince the environment is partially observable and\\nthe true state st is not directly accessible, the agent\\nmust rely on an internal belief state inferred from\\nits interaction history. So, the generated thought\\nshould make this belief more explicit and stable,\\nwhile encoding task-relevant reasoning that effec-\\ntively guides the downstream policy toward the\\nlong-term objective.\\nTo achieve the generation of such thoughts, we\\ndo not use an additional module but exploit the\\nLLM agent’s reasoning capability maximally. For\\n4'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 4}, page_content='this, we redesign a new thought generation instruc-\\ntion to better guide thought generation as follows:\\nInstruction for ReflAct\\nYou should first reflect on the agent’s state in rela-\\ntion to the task goal, and then output the action for\\nthis turn.\\nIn this new design, we have the explicit guiding\\nterms ‘agent’s state’, ‘task goal’ and their connec-\\ntion term ‘in relation to’ to realize the desired state\\ndiagram of thought dependency in the lower part\\nof Figure 1. Following this instruction, the agent\\nengages in reflective reasoning to gain a clearer\\nunderstanding of both the current situation and the\\nintended goal. We refer to so-generated thought\\nas reflection and name the new reflection-action\\nprocess ReflAct. To formalize this, we define a\\nreflection space K, where each reflection k ∈K\\nis a structured representation that aims to explic-\\nitly encode both the agent’s internal belief state M\\nand the task goal G. The belief state captures the\\nagent’s current understanding of the state based on\\nits interaction history, whereas the goal component\\nprovides a concise summary of what the agent is\\ntrying to achieve. By explicitly representing both\\nin the reflection, ReflAct allows the agent to con-\\ndition its subsequent decision-making on a more\\ncoherent and goal-aligned internal context.\\nExample of Thought vs Reflection Before Action\\nThought: Now I find a spraybottle 2. Next, I need to\\ntake it.\\nReflection: Currently, I am at cabinet 2 and have\\nfound a spraybottle 2, which brings me closer to\\ncompleting the task of placing it on the toilet.\\nIn addition, we incorporate one-shot examples\\nbased on the tasks from Yao et al. (2023); Xiong\\net al. (2025) modified with Reflections on the\\nagent’s state in relation to the task goal, gener-\\nated by GPT-4o-mini (OpenAI, 2024). Above, we\\npresent an example describing the modification\\nfrom Thought to Reflection. The complete set of\\none-shot examples is provided in Appendix H.\\n5\\nRelated Works\\nBuilding on CoT reasoning (Wei et al., 2022), nu-\\nmerous approaches attempted to enhance LLM\\nagent capability. ReAct (Yao et al., 2023) pio-\\nneered the interleaving of reasoning with action\\nsteps for interactive environments, while Plan-and-\\nSolve (Wang et al., 2023) introduced higher-level\\nplanning in the initial stage.\\nRecent enhance-\\nment modules sought to improve ReAct’s CoT\\nthrough various mechanisms: Reflexion (Shinn\\net al., 2024) through post-task analysis of fail-\\nures after task completion, WKM (Qiao et al.,\\n2024), MPO (Xiong et al., 2025), and DC (Suz-\\ngun et al., 2025) via external memory of envi-\\nronment knowledge, and RAFA (Liu et al., 2023)\\nby generating and evaluating future possible tra-\\njectory predictions. However, when the ReAct\\nbackbone incorrectly grounds past observations,\\nall these approaches suffer from degraded perfor-\\nmance. Therefore, ReflAct retouches the reasoning\\nprocess itself to enable more grounded and goal-\\naligned decision making. In our experiments, we\\nwill validate the importance of this approach com-\\npared to the design of enhancement modules, as\\nwell as its synergy with them. Additional related\\nworks are discussed in the Appendix A.\\n6\\nExperiments\\n6.1\\nExperimental Settings\\nBenchmarks.\\nWe benchmarked ReflAct on three\\nwidely used text-based environments: ALFWorld\\n(Shridhar et al., 2021), ScienceWorld (Wang et al.,\\n2022), and Jericho (Hausknecht et al., 2020). ALF-\\nWorld evaluates embodied agents on household\\ntasks, ScienceWorld assesses procedural and scien-\\ntific reasoning in educational scenarios, and Jeri-\\ncho tests agents in classic interactive fiction games\\nthat require commonsense reasoning and memory.\\nFor evaluation, ALFWorld uses binary task success,\\nwhile ScienceWorld and Jericho provide dense re-\\nward signals, enabling evaluation based on both\\nsuccess rate and average reward, calculated as the\\nmean reward across all tasks. Additional bench-\\nmark details are provided in Appendix C.\\nAgent Models.\\nWe use GPT-4o and GPT-4o-mini\\n(OpenAI, 2024), and Llama-3.1-8B/70B-Instruct\\n(Grattafiori et al., 2024) as underlying models.\\nGPT-4o variants serve as proprietary models, while\\nLlama-3.1-Instruct variants represent open-source\\ncounterparts, each with large and small sizes.\\n6.2\\nComparison with Prior Methods\\nBaselines.\\nWe first compare ReflAct with three\\nreasoning frameworks. Details for each can be\\nfound in Appendix D.1.\\n(1) NoThinking (Ma et al., 2025): The agent gen-\\nerates an action directly at each time step without\\nany reasoning step.\\n5'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 5}, page_content='Table 2: Performance comparison of ReflAct with NoThinking, ReAct, and Plan-and-Act across ALFWorld,\\nScienceWorld, and Jericho. SR and AR denote success ratio and average reward, respectively. Values in parentheses\\nindicate percentage improvement over the NoThinking baseline.\\nModel\\nPrompting\\nALFWorld\\nScienceWorld\\nJericho\\nAverage\\nSR\\nAR\\nSR\\nAR\\nSR\\nGPT-4o\\nNoThinking\\n76.1\\n67.4\\n50.2\\n27.8\\n10.0\\n46.3\\nReAct\\n85.1\\n68.7\\n55.9\\n50.4\\n20.0\\n56.0 (+21.0%)\\nPlan-and-Act\\n85.8\\n68.7\\n55.0\\n45.6\\n20.0\\n55.0 (+18.8%)\\nReflAct\\n93.3\\n68.9\\n57.8\\n53.2\\n35.0\\n61.6 (+33.1%)\\nGPT-4o-mini\\nNoThinking\\n43.3\\n42.3\\n21.8\\n18.8\\n5.0\\n26.2\\nReAct\\n53.0\\n49.1\\n37.0\\n29.8\\n15.0\\n36.8 (+40.2%)\\nPlan-and-Act\\n59.0\\n51.8\\n35.5\\n37.1\\n15.0\\n39.7 (+51.1%)\\nReflAct\\n66.4\\n55.4\\n37.0\\n45.4\\n20.0\\n44.8 (+70.9%)\\nLlama-3-1-8B\\n-Instruct\\nNoThinking\\n21.6\\n29.9\\n14.2\\n10.0\\n0.0\\n15.1\\nReAct\\n29.1\\n43.0\\n27.5\\n12.8\\n0.0\\n22.5 (+48.5%)\\nPlan-and-Act\\n30.6\\n34.2\\n14.7\\n10.6\\n0.0\\n18.0 (+19.0%)\\nReflAct\\n60.5\\n47.2\\n33.2\\n20.9\\n10.0\\n34.4 (+126.9%)\\nLlama-3-1-70B\\n-Instruct\\nNoThinking\\n53.7\\n65.6\\n46.4\\n27.4\\n5.0\\n39.6\\nReAct\\n81.3\\n66.4\\n53.1\\n33.9\\n10.0\\n48.9 (+23.5%)\\nPlan-and-Act\\n81.3\\n67.7\\n52.6\\n29.6\\n10.0\\n48.2 (+21.8%)\\nReflAct\\n83.6\\n73.7\\n58.8\\n44.5\\n20.0\\n56.1 (+41.6%)\\nFigure 5: A comparison of ReAct, ReflAct, and various verbalization strategies (state, goal, state+goal, and\\nstate+goal with next-action reasoning), using Llama-3.1-8B-Instruct as the agent model. Bars represent success\\nrate; the red dashed line indicates average reward.\\n(2) ReAct (Yao et al., 2023): The agent first reasons\\nabout the next action at each time step and then\\ngenerates an action.\\n(3) Plan-and-Act: In addition to NoThinking and\\nReAct, we designed another reasoning framework\\ninspired by Plan-and-Solve (Wang et al., 2023) for\\ncomparison. Here, the agent is instructed at the first\\ntimestep (t = 1) to ‘plan your approach to the task,\\nand then output the action.’ It performs reasoning\\nonly at this step and outputs actions without further\\nthoughts in subsequent timesteps.\\nResults.\\nTable 2 presents the performance of\\nReflAct compared with the NoThinking, ReAct,\\nand Plan-and-Act baselines across ALFWorld, Sci-\\nenceWorld, and Jericho. As shown in the table, the\\nReAct agent outperforms the NoThinking agent,\\nhighlighting the effectiveness of the Thinking be-\\nfore Action framework. Plan-and-Act, which be-\\ngins with a single planning step and then executes\\nactions directly, performs comparably or slightly\\nbetter than ReAct in stronger models like GPT-\\n4o. This suggests that when a model has enough\\ncapacity, initial goal-based reasoning is effective,\\nand flawed intermediate reasoning may offer little\\nbenefit. However, in weaker models like Llama,\\nPlan-and-Act underperforms because these models\\nstruggle to retain and follow the initial plan. In\\ncontrast, ReflAct, which reflects on both the state\\nand the goal at every timestep, consistently out-\\nperforms all the baseline reasoning frameworks\\nregardless of backbone model or task. Notably,\\nReflAct achieved performance improvements of\\n77.9%, 25.9%, and 101.1% over NoThinking in\\nALFWorld, ScienceWorld, and Jericho, respec-\\ntively, and improvements of 36.4%, 8.5%, and\\n38.1% over ReAct in the same environments.\\nImportance of Reflection over Simply Stating.\\nTo verify the source of ReflAct’s superior perfor-\\n6'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 6}, page_content='mance gain, we conducted an ablation study. Re-\\nflAct reflects on the agent’s state in relation to the\\ntask goal, so we compared this with variants in\\nwhich the agent simply verbalizes its state, its goal,\\nor both, without engaging in reflection.\\nAs shown in Figure 5, we evaluated four settings:\\nthe agent verbalizes (1) the current state, (2) the\\ntask goal, (3) both the state and the goal, and (4) the\\nstate and goal while also reasoning about the next\\naction. The results indicate that merely stating the\\nstate or goal underperforms compared to the ReAct\\nbaseline. Adding an explicit next-action thought\\nin addition to verbalizing the state and goal yields\\nperformance gains in ALFWorld compared to Re-\\nAct, but still falls short of ReAct in ScienceWorld\\nand Jericho. In contrast, ReflAct, which explic-\\nitly reflects on the relationship between the state\\nand the goal, demonstrates a substantially greater\\nperformance gain. These findings suggest that re-\\nflection, specifically reasoning about the state in\\nthe context of the goal, is more effective than sim-\\nply verbalizing the state or the goal.\\n6.3\\nReflAct with Enhancement Modules\\nWe examine layering enhancement modules on top\\nof ReflAct. We consider Reflexion (Shinn et al.,\\n2024), the use of post-task reflection in ReAct to\\nimprove planning, and WKM (Qiao et al., 2024),\\nwhich incorporates a parametric world model into\\nReAct. Discussion on RAFA (Liu et al., 2023),\\nwhich focuses on long-sighted planning via next-\\nstate prediction, and MPO (Xiong et al., 2025),\\nwhich improves planning through online prefer-\\nence learning, can be found in Appendix F.\\n6.3.1\\nReflAct and Reflexion\\nReflexion (Shinn et al., 2024) performs post-task\\nreflection by analyzing failed trajectories and gen-\\nerating improvement plans for future trials. Since\\npost-task reflection operates independently of the\\nunderlying reasoning process, we analyze its im-\\npact when combined with three reasoning frame-\\nworks: NoThinking, ReAct, and ReflAct.\\nFigure 6 shows the results of applying Reflex-\\nion to each backbone in ALFWorld and Jericho.\\nWe followed Shinn et al. (2024) in applying post-\\ntask reflection after each trial, repeating this for\\nthree trials. The results show that post-task re-\\nflection generally improves performance across all\\nbase agents, except Llama NoThinking and ReAct\\nin Jericho. However, even after applying Reflex-\\nion, the NoThinking and ReAct agents still fall\\nFigure 6: Success rate change with Reflexion post-task\\nreflection (NoThinking, ReAct, ReflAct).\\nshort of ReflAct’s trial 0 performance. This high-\\nlights that when the initial reasoning backbone is\\nweak, even repeated feedback across trials provides\\nonly limited benefit. Although post-task reflection\\naids reasoning by analyzing failures, enhancing in-\\ntask reflection through a stronger backbone proves\\nmore fundamental. Notably, the GPT-4o ReflAct\\nagent with Reflexion achieved an unprecedented\\n94.8% success rate in ALFWorld, bringing house-\\nhold robots one step closer to reality, given suffi-\\ncient hardware support.\\n6.3.2\\nReflAct and WKM\\nWKM (Qiao et al., 2024) improves LLM agents’\\ndecision-making in interactive environments by\\nusing Task Knowledge for global planning and\\nState Knowledge for local context. Its paramet-\\nric knowledge model, fine-tuned on knowledge-\\naugmented trajectories, enables context-aware\\ndecision-making by referencing past similar situa-\\ntions. WKM learns and utilizes an external knowl-\\nedge model in contrast to ReflAct, which intends\\nto perform internal state modeling within the rea-\\nsoning backbone.\\nWe applied WKM to ReAct and further exam-\\nined a scenario where state knowledge is placed\\nimmediately before action, replacing the thought,\\nto guide the action. This allows us to assess the\\nimpact of explicit state knowledge compared to\\nReflAct’s internal state modeling. Figure 7 shows\\nperformance related to WKM. Applying WKM to\\nReAct results in a performance improvement, but\\nit still falls short of ReflAct. Replacing the thought\\nstep with state knowledge to directly guide the ac-\\ntion actually degrades performance, highlighting\\nthe side effect of incorrect guidance from the ex-\\n7'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 7}, page_content='Figure 7: Performance: ReflAct, NoThinking, ReAct,\\nand ReAct+WKM with thought replaced by WKM state\\nknowledge (Llama-3.1-8B-Instruct as agent)\\nternal model. This suggests that encouraging the\\nmodel to perform internal state modeling on its\\nown can be more effective than relying on state\\nknowledge generated by an external model.\\n6.4\\nFurther Discussion on ReflAct’s Ability\\nIn this section, we analyze how ReflAct success-\\nfully solves tasks, and in Appendix G, we compare\\nthe hallucinated action ratio and token length be-\\ntween ReflAct and baseline reasoning frameworks.\\n6.4.1\\nFailure Ratio Comparison Between\\nReasoning Frameworks\\nBuilding on the discussion of Figure 3 in Section\\n3.2, we analyze the proportion of tasks failed by\\nthe NoThinking, ReAct, and ReflAct agents across\\n134 tasks in the ALFWorld domain.\\nFigure 8: Failure ratio comparison diagram of NoThink-\\ning, ReAct, and ReflAct on 134 ALFWorld tasks, using\\nGPT-4o and Llama-3.1-8B-Instruct as agent models.\\nFigure 8 illustrates the failure distribution\\namong the three agents. Consistent with earlier\\nobservations, the NoThinking agent accounts for\\nthe largest number of unique failures, especially in\\ntasks where it alone fails. The ReAct agent, while\\nincorporating reasoning, introduces additional fail-\\nure cases not observed in NoThinking. This sug-\\ngests that ungrounded or incorrect reasoning can\\nlead to novel and potentially harmful errors. No-\\ntably, there are no tasks in which only the ReflAct\\nagent fails. ReflAct fails only in cases where other\\nagents also fail, and does not introduce new failure\\nmodes. This highlights the benefit of reflection\\ngrounded in the agent’s state and task goal, sug-\\ngesting that reflective reasoning contributes to safer\\nand more reliable decision-making in LLM agents.\\n6.4.2\\nReflAct Self-Corrects Automatically\\nLLM agents, especially when operating in unfa-\\nmiliar environments with only partially observable\\ninformation, are prone to making mistakes. There-\\nfore, it is essential that they possess the ability to\\nself-correct by identifying the cause of their errors\\nand adjusting their behavior accordingly to return\\nto a correct course of action. The example below\\nby a ReflAct agent demonstrates that ReflAct main-\\ntains an internal belief over the current state and\\ncontinuously aligns its decision-making with the\\ntask goal, enabling the agent to recognize mistakes\\nand flexibly recover from them, ultimately guiding\\nitself back onto the correct path.\\nYour task is cool some lettuce and\\nput it in countertop.\\n...\\nAction:\\ntake lettuce 1 from countertop 2\\nObs:\\nYou pick up the lettuce 1 from the\\ncountertop 2.\\nReflection:\\nI am at countertop 2, holding\\nlettuce 1.\\nI need to cool the lettuce\\nbefore putting it on the countertop to\\ncomplete the task.\\nAction:\\ncool lettuce 1 with fridge 1\\nObs:\\nNothing happens.\\nReflection:\\nI am at countertop 2, holding\\nlettuce 1.\\nThe action to cool the lettuce\\nwith the fridge did not work because I need\\nto be at the fridge to perform that action.\\nAction:\\ngo to fridge 1\\nObs:\\nThe fridge 1 is open.\\nIn it, ...\\nReflection:\\nI am at fridge 1, holding\\nlettuce 1.\\nI can cool the lettuce now that\\nI’m at the fridge.\\nAction:\\ncool lettuce 1 with fridge 1\\nObs:\\nYou cool the lettuce 1 using the\\nfridge 1.\\n...\\n7\\nConclusion\\nWe have proposed ReflAct, a reflection-based rea-\\nsoning framework that addresses key limitations\\nof ReAct. While ReAct focuses on next-action\\nthinking, it often fails to maintain coherent internal\\nbeliefs about the environment and goal, leading\\nto poor decisions in complex, partially observable\\ntasks. In contrast, ReflAct emphasizes ongoing re-\\nflection on state and goal, enabling more grounded\\nand reliable decision making. Our experiments\\nshow that ReflAct consistently outperforms ReAct\\nand other baselines, demonstrating the value of re-\\nflection in long-horizon reasoning. We hope this\\nwork inspires further research into more robust\\nand informative reasoning guidance for intelligent\\nagents.\\n8'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 8}, page_content='Limitations\\nWhile ReflAct shows strong performance in in-\\nteractive agent environments, its applicability to\\nother domains such as mathematics and coding\\nremains unexplored. These tasks pose unique chal-\\nlenges: mathematics requires step-by-step deduc-\\ntion, while programming demands consistency in\\nlogic, state, and syntax. Extending ReflAct to these\\nareas may require adapting its reflection mecha-\\nnism to better align the current state with task-\\nspecific goals. Incorporating structured reason-\\ning that explicitly supports goal-state alignment\\ncould enhance performance, and we consider this\\na promising direction for future work.\\nIn addition, as discussed in Appendix G, Re-\\nflAct results in a modest increase in token length\\ncompared to ReAct. To address this, it is worth ex-\\nploring more efficient formulations that retain the\\nbenefits of state-goal reflection while reducing ver-\\nbosity. Possible approaches include compressing\\nreflection outputs, using more concise representa-\\ntions of reasoning steps, or integrating summariza-\\ntion modules to maintain informativeness within a\\nsmaller token budget.\\nFinally, there is growing interest in enhancing\\nreasoning with external modules. Incorporating\\nsuch components into ReflAct could further im-\\nprove its reflection process. For example, an exter-\\nnal verifier might evaluate reflected goals or sug-\\ngest fixes for inconsistencies. Exploring such hy-\\nbrid architectures remains a promising direction\\nfor future research.\\nEthical Statements\\nWhile LLM Agents represent powerful tools with\\nsignificant practical applications, they also pose\\nsubstantial risks if misused or deployed without\\nproper safeguards. Of particular concern is their\\ntendency to hallucinate or generate ungrounded rea-\\nsoning, which can lead to unreliable or potentially\\nharmful decisions in real-world contexts. This re-\\nsearch aims to address these challenges by develop-\\ning more grounded decision-making frameworks\\nthat enhance reliability and reduce hallucination.\\nBy focusing on improving the alignment between\\nthe agent’s internal beliefs and the actual environ-\\nment state, our work contributes to the broader\\ngoal of creating more trustworthy AI systems that\\ncan safely operate in complex, partially observable\\nenvironments while maintaining consistent goal-\\ndirected behavior.\\nReferences\\nMa Chang, Junlei Zhang, Zhihao Zhu, Cheng Yang,\\nYujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng\\nKong, and Junxian He. 2024. Agentboard: An an-\\nalytical evaluation board of multi-turn llm agents.\\nAdvances in Neural Information Processing Systems,\\n37:74325–74362.\\nYuri Chervonyi, Trieu H Trinh, Miroslav Olšák, Xi-\\naomeng Yang, Hoang Nguyen, Marcelo Menegali,\\nJunehyuk Jung, Vikas Verma, Quoc V Le, and Thang\\nLuong. 2025. Gold-medalist performance in solv-\\ning olympiad geometry with alphageometry2. arXiv\\npreprint arXiv:2502.03544.\\nAli Forootani. 2025. A survey on mathematical rea-\\nsoning and optimization with large language models.\\narXiv preprint arXiv:2503.17726.\\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-\\nDahle, Aiesha Letman, Akhil Mathur, Alan Schelten,\\nAlex Vaughan, and 1 others. 2024. The llama 3 herd\\nof models. arXiv preprint arXiv:2407.21783.\\nDavid Ha and Jürgen Schmidhuber. 2018. World mod-\\nels. arXiv preprint arXiv:1803.10122.\\nDanijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mo-\\nhammad Norouzi. 2019. Dream to control: Learn-\\ning behaviors by latent imagination. arXiv preprint\\narXiv:1912.01603.\\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timo-\\nthy Lillicrap. 2025. Mastering diverse control tasks\\nthrough world models. Nature, pages 1–7.\\nShibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong,\\nZhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023.\\nReasoning with language model is planning with\\nworld model. arXiv preprint arXiv:2305.14992.\\nMatthew Hausknecht, Prithviraj Ammanabrolu, Marc-\\nAlexandre Côté, and Xingdi Yuan. 2020. Interactive\\nfiction games: A colossal adventure. In Proceedings\\nof the AAAI Conference on Artificial Intelligence,\\nvolume 34, pages 7903–7910.\\nMatthew J Hausknecht and Peter Stone. 2015. Deep\\nrecurrent q-learning for partially observable mdps.\\nIn AAAI fall symposia, volume 45, page 141.\\nLeslie Pack Kaelbling, Michael L Littman, and An-\\nthony R Cassandra. 1998. Planning and acting in\\npartially observable stochastic domains. Artificial\\nintelligence, 101(1-2):99–134.\\nJacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol\\nHausman, Brian Ichter, Pete Florence, and Andy\\nZeng. 2023.\\nCode as policies: Language model\\nprograms for embodied control. In 2023 IEEE In-\\nternational Conference on Robotics and Automation\\n(ICRA), pages 9493–9500. IEEE.\\n9'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 9}, page_content='Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo,\\nShuqi Ke, Boyi Liu, and Zhaoran Wang. 2023. Rea-\\nson for future, act for now: A principled framework\\nfor autonomous llm agents with provable sample\\nefficiency. arXiv preprint arXiv:2309.17382.\\nWenjie Ma, Jingxuan He, Charlie Snell, Tyler Griggs,\\nSewon Min, and Matei Zaharia. 2025. Reasoning\\nmodels can be effective without thinking.\\narXiv\\npreprint arXiv:2504.09858.\\nJunhyuk Oh, Valliappa Chockalingam, Honglak Lee,\\nand 1 others. 2016. Control of memory, active per-\\nception, and action in minecraft. In International\\nconference on machine learning, pages 2790–2799.\\nPMLR.\\nOpenAI. 2024. Hello gpt-4o.\\nMartin L Puterman. 1990. Markov decision processes.\\nHandbooks in operations research and management\\nscience, 2:331–434.\\nShuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu,\\nXiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie,\\nFei Huang, and Huajun Chen. 2024. Agent planning\\nwith world knowledge model. In The Thirty-eighth\\nAnnual Conference on Neural Information Process-\\ning Systems.\\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\\npher D Manning, Stefano Ermon, and Chelsea Finn.\\n2024. Direct preference optimization: Your language\\nmodel is secretly a reward model. Advances in Neu-\\nral Information Processing Systems, 36.\\nAndres Rodriguez, Ronald Parr, and Daphne Koller.\\n1999. Reinforcement learning using approximate\\nbelief states. Advances in Neural Information Pro-\\ncessing Systems, 12.\\nJulian Schrittwieser, Ioannis Antonoglou, Thomas Hu-\\nbert, Karen Simonyan, Laurent Sifre, Simon Schmitt,\\nArthur Guez, Edward Lockhart, Demis Hassabis,\\nThore Graepel, and 1 others. 2020. Mastering atari,\\ngo, chess and shogi by planning with a learned model.\\nNature, 588(7839):604–609.\\nNoah Shinn, Federico Cassano, Ashwin Gopinath,\\nKarthik Narasimhan, and Shunyu Yao. 2024. Re-\\nflexion: Language agents with verbal reinforcement\\nlearning. Advances in Neural Information Process-\\ning Systems, 36.\\nKeisuke Shirai, Cristian C Beltran-Hernandez, Masashi\\nHamaya, Atsushi Hashimoto, Shohei Tanaka, Kento\\nKawaharazuka, Kazutoshi Tanaka, Yoshitaka Ushiku,\\nand Shinsuke Mori. 2024. Vision-language inter-\\npreter for robot task planning. In 2024 IEEE Inter-\\nnational Conference on Robotics and Automation\\n(ICRA), pages 2051–2058. IEEE.\\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote,\\nYonatan Bisk,\\nAdam Trischler,\\nand Matthew\\nHausknecht. 2021. {ALFW}orld: Aligning text and\\nembodied environments for interactive learning. In\\nInternational Conference on Learning Representa-\\ntions.\\nYifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian\\nLi, and Bill Yuchen Lin. 2024.\\nTrial and error:\\nExploration-based trajectory optimization of llm\\nagents. In Proceedings of the 62nd Annual Meet-\\ning of the Association for Computational Linguistics\\n(Volume 1: Long Papers), pages 7584–7600.\\nMirac Suzgun, Mert Yuksekgonul, Federico Bianchi,\\nDan Jurafsky, and James Zou. 2025. Dynamic cheat-\\nsheet: Test-time learning with adaptive memory.\\narXiv preprint arXiv:2504.07952.\\nMudit Verma, Siddhant Bhambri, and Subbarao Kamb-\\nhampati. 2024. On the brittle foundations of react\\nprompting for agentic large language models. arXiv\\npreprint arXiv:2405.13966.\\nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi\\nLan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023. Plan-\\nand-solve prompting: Improving zero-shot chain-\\nof-thought reasoning by large language models. In\\nProceedings of the 61st Annual Meeting of the As-\\nsociation for Computational Linguistics (Volume 1:\\nLong Papers), pages 2609–2634.\\nRuoyao Wang, Peter Jansen, Marc-Alexandre Côté, and\\nPrithviraj Ammanabrolu. 2022. Scienceworld: Is\\nyour agent smarter than a 5th grader? In Proceedings\\nof the 2022 Conference on Empirical Methods in\\nNatural Language Processing, pages 11279–11298.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\\nand 1 others. 2022. Chain-of-thought prompting\\nelicits reasoning in large language models. Advances\\nin neural information processing systems, 35:24824–\\n24837.\\nYiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang,\\nand Qingyun Wu. 2024. Stateflow: Enhancing llm\\ntask-solving through state-driven workflows. In First\\nConference on Language Modeling.\\nWeimin Xiong, Yifan Song, Qingxiu Dong, Bingchan\\nZhao, Feifan Song, Xun Wang, and Sujian Li. 2025.\\nMpo: Boosting llm agents with meta plan optimiza-\\ntion. arXiv preprint arXiv:2503.02682.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\\nShafran, Karthik R Narasimhan, and Yuan Cao. 2023.\\nReact: Synergizing reasoning and acting in language\\nmodels. In The Eleventh International Conference\\non Learning Representations.\\nWangchunshu Zhou, Yuchen Eleanor Jiang, Long Li,\\nJialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang,\\nJing Chen, Ruipu Wu, Shuai Wang, and 1 oth-\\ners. 2023.\\nAgents: An open-source framework\\nfor autonomous language agents.\\narXiv preprint\\narXiv:2309.07870.\\n10'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 10}, page_content='A\\nExpanded Related Works\\nBelief-State Modeling in RL.\\nReinforcement\\nLearning (RL) has aimed to endow agents with\\nan internal state representation that captures all\\nrelevant information from past observations (Ro-\\ndriguez et al., 1999). In partially observable en-\\nvironments, this often takes the form of a belief\\nstate, a probability distribution over possible world\\nstates, which is updated as new observations are\\nreceived. Kaelbling et al. (1998) describe plan-\\nning as tracking a sufficient statistic of the history\\n(i.e., the belief), which serves as the agent’s core\\nstate for action selection. This approach has been\\nfurther developed in deep RL, where agents learn\\nto track belief states using recurrent neural net-\\nworks (Hausknecht and Stone, 2015), memory-\\naugmented architectures (Oh et al., 2016), and\\nworld models (Ha and Schmidhuber, 2018). Vari-\\nous studies (Hafner et al., 2019; Schrittwieser et al.,\\n2020; Hafner et al., 2025) have demonstrated the ef-\\nfectiveness of belief state modeling, enabling more\\neffective planning and reliable decision-making.\\nState Representations in LLMs.\\nSimilar to\\nbelief-state modeling in RL, recent work on LLMs\\nhas explored how internal or external state rep-\\nresentations can support reasoning and planning.\\nOne line of research adopts an extrinsic model-\\ning approach, inspired by the Code-as-Policies\\nparadigm (Liang et al., 2023), in which observa-\\ntions are structured into symbolic formats such as\\ntextual summaries, PDDL, or finite state machines,\\nand explicitly injected into the prompt. These de-\\nsigns enhance grounding and interpretability in\\nrobotic tasks, but they typically rely on predefined\\ncode or external modules to maintain and update\\nthe state representation (Hao et al., 2023; Shirai\\net al., 2024; Wu et al., 2024).\\nWhile prior work investigates whether LLMs\\ninternally form task-relevant abstractions, ReflAct\\nadvances this line of research by explicitly prompt-\\ning models to articulate and reflect on such ab-\\nstractions. By encouraging LLMs to generate and\\nreason over goal-conditioned state representations,\\nReflAct facilitates more grounded and efficient\\ndecision-making during interaction.\\nBackbone Reasoning Frameworks.\\nThe emer-\\ngence of LLMs has introduced new agent design\\nparadigms, especially via prompting-based reason-\\ning strategies. CoT prompting (Wei et al., 2022)\\nshowed that models can handle complex tasks by\\noutlining intermediate steps. ReAct (Yao et al.,\\n2023) extended this to interactive settings by in-\\nterleaving reasoning and action, while Plan-and-\\nSolve (Wang et al., 2023) added high-level plan-\\nning before stepwise execution. However, recent\\nstudies (Ma et al., 2025) argue that these CoT-\\nbased approaches are often token-inefficient and\\nprone to hallucinations. We attribute these reliabil-\\nity issues to the absence of an explicit belief state.\\nReflAct addresses this by maintaining and reflect-\\ning belief states to guide reasoning and improve\\nboth efficiency and reliability.\\nEnhancement Reasoning Modules.\\nRecently,\\na growing body of research has explored add-on\\nor post-processing modules that operate on top of\\nreasoning backbones to enhance reasoning capa-\\nbilities. Reflexion (Shinn et al., 2024) improves\\nperformance by analyzing failed trajectories and\\nstoring insights for future use. WKM (Qiao et al.,\\n2024) mitigates hallucinations by grounding deci-\\nsions in a learned world model that reflects realistic\\ndynamics. RAFA (Liu et al., 2023) strengthens the\\nreasoning-acting link by imagining future trajecto-\\nries and evaluating them with separate Model and\\nCritic components, forming a structured loop of\\nplanning, action, and feedback. Unlike these ap-\\nproaches, ReflAct is not layered on top of a reason-\\ning backbone but instead redefines the backbone\\nitself, enabling more efficient reasoning.\\nB\\nAnother Case of the Problem of\\nUngrounded Thought\\nIn addition to the discussion of the ReAct agent’s\\nfailure case in Figure 4 in Section 3.2, we examine\\nanother failure case in ScienceWorld (Wang et al.,\\n2022). As shown in Figure 9 (1), the agent is\\ntasked with boiling lead. To do this, the agent must\\nfind lead, transfer it to a suitable heat source, and\\nthen boil it. During the previous steps, the agent\\nsuccessfully located the lead in the workshop. Now,\\nthe agent must carry it to the foundry. However, the\\nagent mistakenly assumes that it is already holding\\nthe lead and proceeds with the next action based\\non this false assumption, ultimately resulting in a\\nhallucination.\\nIn the same situation, similar to the discussion\\nin Section 3.2, we replace the thought with a re-\\nflection sentence about the current state and task\\ngoal, as seen in the right branch of Figure 9. This\\nallows the agent to clearly recognize the current\\nsituation, make goal-aware long horizon decisions,\\nand ultimately succeed in the task.\\n11'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 11}, page_content=\"→ Although the agent has only found the lead and has not yet picked \\nit up, it is already planning its next move as if it had.\\n→ By reflecting the current state and task goal, it guides more \\npromising actions to reach the task goal, ultimately leading to task \\nsuccess.\\nScienceWorld: Your task is to boil lead. First, focus on the substance. Then, take actions that will cause it to change its state of matter.\\nWrong Thinking\\n...\\nObservation: You teleport to the workshop\\nThought: Now that I'm in the workshop, I should look around to find lead. Lead is often used in metalworking, so it's likely to be found in a container or on a workbench.\\nAction: look around\\nObservation: This room is called the workshop. Inside, you see the agent, a substance called air, and a table.\\nOn the table, there is a battery, a green wire, an orange light bulb (which is off), an orange wire, a paper cup containing a substance called lead, a red wire, a switch (which is off), a \\nviolet light bulb (which is off), and a yellow light bulb (which is off).\\nThought: I see a paper cup containing lead on the table in the workshop. Now that I have \\nlead, I need to heat it to boil it. I can use the blast furnace in the foundry to heat the lead.\\nAction: teleport to foundry\\n(1) Thought on next action\\n(2) Reflection on the current state in relation to   \\n       the task goal\\nReflection t+2: I am currently in the workshop and have found a paper cup containing \\nlead, the substance I need to focus on and whose state of matter I need to change.\\nAction: pick up cup containing lead\\nFigure 9: Another failure case of ReAct, following Figure 4, is seen in the ScienceWorld task boil lead. The agent\\nfinds the lead in the workshop. (1) It mistakenly believes it is holding the lead, proceeds with the task, and fails. (2)\\nAfter reflecting on its current state in relation to the task goal, the agent correctly recognizes its situation, takes\\ngoal-aware actions, and successfully completes the task.\\nC\\nBenchmark Details\\n• ALFWorld (Shridhar et al., 2021): ALFWorld\\nis a text-based benchmark derived from the AL-\\nFRED dataset, designed to evaluate an agent’s\\nability to interpret and execute natural language\\ninstructions in interactive, multi-step household\\ntasks. It converts embodied vision-and-language\\ntasks into textual form, allowing for assessment\\nof high-level planning, language grounding, and\\nsequential decision making in a simulated envi-\\nronment.\\n• ScienceWorld (Wang et al., 2022): Science-\\nWorld is a text-based benchmark for evaluating\\nagents on scientific reasoning and procedural\\ntask completion. Grounded in standardized K–12\\nscience curricula, it tests an agent’s ability to fol-\\nlow instructions, perform virtual experiments,\\nmake causal inferences, and manipulate objects\\nacross domains such as physics, chemistry, and\\nbiology. Tasks require multi-step interaction, hy-\\npothesis testing, and language grounding in a\\ndynamic environment.\\n• Jericho (Hausknecht et al., 2020): Jericho is a\\nsuite of text-based adventure games, each with\\ndistinct environments and roles. Tasks require\\ncompleting a sequence of implicit subgoals, of-\\nten in specific order. Since these subgoals often\\ndo not follow intuitive causal logic, agents must\\nrely on interaction to model the environment and\\naccurately infer their current state.\\nIn ALFWorld, success is measured using a bi-\\nnary signal: agents receive a reward of 1 only\\nwhen the task is fully completed, and 0 otherwise.\\nIn contrast, the official environments of Science-\\nWorld and Jericho provide both a success flag and\\na progress reward, which assigns a value between\\n0 and 1 based on the degree of task completion.\\nHowever, we discovered a bug in both Science-\\nWorld and Jericho where the success flag could\\nbe incorrectly set even when the progress reward\\nwas low or incomplete. For example, in Jericho,\\na task was sometimes marked as successful even\\nwhen the agent died during execution. To address\\nthis, we adjusted the success criteria: a task was\\nconsidered successful only if the progress reward\\nwas at least 0.7 in ScienceWorld, or exactly 1.0 in\\nJericho.\\nIn our experiments, the setups for ALFWorld\\nand ScienceWorld were based on the official im-\\nplementation by MPO (Xiong et al., 2025) (https:\\n//github.com/WeiminXiong/MPO), and we used\\nthe same test set for evaluation. The ALFWorld\\ntest set consists of 134 tasks across six different\\nhousehold task types, including ‘pick-and-place’,\\n‘pick-heat-then-place’, and ‘pick-two-and-place’.\\nThe ScienceWorld test set includes 211 tasks across\\n24 different scientific experiment types, including\\n‘Boil’, ‘Test Conductivity of Unknown Substances’,\\nand ‘Grow Fruit’.\\nThe experiments for Jericho were based\\non the implementation by AgentBoard (Chang\\net al., 2024) (https://github.com/hkust-nlp/\\nAgentBoard).\\nThe Jericho test set consists of\\n20 tasks, each corresponding to a different game,\\nincluding 905, Acorncourt, Afflicted, Balances,\\nDragon, Jewel, Library, Omniquest, Reverb, Snack-\\ntime, Zenon, Zork1, Zork2, Zork3, Detective,\\nNight, Pentari, Weapon, Darkhunt, and Loose.\\n12\"),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 12}, page_content='D\\nBaseline Details\\nD.1\\nBaselines for Backbone Reasoning\\nFrameworks\\nWe use the same environment code base and test set\\nfor all reasoning frameworks, including ReflAct.\\nFor specific environments, we follow existing im-\\nplementations: ALFWorld and ScienceWorld are\\nbased on the implementation by MPO (Xiong et al.,\\n2025), and Jericho is based on the implementation\\nby AgentBoard (Chang et al., 2024), as described\\nin detail in the section above. We implement base-\\nline reasoning frameworks using the following in-\\nstructions:\\n• Instruction for NoThinking\\nYou should directly output the action in this turn.\\n• Instruction for ReAct\\nYou should first think about the current condition\\nand plan for your future actions, and then out-\\nput your action in this turn.\\nNote that this ReAct instruction is from Song\\net al. (2024); Xiong et al. (2025).\\n• Instruction for Plan-and-Act\\nYou should first think about the given task and plan\\nyour approach to the task, and then output the\\naction for this turn.\\nThe one-shot example for ReAct is based on\\nYao et al. (2023); Xiong et al. (2025) and can be\\nfound in Appendix H. For NoThinking, we remove\\nthe thought step from all timesteps in the same\\nexample. For Plan-and-Act, we retain only the\\nthought from the first timestep (t = 1). We will\\nrelease the public implementation repository after\\npublication.\\nD.2\\nBaselines for Enhancement Reasoning\\nModules\\nIn our experiments, we discuss four enhanced\\nreasoning modules: Reflexion (Shinn et al., 2024)\\nand WKM (Qiao et al., 2024) in Section 6.3, and\\nRAFA (Liu et al., 2023), MPO (Xiong et al., 2025),\\nand ReflAct in Appendix F. We implemented\\neach module based on the official repositories\\nprovided by the original papers. For Reflexion, we\\nused the official implementation on top of each\\nenvironment’s base code: ALFWorld and Science-\\nWorld from Xiong et al. (2025), and Jericho from\\nChang et al. (2024). In addition, for WKM, we\\nused the publicly available dataset on Hugging\\nFace (https://huggingface.co/collections/\\nzjunlp/wkm-6684c611102213b6d8104f84)\\nto\\nreproduce the original setup and conducted\\nexperiments using WKM’s world model.\\n• Reflexion (Shinn et al., 2024):\\nhttps://\\ngithub.com/noahshinn/reflexion\\n• WKM (Qiao et al., 2024): https://github.\\ncom/zjunlp/WKM\\n• RAFA (Liu et al., 2023):\\nhttps://github.\\ncom/agentification/RAFA_code\\n• MPO (Xiong et al., 2025): https://github.\\ncom/WeiminXiong/MPO\\nE\\nResources\\nFor inference with the Llama3.1-Instruct model,\\nwe used one A6000 48GB GPU for the 8B model\\nand two A100 80GB GPUs for the 70B model.\\nFor training the WKM world model, we used four\\nA6000 48GB GPUs.\\nF\\nMore Discussion on Enhancement\\nModules\\nF.1\\nReflAct and RAFA\\nRAFA (Liu et al., 2023) introduces a next-state\\nprediction framework where a language model re-\\ncursively expands a tree of possible future action-\\nobservation trajectories, selecting actions based on\\nthe highest estimated value. While this foresight\\naids long-term reasoning, ReflAct offers practical\\nadvantages in efficiency and grounded decision-\\nmaking by internally modeling the current state.\\n On the desk 2, you \\nsee a alarmclock 1 ...\\ntake alarmclock 1 \\nfrom desk 2\\nI am at desk 2 with \\nthe alarm clock ...\\nReflection\\nAction\\n# of model queries per step = 13\\nMQ : 2\\nMQ : 4\\nMQ : 4\\nMQ : 1\\n(MQ = Model Queries to LM)\\nMQ : 2\\nCandidate\\nActions\\nPredicted\\nObs\\nValue\\nEstimate\\nCandidate\\nActions\\nObs\\nObs\\nPredicted\\nObs\\n# of model queries per step = 1\\nopen drawer 4\\ngo to drawer 4\\nTask : examine the alarmclock with the desklamp\\ngo to drawer 2\\ngo to desk 1\\ntake mug 1 \\nfrom desk 2\\ngo to drawer 1\\n On the desk 2, you \\nsee a alarmclock 1 ...\\nRAFA\\n(depth = 2, branch = 2)\\nReflAct\\nSelect action\\nwith highest value\\n*\\n*\\nFigure 10: Comparison between RAFA and ReflAct.\\n13'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 13}, page_content='As shown in Figure 10, RAFA constructs a tree\\nat each time step t, requiring 13 queries to the\\nlanguage model per step with depth d = 2 and\\nbranching factor b = 2: 3 for action sampling, 6\\nfor observation prediction, and 4 for value estima-\\ntion. This overhead grows rapidly with depth due\\nto exponential node expansion. In contrast, ReflAct\\nneeds only a single query per step to jointly pro-\\nduce a reflection and action, offering constant cost\\nand greater efficiency when latency or throughput\\nis constrained.\\nFigure 10 also highlights a behavioral difference\\nbetween the two methods. Given the task \"examine\\nthe alarmclock with the desklamp\" in ALFWorld,\\nboth agents observe an alarmclock on desk 2. Re-\\nflAct grounds its reflection in this state and selects\\nthe correct action, while RAFA relies on predicted\\ntrajectories that miss the action and lead to an un-\\nrelated exploratory move. This shows that ReflAct\\naligns decisions more closely with the actual state,\\nachieving more reliable behavior with significantly\\nlower cost via a single LLM call per step.\\nF.2\\nReflAct and MPO\\nRecently, Xiong et al. (2025) proposed a frame-\\nwork that enhances LLM agents by generating and\\nrefining high-level meta plans based on agent feed-\\nback. The meta plans are initially learned through\\nsupervised fine-tuning on expert-generated exam-\\nples and subsequently optimized via preference-\\nbased learning (Rafailov et al., 2024) using feed-\\nback from agent executions. The resulting meta\\nplanner can be applied to various agents in a\\nplug-and-play manner without requiring additional\\nretraining.\\nAccordingly, we applied the pub-\\nlicly available ALFWorld MPO meta plans from\\nhttps://github.com/WeiminXiong/MPO to No-\\nThinking, ReAct, and ReflAct, and compared the\\nresulting performance gains.\\nFigure 11: Performance comparison across NoThinking,\\nReAct, and ReflAct when applying MPO meta-plan.\\nAs shown in Figure 11, applying MPO meta\\nplans to NoThinking and ReAct leads to substan-\\ntial performance improvements.\\nHowever, no-\\ntably, even with these gains, NoThinking+MPO\\nand ReAct+MPO still fall short of ReflAct’s perfor-\\nmance. This further reinforces previous findings\\nthat strengthening the reasoning backbone itself\\nis more crucial than simply adding enhancement\\nmodules to ReAct.\\nApplying MPO meta plans to ReflAct results in\\nslight performance gains for GPT-4o, but a minor\\nperformance drop for Llama-3.1-8B-Instruct. This\\nmay be due to the fact that the meta plans were\\ntrained on tasks different from those in the test\\nset; in some out-of-distribution cases, they may\\noffer misleading guidance that negatively impacts\\nthe agent’s behavior. The limited effectiveness\\nof meta plans on ReflAct also suggests that its\\ngrounded decision-making already enables high-\\nquality planning.\\nG\\nMore Discussion on ReflAct’s Effects\\nG.1\\nReflAct Prevents Suboptimality Through\\nGoal-Oriented Reasoning\\nJericho: You are a treasure hunter who wants to seek out a \\nmysterious cylindrical room under a rock on an island, remember to \\nuse a tool to help you breathe when you swim in the ocean.\\n(1) ReAct\\n(2) ReflAct\\n→ The agent needed a breathing tool but became fixated on a shovel, repeatedly \\nusing it inappropriately and failing to find the right tool.\\n→ By continuously reflecting on the task goal of reaching the cylindrical room, \\nthe agent generates actions without falling into suboptimal behavior.\\n...\\nReflection: I currently have no items in my inventory, which is concerning since I need a \\ntool to help me breathe while swimming to reach the mysterious cylindrical room.\\xa0\\n...\\nReflection: I found a snorkel, the tool I need to breathe while swimming. Now I can head \\nto the ocean to look for the cylindrical room under a rock.\\n...\\nReflection: I am in the ocean and need to swim towards the island to continue my quest \\nfor the mysterious cylindrical room. \\n...\\nThought: I have found a shovel in this small clearing, which could be useful for digging \\nor uncovering items. Since I need a tool to help me breathe while swimming, I should \\ntake the shovel with me.\\n...\\nThought: Since I have the shovel, I will dig in the small clearing to see if I can uncover \\nanything useful.\\nFigure 12: Comparison of ReAct’s Thought and Re-\\nflAct’s Reflection on a Jericho task: ReAct fixates on a\\nfound shovel, losing sight of the main goal and failing;\\nReflAct succeeds through goal-oriented reasoning.\\nReflAct enables long-sighted planning by con-\\ntinuously reflecting on the current state and goal.\\nFigure 12 illustrates this with an example in a task\\nwhere the agent must gather swimming-related\\nitems and ultimately reach a cylindrical room. As\\nseen, ReAct fails due to short-sighted reasoning,\\nwhereas ReflAct successfully achieves the goal\\nthrough consistent reflection on the state and ob-\\njective.\\n14'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 14}, page_content='G.2\\nToken Length vs. Hallucination Action\\nRate in ReAct and ReflAct\\nHere, we further compare ReflAct and ReAct in\\nterms of token length and the hallucinated action\\nrate. Specifically, token length refers to the number\\nof tokens in each thought (or reflection) with action\\ngenerated by the model, normalized by the number\\nof steps to account for variations in agent trajectory\\nlength. The hallucinated action rate is defined as\\nthe proportion of actions that result in erroneous\\nobservations (e.g., \"Nothing happens\"). Both met-\\nrics were averaged across the four agent models\\nused in our experiments: GPT-4o, GPT-4o-mini,\\nLlama-3.1-8B/70B-Instruct.\\nFigure 13: Comparison of the average token length and\\naverage hallucination action rate between ReAct and\\nReflAct in ALFWorld, ScienceWorld, and Jericho.\\nFigure 13 shows that ReflAct produces slightly\\nlonger token sequences than ReAct, as it incorpo-\\nrates reflection on the current state and goal into\\nits reasoning process. Interestingly, despite the\\nincreased token length, the hallucination rate de-\\ncreases. This suggests that hallucinations in LLM\\nagents may not arise simply from increased rea-\\nsoning (i.e., overthinking), but rather from unstruc-\\ntured or unguided reasoning processes.\\n15'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 15}, page_content='H\\nPrompt\\nH.1\\nALFWorld\\n1) ReAct\\nYou are in the middle of a room.\\nLooking quickly around you, you see a\\ncabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, a garbagecan\\n1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a\\ntoilet 1, a toiletpaperhanger 1, and a towelholder 1.\\nYour task is to:\\nput some spraybottle on toilet.\\nThought:\\nTo solve the task, I need to find and take a sparybottle, then\\nput it on toilet.\\nFirst I need to find a spraybottle.\\nA spraybottle is\\nmore likely to appear in cabinet 1-4, countertop 1, toilet 1, sinkbasin 1-2,\\ngarbagecan 1.\\nI can check one by one, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\nObservation:\\nOn the cabinet 1, you see a cloth 1, a soapbar 1, a soapbottle\\n1.\\nAction:\\ngo to cabinet 2\\nObservation:\\nThe cabinet 2 is closed.\\nAction:\\nopen cabinet 2\\nObservation:\\nYou open the cabinet 2.\\nThe cabinet 2 is open.\\nIn it, you see\\na candle 1, and a spraybottle 2.\\nThought:\\nNow I find a spraybottle 2.\\nNext, I need to take it.\\nAction:\\ntake spraybottle 2 from cabinet 2\\nObservation:\\nYou pick up the spraybottle 2 from the cabinet 2.\\nThought:\\nNow I take a spraybottle 2.\\nNext, I need to put it in/on toilet 1.\\nAction:\\ngo to toilet 1\\nObservation:\\nOn the toilet 1, you see a soapbottle 2.\\nAction:\\nput spraybottle 2 in/on toilet 1\\nYou put the spraybottle 2 in/on the toilet 1.\\nFigure 14: Prompt for ALFWorld ReAct\\n16'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 16}, page_content='2) ReflAct\\nYou are in the middle of a room.\\nLooking quickly around you, you see a\\ncabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, a garbagecan\\n1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a\\ntoilet 1, a toiletpaperhanger 1, and a towelholder 1.\\nYour task is to:\\nput some spraybottle on toilet.\\nReflection:\\nTo solve the task, I need to find and take a sparybottle, then\\nput it on toilet.\\nFirst I need to find a spraybottle.\\nA spraybottle is\\nmore likely to appear in cabinet 1-4, countertop 1, toilet 1, sinkbasin 1-2,\\ngarbagecan 1.\\nI can check one by one, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\nObservation:\\nOn the cabinet 1, you see a cloth 1, a soapbar 1, a soapbottle\\n1.\\nReflection:\\nCurrently, I am at cabinet 1, not holding anything, and am\\nsearching for a spraybottle to place on the toilet, but instead I find a\\ncloth, a soapbar, and a soapbottle.\\nAction:\\ngo to cabinet 2\\nObservation:\\nThe cabinet 2 is closed.\\nReflection:\\nCurrently, I am at cabinet 2, not holding anything, but the\\nclosed cabinet hinders me from finding the spraybottle needed to place on\\nthe toilet.\\nAction:\\nopen cabinet 2\\nObservation:\\nYou open the cabinet 2.\\nThe cabinet 2 is open.\\nIn it, you see\\na candle 1, and a spraybottle 2.\\nReflection:\\nCurrently, I am at cabinet 2 and have found a spraybottle 2,\\nwhich brings me closer to completing the task of placing it on the toilet.\\nAction:\\ntake spraybottle 2 from cabinet 2\\nObservation:\\nYou pick up the spraybottle 2 from the cabinet 2.\\nReflection:\\nCurrently I am located at cabinet 2, now holding a spraybottle 2,\\nand I am ready to complete the task of placing the spraybottle on the toilet,\\nas I have obtained spraybottle 2.\\nAction:\\ngo to toilet 1\\nObservation:\\nOn the toilet 1, you see a soapbottle 2.\\nReflection:\\nCurrently, I am at toilet 1, still holding spraybottle 2, and the\\ntask is nearly complete, with only the placement remaining.\\nAction:\\nput spraybottle 2 in/on toilet 1\\nObservation:\\nYou put the spraybottle 2 in/on the toilet 1.\\nFigure 15: Prompt for ALFWorld ReflAct\\n17'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 17}, page_content='H.2\\nScienceWorld\\n1) ReAct\\nYour task is to use chemistry to create green paint.\\nWhen you are done, focus\\non the green paint.\\nThought:\\nTo solve the task, I need to find materials to create green paint,\\nuse those materials, and focus on the object specified in the task once it is\\nidentified.\\nThe materials for making green paint are likely to be found in an\\nart studio.\\nAction:\\nlook around\\nObservation:\\nThis room is called the bedroom.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nbed.\\nOn the bed is:\\na mattress.\\nOn the mattress is:\\na white pillow..\\ncloset.\\nThe closet door is open.\\nIn the closet is:\\nnothing.\\npicture\\ntable.\\nOn the table is:\\nnothing.\\nYou also see:\\nA door to the hallway (that is open)\\nThought:\\nThe bedroom doesn’t have the materials I need.\\nI should go to a\\nplace where paint and painting supplies are likely to be found, such as an art\\nstudio.\\nAction:\\nteleport to art studio\\nObservation:\\nYou teleport to the art studio.\\nThought:\\nNow that I’m in the art studio, I should look around to find the\\nnecessary materials to create green paint.\\nAction:\\nlook around\\nObservation:\\nThis room is called the art studio.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nlarge cupboard.\\nThe large cupboard door is open.\\nIn the large cupboard is:\\na drawer, a wood cup (containing yellow paint), a wood cup (containing blue\\npaint), a wood cup (containing red paint).\\ntable.\\nOn the table is:\\na glass cup (containing nothing).\\nwood cup (containing yellow paint)\\na wood cup (containing blue paint)\\nwood cup (containing red paint)\\nYou also see:\\nA door to the hallway (that is open)\\nThought:\\nI see blue paint here, which is one of the primary colors needed to\\nmix green paint.\\nI should start by pouring it into an empty container to mix\\nwith another color.\\nAction:\\npour cup containing blue paint in art studio in cup containing\\nnothing\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nThought:\\nYellow paint is the other primary color needed to mix with blue to\\ncreate green.\\nI should add the yellow paint to the container with blue paint.\\nAction:\\npour cup containing yellow paint in art studio in cup containing blue\\npaint in table\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nThought:\\nNow that I have both blue and yellow paint in the same container, I\\nneed to mix them together to create green paint.\\nAction:\\nmix cup containing blue paint and yellow paint\\nObservation:\\nBlue and yellow paint mix to produce green paint.\\nThought:\\nThe task is to create green paint and then focus on it.\\nNow that\\nthe green paint is made, I should focus on the final product.\\nAction:\\nfocus on green paint\\nFigure 16: Prompt for ScienceWorld ReAct\\n18'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 18}, page_content='2) ReflAct\\nYour task is to use chemistry to create green paint.\\nWhen you are done, focus\\non the green paint.\\nReflection:\\nTo solve the task, I need to find materials to create green\\npaint, use those materials, and focus on the object specified in the task\\nonce it is identified.\\nThe materials for making green paint are likely to be\\nfound in an art studio.\\nAction:\\nlook around\\nObservation:\\nThis room is called the bedroom.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nbed.\\nOn the bed is:\\na mattress.\\nOn the mattress is:\\na white pillow..\\ncloset.\\nThe closet door is open.\\nIn the closet is:\\nnothing.\\npicture\\ntable.\\nOn the table is:\\nnothing.\\nYou also see:\\nA door to the hallway (that is open)\\nReflection:\\nCurrently, I am in the bedroom, holding nothing and focused on\\nnothing.\\nThere are no useful materials here to create the green paint I need\\nto focus on.\\nAction:\\nteleport to art studio\\nObservation:\\nYou teleport to the art studio.\\nReflection:\\nCurrently, I am in the art studio, holding nothing and focused on\\nnothing.\\nI need to look for materials to create green paint.\\nAction:\\nlook around\\nObservation:\\nThis room is called the art studio.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nlarge cupboard.\\nThe large cupboard door is open.\\nIn the large cupboard is:\\na drawer, a wood cup (containing yellow paint), a wood cup (containing blue\\npaint), a wood cup (containing red paint).\\ntable.\\nOn the table is:\\na glass cup (containing nothing).\\nwood cup (containing yellow paint)\\na wood cup (containing blue paint)\\nwood cup (containing red paint)\\nYou also see:\\nA door to the hallway (that is open)\\nReflection:\\nCurrently, I am in the art studio, not holding anything.\\nI’ve\\nfound the primary colors yellow, blue, and red, which can be used to make\\ngreen paint, the substance I will need to focus on.\\nAction:\\npour cup containing blue paint in art studio in cup containing\\nnothing\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nReflection:\\nI poured blue paint into the glass cup.\\nI’m now holding it and\\nwill next add yellow paint.\\nAction:\\npour cup containing yellow paint in art studio in cup containing blue\\npaint in table\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nReflection:\\nI’ve added yellow paint to the blue in the glass cup.\\nI’m now\\nholding a mix of blue and yellow paint, ready to be mixed into green.\\nAction:\\nmix cup containing blue paint and yellow paint\\nObservation:\\nBlue and yellow paint mix to produce green paint.\\nReflection:\\nThe task is to create green paint and then focus on it.\\nNow that\\nthe green paint is made, I should focus on the final product.\\nAction:\\nfocus on green paint\\nFigure 17: Prompt for ScienceWorld ReflAct\\n19'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 19}, page_content='H.3\\nJericho\\n1) ReAct\\nGoal:\\nYou are the warrior Link that needs to save the princess from the\\ncastle.\\nObservation:\\nYou are at the path leading to the castle.\\nThe castle is to\\nyour north.\\nThere is a barrel in front of you.\\nThought:\\nTo solve the task, I first need to explore my surroundings to gather\\nany useful items.\\nOnce prepared, I will move north into the castle, navigate\\nto the princess’s location, interact with the princess and complete the rescue\\nmission.\\nAction:\\nExamine barrel\\nObservation:\\nThere is a gleaming elvish sword.\\nThought:\\nThe sword inside the barrel has a gleaming finish, which suggests it\\nis of high quality and possibly enchanted.\\nTaking this sword now will likely\\nincrease my chances of handling any immediate challenges.\\nAction:\\ntake the sword\\nObservation:\\nThe sword is taken\\nThought:\\nI’m now armed.\\nAdvancing north into the castle should provide new\\nopportunities for exploration and reveal the next critical steps.\\nAction:\\nnorth\\nObservation:\\nMain hall\\nThe castle is dimly lit, with lava flowing in many places.\\nThere is a\\nstaircase leading up to princess bedroom, a door to your north leading to\\nthe kitchen hall, and the door you just entered on your south\\nThought:\\nBefore making a move toward any specific direction, I need to\\nevaluate what options are actually available to me right now.\\nIt would be\\nhelpful to check the possible actions I can take from here.\\nAction:\\ncheck valid actions\\nObservation:\\nsouth, north, up, look, examine staircase\\nThought:\\nAmong the available actions, ascending the staircase seems like the\\nmost direct route to explore.\\nSince it leads upward and the hall below seems\\nperilous, I’ll proceed to investigate what’s at the top of the stairs.\\nAction:\\nup\\nObservation:\\nPrincess’s bedroom.\\nPrincess is sleeping in bed.\\nThought:\\nI’ve entered a bedroom where the princess is lying unconscious.\\nThere are likely specific actions I can perform in this situation, and\\nI should understand my options before taking a step that could have\\nconsequences.\\nChecking what I can do here would be the most logical next\\nmove.\\nAction:\\ncheck valid actions\\nObservation:\\nwake up the princess, take out sword, down\\nThought:\\nOne of the available actions is to wake the princess, which might\\nchange the course of events.\\nIt seems like the most immediate and gentle way\\nto interact with her.\\nI’ll go ahead and try that first.\\nAction:\\nwake up the princess\\nObservation:\\nThe princess wake up from the coma.\\nThank you my knight, she\\nsays.\\nThe task is finished.\\nFigure 18: Prompt for Jericho ReAct\\n20'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 20}, page_content='2) ReflAct\\nGoal:\\nYou are the warrior Link that needs to save the princess from the\\ncastle.\\nObservation:\\nYou are at the path leading to the castle.\\nThe castle is to\\nyour north.\\nThere is a barrel in front of you.\\nReflection:\\nTo solve the task, I first need to explore my surroundings to\\ngather any useful items.\\nOnce prepared, I will move north into the castle,\\nnavigate to the princess’s location, interact with the princess and complete\\nthe rescue mission.\\nAction:\\nExamine barrel\\nObservation:\\nThere is a gleaming elvish sword.\\nReflection:\\nI found a powerful elvish sword in the barrel.\\nSince I currently\\nhave no weapons, this sword will be essential for protection once I enter the\\ncastle.\\nAction:\\ntake the sword\\nObservation:\\nThe sword is taken\\nReflection:\\nI have obtained the elvish sword and am now equipped.\\nWith my\\nweapon ready, I should head into the castle to continue the search for the\\nprincess.\\nAction:\\nnorth\\nObservation:\\nMain hall\\nThe castle is dimly lit, with lava flowing in many places.\\nThere is a\\nstaircase leading up to princess bedroom, a door to your north leading to\\nthe kitchen hall, and the door you just entered on your south\\nReflection:\\nI have entered the main hall of the castle.\\nThe environment is\\ndangerous with lava present.\\nThe staircase likely leads to the princess’s\\nbedroom, which aligns with my goal.\\nI should verify available actions first.\\nAction:\\ncheck valid actions\\nObservation:\\nsouth, north, up, look, examine staircase\\nReflection:\\nThe valid actions include going “up,” which matches the staircase\\nthat leads to the princess’s bedroom.\\nThis is likely the shortest path to the\\ngoal.\\nAction:\\nup\\nObservation:\\nPrincess’s bedroom.\\nPrincess is sleeping in bed.\\nReflection:\\nI have reached the princess, but she appears to be unconscious\\nor in a coma.\\nI need to determine how to safely wake her to complete the\\nmission.\\nAction:\\ncheck valid actions\\nObservation:\\nwake up the princess, take out sword, down\\nReflection:\\nThe available actions include “wake up the princess,” which\\ndirectly supports the goal of saving her.\\nNo threat is present, so this is\\nthe appropriate move.\\nAction:\\nwake up the princess\\nObservation:\\nThe princess wake up from the coma.\\nThank you my knight, she\\nsays.\\nThe task is finished.\\nFigure 19: Prompt for Jericho ReflAct\\n21'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 21}, page_content='I\\nMore Case Study\\nALFWorld: clean some soapbar and put it in cabinet.\\nReAct\\nGoal:\\nclean some soapbar and put it\\nin cabinet.\\nThought:\\nTo solve the task, I need\\nto find a soapbar, then clean it with\\nsinkbasin, then put it in cabinet.\\nFirst I need to find a soapbar.\\nA\\nsoapbar is more likely to appear in\\ncabinet 1-4, countertop 1, sinkbasin\\n1-2, or toilet 1.\\nI can check one by\\none, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\n...\\nAction:\\ngo to cabinet 4\\nObservation:\\nYou open the cabinet 4.\\nThe cabinet 4 is open.\\nIn it, you\\nsee a candle 1, and a cloth 2.\\nThought:\\nNow I find a cloth 2 in\\ncabinet 4, which I can use to clean\\nthe soapbar.\\nNext, I need to find a\\nsoapbar.\\nI will go to countertop 1\\nto check if it contains a soapbar.\\nAction:\\ngo to countertop 1\\nObservation:\\nOn the countertop 1,\\nyou see a soapbar 1, and a soapbottle\\n1.\\nThought:\\nNow I find a soapbar 1 on\\nthe countertop 1.\\nNext, I need to\\nclean it with sinkbasin.\\nI will go\\nto sinkbasin 1 to clean the soapbar.∗\\n∗Ungrounded thought:\\nThe agent\\nattempts to go to the sinkbasin\\nwithout having taken the soapbar.\\nAction:\\ngo to sinkbasin 1\\nObservation:\\nOn the sinkbasin 1, you\\nsee nothing.\\nThought:\\nSince the sinkbasin 1 is\\nempty, I need to clean the soapbar\\n1 with something.\\nI will use the\\ncloth 2 from cabinet 4 to clean the\\nsoapbar.∗\\n∗Hallucination:\\nThe agent performs\\nan action without soapbar present.\\nAction:\\nuse cloth 2\\nObservation:\\nNothing happens.\\nThought:\\nSince using the cloth 2 did\\nnot have any effect, I need to find\\na way to use it to clean the soapbar.\\nI will go back to the cabinet 4 and\\ntake the cloth 2 to use it with the\\nsinkbasin 1.\\nAction:\\ntake cloth 2 from cabinet 4\\nObservation:\\nNothing happens.\\n...\\n# Task Failed\\nReflAct\\nGoal:\\nclean some soapbar and put it\\nin cabinet.\\nReflection:\\nTo solve the task, I\\nneed to find a soapbar, clean it\\nwith sinkbasin, and then put it in\\ncabinet.\\nFirst, I need to find a\\nsoapbar.\\nA soapbar is more likely to\\nappear in cabinet 1-4, countertop 1,\\nor sinkbasin 1-2.\\nI can check one by\\none, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\n...\\nAction:\\ngo to countertop 1\\nObservation:\\nOn the countertop 1,\\nyou see a soapbar 1, and a soapbottle\\n1.\\nReflection:\\nCurrently, I am at\\ncountertop 1, and I have found a\\nsoapbar 1, which I need to clean\\nbefore placing it in the cabinet to\\ncomplete the task.∗\\n∗The agent performs an action that\\nare goal-related and well grounded in\\nthe current situation.\\nAction:\\ntake soapbar 1 from\\ncountertop 1\\nObservation:\\nYou pick up the soapbar\\n1 from the countertop 1.\\nReflection:\\nCurrently, I am at\\ncountertop 1, now holding soapbar 1,\\nwhich I need to clean before placing\\nit in the cabinet to complete my\\ntask.\\nObservation:\\nOn the sinkbasin 1, you\\nsee nothing.\\nReflection:Currently, I am at\\nsinkbasin 1, I’m holding a soapbar\\n1, and I am now ready to clean it\\nbefore placing it in the cabinet to\\ncomplete my task.\\nAction:\\nAction:\\nclean soapbar 1\\nwith sinkbasin 1\\nObservation:\\nYou clean the soapbar 1\\nusing the sinkbasin 1.\\n...\\n# Task Succeed\\nFigure 20: Case study for ALFWorld\\n22'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 22}, page_content='ScienceWorld: Your task is to boil tin.\\nFor compounds without a boiling point, combusting the substance is also acceptable.\\nFirst, focus on the substance. Then, take actions that will cause it to change its state of matter.\\nReAct\\n...\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nThought:\\nNow that I’m in the\\nworkshop, I should look around to\\nfind tin.\\nThe workshop is a place\\nwhere various projects and repairs\\nare done, so I might find tin here in\\nthe form of scraps, sheets, or other\\nobjects.\\nAction:\\nlook around\\nObservation:\\nThis room is called the\\nworkshop.\\nIn it, you see:\\n...\\nOn\\nthe table is:\\na battery, a green\\nwire, a metal pot (containing a\\nsubstance called tin), ...\\nThought:\\nI found tin in the metal\\npot on the table!\\nNow that I’ve\\nlocated the tin, I should focus on it\\nas per the task instructions.\\nAction:\\nfocus on tin\\nObservation:\\nYou focus on the tin.\\nThought:\\nNow that I’ve focused on\\nthe tin, I need to take actions to\\nboil or combust it.\\nSince the tin\\nis in a metal pot, I can use a heat\\nsource to boil it.\\nI see a blast\\nfurnace in the foundry, which would\\nbe perfect for heating the tin.\\nI\\nshould teleport back to the foundry\\nand use the blast furnace.∗\\n∗Ungrounded thought:\\nThe agent\\nconfirms the presence of tin and\\nproceeds with planning, but does not\\nactually possess the tin.\\nAction:\\nteleport to foundry\\nObservation:\\nYou teleport to the\\nfoundry.\\nThought:\\nNow that I’m back in the\\nfoundry, I should move the metal\\npot containing the tin to the blast\\nfurnace and then activate the blast\\nfurnace to heat the tin.\\nAction:\\nmove metal pot to blast\\nfurnace\\nObservation:\\nNo known action matches\\nthat input.\\nThought:\\nIt seems I made a mistake\\nwith the action.\\nI should try again,\\nusing a different action to move the\\nmetal pot to the blast furnace.∗\\n∗Hallucination:\\nAlthough the agent\\nrecognizes the mistake, it continues\\nto attempt the same invalid action.\\nAction:\\nmove metal pot to blast\\nfurnace\\n...\\n# Task Failed\\nReflAct\\n...\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nReflection:\\nCurrently, I am in the\\nworkshop, holding nothing and focused\\non nothing.\\nI need to look for tin\\nin this room.\\nAction:\\nlook around\\nObservation:\\nThis room is called the\\nworkshop.\\nIn it, you see:\\n...\\nOn\\nthe table is:\\na battery, a green\\nwire, a metal pot (containing a\\nsubstance called tin), ...\\nReflection:\\nCurrently, I am in the\\nworkshop, holding nothing and focused\\non nothing.\\nI’ve found a metal pot\\ncontaining tin on the table, which is\\nthe substance I need to focus on and\\nthen boil or combust\\nAction:\\nfocus on tin\\nObservation:\\nYou focus on the tin.\\nReflection:\\nI am now focused on\\nthe tin, which is contained in the\\nmetal pot on the table.\\nTo boil\\nor combust the tin, I need to apply\\nheat to it.\\nI see a foundry in the\\nenvironment, which is likely to have\\na heat source.\\nAction:\\nteleport to foundry\\n...\\nReflection:\\nThe blast furnace is now\\nactivated and ready to be used as a\\nheat source.\\nI need to move the tin\\nfrom the metal pot in the workshop to\\nthe blast furnace in the foundry.\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nReflection:\\nI am now back in the\\nworkshop, where the metal pot\\ncontaining the tin is located.\\nI\\nneed to move the tin to the blast\\nfurnace in the foundry.\\nAction:\\nmove metal pot to blast\\nfurnace\\nObservation:\\nNo known action matches\\nthat input.\\nReflection:\\nI need to move the\\ntin to the blast furnace, but the\\naction is not recognized.\\nInstead,\\nI can pick up the metal pot and then\\nteleport to the foundry.\\nAction:\\npick up metal pot\\nObservation:\\nYou move the metal pot\\nto the inventory.\\nReflection:\\nI am now back in\\nthe foundry, with the metal pot\\ncontaining the tin in my inventory.\\nI can now use the blast furnace to\\nboil or combust the tin.\\n...\\n# Task Succeed\\nFigure 21: Case study for ScienceWorld\\n23'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 23}, page_content='Jericho: You are a pizza delivery man. Today you are making a new delivery on your boss’s order.\\nYou need to find out by yourself who to deliver.\\nReAct\\n...\\nObservation:\\nThe note reads:\\n\"Stanley, Don’t forget to make your\\ndelivery to Mr.\\nCalzone, located at\\nthe San Doppleton Courthouse.\\n...\\n...\\nObservation:\\nStreet, Near Courthouse\\nYou are approaching the center of\\ndowntown San Doppleton.\\nThere is a\\ncourthouse to the south.\\nThe street\\nruns east and west.\\nThought:\\nIt seems like I’m on the\\nright track, as the courthouse is now\\nvisible to the south.\\nI should head\\nsouth to reach the courthouse and\\ndeliver the pizza to Mr.\\nCalzone as\\ninstructed in the note.\\nAction:\\nSouth\\nObservation:\\nCourthouse You are in\\na crowded courthouse.\\nThe street is\\noff to the north.\\nThe courtroom is\\ncurrently abuzz with excitement as\\nit seems that the pre-trial hearing\\nof the infamous gangster, Guido \"The\\nArmadillo\" Calzone is winding to a\\nclose.\\nGuido and his hotshot lawyer\\nsit placidly at their table, while\\nthe flustered young district attorney\\nwho is prosecuting the case seems\\nlike she’s at her wits’ end.\\nAt the\\nmoment, the D.A. stands at the front\\nof the courtroom, arguing over a\\nlegal point with the judge.\\nThought:\\nI have arrived at the\\ncourthouse where Mr.\\nCalzone is\\npresent.\\nSince the courtroom is busy,\\nI need to find a way to deliver the\\npizza to Mr.\\nCalzone without causing\\na disruption.\\nI should approach him\\nor his lawyer to hand over the pizza\\nbox.\\nAction:\\nShow people box\\nObservation:\\nYou can’t see any such\\nthing.\\nThought:\\nIt seems that the action\\n\"show people box\" was not understood\\nin this context.\\nI need to find a\\nmore direct way to deliver the pizza\\nto Mr.Calzone.\\nSince he is present\\nin the courtroom, I should try to\\ngive the pizza box directly to him or\\nhis lawyer.∗\\n∗Mismatched execution:\\nThe agent\\nfails to specify the target, leading\\nto another invalid action.\\nAction:\\nGive people box\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\n# Task Failed\\nReflAct\\n...\\nObservation:\\nThe note reads:\\n\"Stanley, Don’t forget to make your\\ndelivery to Mr.\\nCalzone, located at\\nthe San Doppleton Courthouse.\\n...\\n...\\nObservation:\\nStreet, Near Courthouse\\nYou are approaching the center of\\ndowntown San Doppleton.\\nThere is a\\ncourthouse to the south.\\nThe street\\nruns east and west.\\nReflection:\\nI’ve finally found the\\ncourthouse, which is located to\\nthe south of my current position.\\nThis is where I need to deliver\\nthe pizza to Mr.\\nCalzone.\\nNow\\nthat I’ve located the courthouse,\\nI should proceed south to complete\\nthe delivery task.\\nAction:\\nSouth\\nObservation:\\nCourthouse You are in\\na crowded courthouse.\\nThe street is\\noff to the north.\\nThe courtroom is\\ncurrently abuzz with excitement as\\nit seems that the pre-trial hearing\\nof the infamous gangster, Guido \"The\\nArmadillo\" Calzone is winding to a\\nclose.\\nGuido and his hotshot lawyer\\nsit placidly at their table, while\\nthe flustered young district attorney\\nwho is prosecuting the case seems\\nlike she’s at her wits’ end.\\nAt the\\nmoment, the D.A. stands at the front\\nof the courtroom, arguing over a\\nlegal point with the judge.\\nReflection:\\nI’ve entered the\\ncourthouse where the pre-trial\\nhearing for Guido \"The Armadillo\"\\nCalzone is taking place.\\nThis is\\nthe location where I need to deliver\\nthe pizza to Mr.\\nCalzone.\\nSince\\nI’ve found him, I should proceed with\\ndelivering the pizza to complete my\\ntask.∗\\n∗Well-grounded and goal-aligned\\nreasoning:\\nThe agent explicitly\\nidentifies the recipient and forms a\\nvalid, context-aware action.\\nAction:\\nGive pizza box to Guido\\nCalzone\\nObservation:\\nGuido grins shiftily\\nand takes the pizza from you.\\nHe\\nhands it to his lawyer so he can\\neat it later.\\nYou walk away,\\ncongratulating yourself on a job\\nwell done.\\n# Task Succeed\\nFigure 22: Case study for Jericho\\n24'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 24}, page_content='Jericho: search for a mug in an inn.\\nReAct\\n...\\nObservation:\\nInside the Inn There\\nare a few patches of mould on the\\nwalls and the floorboards creak\\nslightly, but the building seems safe\\nenough.\\n...\\nYou see some tables and\\nchairs.\\n...\\nYou can go west (back\\noutside) or down some steps.\\nYou\\ncan see a magnificently carved chair\\nhere.\\nThought:\\nI’m inside the inn, and I\\nneed to find a mug.\\nI should start\\nby examining the tables and chairs to\\nsee if there’s a mug lying around.\\nAction:\\nExamine tables and chairs\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\nAction:\\nExamine floorboards\\nObservation:\\nThe floor is made\\nof large, rather uneven rough\\nfloorboards, on which lie the remains\\nof the scattered rushes once used as\\na floor covering.\\nThought:\\nI’ve examined the\\nfloorboards, but I didn’t find a\\nmug.\\nI should try to find something\\nto pick up, and since I’m in the inn,\\nI should check the inventory again to\\nsee if I have any other options, but\\nit seems I’m empty-handed.\\nI should\\ntry to find something to pick up.\\nAction:\\nExamine stone steps leading\\ndown\\n...\\nAction:\\nExamine the floorboards\\nagain\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nfloor.\\nThought:\\nI’ve tried examining\\nvarious objects and places in the inn,\\nbut I didn’t find a mug.\\nI should\\ntry to find something to pick up, and\\nsince I’m in the inn, I should check\\nthe inventory again to see if I have\\nany other options, but it seems I’m\\nempty-handed.\\nI should try to find\\nsomething to pick up.∗\\n∗Short-sighted planning:\\nThe\\nagent repeatedly focuses narrowly\\non immediate surroundings without\\nreconsidering its strategy in light\\nof prior failures.\\nAction:\\nExamine the rushes on the\\nfloor again\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nfloor.\\n...\\n# Task Failed\\nReflAct\\n...\\nObservation:\\nInside the Inn There\\nare a few patches of mould on the\\nwalls and the floorboards creak\\nslightly, but the building seems safe\\nenough.\\n...\\nYou see some tables and\\nchairs.\\n...\\nYou can go west (back\\noutside) or down some steps.\\nYou\\ncan see a magnificently carved chair\\nhere.\\nReflection:\\nI’ve entered the\\nabandoned inn, the Troll’s Arms,\\nand it appears to be old and dusty,\\nbut safe enough.\\nI’ve seen some\\ntables and chairs, and a dark,\\nintricately-carved wooden chair in\\nthe corner.\\nSince my goal is to\\nsearch for a mug in an inn, I should\\ninvestigate the tables and chairs to\\nsee if there’s anything useful.\\nAction:\\nExamine tables and chairs\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\nAction:\\nExamine bar or counter\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nwalls.\\nReflection:\\nI’ve been trying to\\nfind a mug, but that didn’t reveal\\nanything.\\nI should try to think of a\\ndifferent approach to find the mug.\\nAction:\\nDown\\nObservation:\\nInn Cellar The cellar\\nseems to have been formed from a\\nnatural cavern in the rock under the\\ninn, ...\\n, which will remain cool in\\nthe slightly chill air.\\n...\\nYou can\\ngo up (to the inn) or west (into the\\ndark tunnel).\\nYou can see an ancient\\nsilver coin and some barrels here.\\nReflection:\\nI’ve been trying to find\\na mug, but so far, I haven’t found\\nanything useful.\\nI should try to\\nthink of a different approach to find\\nthe mug.\\nThe cellar seems like a\\npromising location to search for a\\nmug, as it’s a storage area for the\\ninn’s supplies.∗\\n∗Reflecting on long-term goal:\\nThe\\nagent adapts its exploration strategy\\nbased on environmental cues and prior\\nsearch failures.\\nAction:\\nExamine barrels\\nObservation:\\nThe barrels are now no\\nmore than rotten staves of dry wood,\\nheld together by the woodworm holding\\nhands.\\nYou have found a pewter mug.\\n# Task Succeed\\nFigure 23: Another case study for Jericho\\n25')],\n",
              " 'chunks': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 0}, page_content='ReflAct: World-Grounded Decision Making in\\nLLM Agents via Goal-State Reflection\\nJeonghye Kim1∗, Sojeong Rhee1∗, Minbeom Kim2, Dohyung Kim2,\\nSangmook Lee2, Youngchul Sung1†, Kyomin Jung2†,\\n1KAIST, 2Seoul National University\\n{jeonghye.kim, sojeong.rhee, ycsung}@kaist.ac.kr, kjung@snu.ac.kr\\nAbstract\\nRecent advances in LLM agents have largely\\nbuilt on reasoning backbones like ReAct (Yao\\net al., 2023), which interleave thought and ac-\\ntion in complex environments. However, Re-\\nAct often produces ungrounded or incoherent\\nreasoning steps, leading to misalignment be-\\ntween the agent’s actual state and goal. Our\\nanalysis finds that this stems from ReAct’s\\ninability to maintain consistent internal be-\\nliefs and goal alignment, causing compound-\\ning errors and hallucinations. To address this,\\nwe introduce ReflAct, a novel backbone that\\nshifts reasoning from merely planning next ac-\\ntions to continuously reflecting on the agent’s\\nstate relative to its goal. By explicitly ground-\\ning decisions in states and enforcing ongoing\\ngoal alignment, ReflAct dramatically improves\\nstrategic reliability. This design delivers sub-\\nstantial empirical gains: ReflAct surpasses Re-\\nAct by 27.7% on average, achieving a 93.3%\\nsuccess rate in ALFWorld. Notably, ReflAct\\neven outperforms ReAct with added enhance-\\nment modules (e.g., Reflexion, WKM), show-\\ning that strengthening the core reasoning back-\\nbone is key to reliable agent performance.\\n1\\nIntroduction\\nRecent advancements in Large Language Mod-\\nels (LLMs) have significantly enhanced their rea-\\nsoning capabilities, enabling LLM-based agents\\nto perform complex multi-step decision making\\nbeyond static problem solving (Forootani, 2025;\\nChervonyi et al., 2025). As LLMs are extended\\ninto agentic frameworks where they interact with\\nopen-ended environments, the ability to solve long-\\nhorizon tasks through ongoing interaction and se-\\nquential reasoning has become a central research\\nfocus (Zhou et al., 2023; Song et al., 2024).\\nA large number of recent LLM agents build on\\nthe ReAct (Yao et al., 2023) framework, which in-\\n∗Equal contribution.\\n† Co-corresponding authors.\\nAction\\nReflection\\nTimestep\\n1\\n2\\n3\\nT-1\\nObs\\nGoal\\n. . .\\n. . .\\n. . .\\n1\\n2\\n2\\n3\\n3\\nT-1\\n1\\n2\\n3\\nT-1\\nT-1\\nT\\nT\\nInternal\\nState\\n1\\n2\\n3\\nT-1\\nAction\\nThought\\nObs\\nTimestep\\n1\\n2\\n3\\nT-1\\nT\\nT\\nGoal\\n. . .\\n. . .\\nReasoning Direction in ReAct\\n. . .\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n3\\nT-1\\nT-1\\nT-1\\nT\\nT\\nReasoning Direction in ReflAct\\nFigure 1: Comparison of reasoning influence in ReflAct'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 0}, page_content='Action\\nThought\\nObs\\nTimestep\\n1\\n2\\n3\\nT-1\\nT\\nT\\nGoal\\n. . .\\n. . .\\nReasoning Direction in ReAct\\n. . .\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n3\\nT-1\\nT-1\\nT-1\\nT\\nT\\nReasoning Direction in ReflAct\\nFigure 1: Comparison of reasoning influence in ReflAct\\nand ReAct. While ReAct focuses on the current ob-\\nservation and the next action at each timestep, ReflAct\\nreflects on the internal belief state and the task goal.\\ntegrates Chain-of-Thought (CoT) reasoning (Wei\\net al., 2022) with an action selection mechanism.\\nVarious extensions have been proposed to enhance\\nthis backbone by incorporating reflective iterations\\nor memory components to improve reasoning per-\\nformance (Shinn et al., 2024; Liu et al., 2023; Qiao\\net al., 2024). However, mounting evidence sug-\\ngests that ReAct and its variants often deliver lim-\\nited benefits and can even deteriorate performance,\\nespecially in complex, partially observable, or dy-\\nnamic environments (Ma et al., 2025; Chang et al.,\\n2024; Verma et al., 2024). These findings raise\\nquestions about the current direction of extending\\nthe basic ReAct reasoning-action framework.\\nIn this paper, we claim that true progress lies in\\nfundamentally redesigning the backbone reasoning\\nprocess itself, rather than adding complementary\\nmodules. Our analysis shows that the fundamental\\nproblem of current ReAct-based reasoning meth-\\nods is the frequent lack of proper grounding of\\ngenerated thoughts on the agent’s historical con-\\ntext or overarching objective. These misaligned\\nthoughts guide subsequent action choices. In dy-\\n1\\narXiv:2505.15182v1  [cs.CL]  21 May 2025'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 1}, page_content='namic or partially observable environments, such\\nreasoning errors compound over time, leading to\\nincreasingly divergent internal beliefs, deteriorated\\ndecision quality, and failed task execution.\\nTo address this limitation, we introduce ReflAct\\n(Reflect for Action), a new backbone framework\\nthat shifts the focus of the agent’s thought from pre-\\ndicting the next action to continuously reflecting\\non its current state in the context of the task goal,\\nas shown in Figure 1. Unlike previous approaches\\nthat layer reflective or memory modules onto the\\nReAct backbone (Shinn et al., 2024; Qiao et al.,\\n2024; Xiong et al., 2025), ReflAct does not rely\\non such additional components but replaces the\\ncore reasoning–action cycle itself. That is, at each\\ntimestep, the agent evaluates whether its current\\ntrajectory and situation align with its intended long-\\nterm objective before selecting an action. This\\nreflective thought mechanism enables early detec-\\ntion of potential deviations and facilitates timely\\nstrategy adjustments, as we shall see shortly. By\\ngrounding decisions in actual observations and\\nmaintaining continuous goal alignment, ReflAct\\nsubstantially reduces hallucination tendency and\\nenhances long-term strategic coherence.\\nWe implemented ReflAct using both open-\\nsource (Llama 3.1-8B/70B-Instruct (Grattafiori\\net al., 2024)) and proprietary (GPT-4o-mini/4o\\n(OpenAI, 2024)) LLMs, and evaluated it in three\\ntext-based environments: ALFWorld (Shridhar\\net al., 2021), ScienceWorld (Wang et al., 2022) and\\nJericho (Hausknecht et al., 2020), which require an\\nagent to decompose the goal and acts over a long\\ntime horizon under partial observability. Empirical\\nresults show that ReflAct helps the agent better\\nalign its internal beliefs with the environment and\\npromotes goal-consistent behavior. As a result, Re-\\nflAct significantly outperforms ReAct by 36.4%,\\n8.5%, and 38.1% on ALFWorld, ScienceWorld,\\nand Jericho, respectively. Notably, ReflAct also\\nsurpasses enhancement modules layered on top of\\nexisting backbones, demonstrating that revising the\\nreasoning process itself can be more effective than\\nadding new components.\\n2\\nPreliminaries\\nWe model the agent’s task in a language-based en-\\nvironment as a Partially Observable Markov Deci-\\nsion Process (POMDP) (Puterman, 1990), defined\\nas M = ⟨U, S, A, O, P, R⟩, where u ∈U is a\\ntask instruction, s ∈S is the (hidden) environment\\nstate, a ∈A is an action, o ∈O is an observation,\\nP is the transition function, and R is the reward\\nfunction. In our setting, U, A and O are expressed\\nin natural language.\\nThe ReAct Framework\\nThe ReAct framework\\n(Yao et al., 2023) enables LLM agents to solve\\ntasks through interleaved reasoning and action. To\\nincorporate reasoning steps (thoughts), we extend\\nthe above POMDP by including a thought space\\nT , where each thought τ ∈T represents a natural\\nlanguage reasoning step generated by the agent.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 1}, page_content='in natural language.\\nThe ReAct Framework\\nThe ReAct framework\\n(Yao et al., 2023) enables LLM agents to solve\\ntasks through interleaved reasoning and action. To\\nincorporate reasoning steps (thoughts), we extend\\nthe above POMDP by including a thought space\\nT , where each thought τ ∈T represents a natural\\nlanguage reasoning step generated by the agent.\\nThen, this extended POMDP operates as follows.\\nGiven a task instruction u ∈U, the agent follows\\na policy πθ that alternates between generating a\\nthought as πthought\\nθ\\nand taking an executable action\\nas πact\\nθ . At each time step t, the agent receives an\\nobservation ot and forms a context ct = (ht, ot),\\nwhere ht = {u, τ1, a1, o1, . . . , τt, at} is the history\\nof previous interactions. Based on ct, the agent\\nsamples a thought from a context-conditioned dis-\\ntribution: τt ∼πthought\\nθ\\n(· | ct). This thought τt is\\nthen appended to the context to form an enriched\\ninput c′\\nt = ct ⊕τt, which is used to select the next\\naction: at ∼πact\\nθ (· | c′\\nt). The selected action at is\\nexecuted to the environment, resulting in the next\\nobservation ot+1. This reasoning–acting loop con-\\ntinues until the task is completed or a predefined\\ntime limit is reached.\\n3\\nRevisiting the Efficacy of Thought\\n3.1\\nHow Thought Impacts Action Selection\\nBasically the thought τt functions as a reweighting\\nmechanism for the action probability distribution\\nof the policy πact\\nθ\\nby enriching the context ct into\\nan augmented form: c′\\nt = ct ⊕τt.\\nWe analyzed this process in detail using a task\\nfrom ALFWorld (Shridhar et al., 2021), where the\\ntask is to find an apple, heat it, and place it in a\\ngarbage can. We implemented the policy πθ us-\\ning Llama-3.1-8B-Instruct (Grattafiori et al., 2024)\\nand compared two agent variants: the NoThinking\\nagent, which selects actions without intermediate\\nreasoning, and the ReAct agent, which generates a\\nreasoning step before each action. Figure 2 shows\\none instance of execution sequence. The sequence\\nstarts with the task description with initial obser-\\nvation, followed by two cycles of thought-action-\\nobservation, ending with observation \"You open\\nthe microwave 1. The microwave 1 is open. · · · \".\\nThen, in the next thought step, we tried each of four\\ncases: empty (i.e., no thought) and three thoughts\\n2'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 2}, page_content='in the middle of Figure 2, and observed the distri-\\nbution on actions in the next step.\\nObservation: You pick up the apple 1 from the countertop 1.\\nThought: Now I take an apple 1. Next, I need to go to a microwave 1 and heat it.\\nAction: go to microwave 1\\nObservation: The microwave 1 is closed.\\nThought: The microwave 1 is closed, so I need to open it first.\\nAction: open microwave 1\\nObservation: You open the microwave 1. The microwave 1 is open. In it, you see nothing.\\nThought: \\nAction: \\n[THOUGHT HERE]\\nTHOUGHT 1: I need to heat apple with microwave.\\nTHOUGHT 2: I think trying to cool the apple in the microwave might be a good idea.\\nTHOUGHT 3: I ate a hotdog this morning.\\nTask: heat some apple and put it in garbagecan.\\nTop 5 Action Probability\\nFigure 2: Changes in the action probability distribution\\nwhen modifying thought in the ALFWorld ‘heat some\\napple and put it in garbagecan’ task.\\nFirst, without any thought (NoThinking), the\\nagent assigns high probability to the heat action,\\nstill considering other actions such as ‘put’ and\\n‘go’ with non-negligible probabilities. Now, when\\na non-empty thought is provided, the next ac-\\ntion probability distribution is directly influenced:\\nTHOUGHT 1 relevant to the task sharpens the distri-\\nbution toward appropriate actions, leading to con-\\ntextually aligned selections. In contrast, THOUGHT\\n2 and THOUGHT 3, injecting incorrect or conflict-\\ning information, bias the distribution and increase\\nthe likelihood of inappropriate actions. As seen,\\nthought directly shapes the next action distribu-\\ntion, either reinforcing correct decisions or causing\\nmisalignment depending on its quality. When the\\nmodel is provided with a structured thought, it\\nrelies predominantly on that thought to drive de-\\ncision making, thereby significantly reducing its\\ndependence on the broader historical context.\\nTo quantify the overall impact of thought on the\\nagent’s decision-making process, we measured the\\nentropy of the agent’s action probability distribu-\\ntion across 134 tasks from ALFWorld. Specifically,\\nfor a given timestep t, the entropy is defined as\\nHNoThinking\\nt\\n= −\\nX\\na∈A\\nπact\\nθ (a | ct) log πact\\nθ (a | ct)\\nHReAct\\nt\\n= −\\nX\\na∈A\\nπact\\nθ (a | c′\\nt) log πact\\nθ (a | c′\\nt),\\nwhere c′\\nt = ct ⊕τt and τt ∼πthought\\nθ\\n(· | ct).\\nWe computed the entropy averaged over all\\ntimesteps and tasks, and the result is reported in\\nTable 1. As shown in the table, the NoThinking\\nTable 1: Average entropy of the action probability distri-\\nbution when performing 134 ALFWorld tasks using the\\nLlama-3.1-8B-Instruct with NoThinking and ReAct.\\nModel\\n¯\\nHNoThinking\\n¯\\nHReAct\\nLlama-3-1-8B-Instruct\\n1.23\\n0.30\\nagent exhibits mean entropy of 1.23, whereas the'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 2}, page_content='Table 1: Average entropy of the action probability distri-\\nbution when performing 134 ALFWorld tasks using the\\nLlama-3.1-8B-Instruct with NoThinking and ReAct.\\nModel\\n¯\\nHNoThinking\\n¯\\nHReAct\\nLlama-3-1-8B-Instruct\\n1.23\\n0.30\\nagent exhibits mean entropy of 1.23, whereas the\\nReAct agent yields a significantly lower value of\\n0.30. This substantial reduction in entropy implies\\nthat conditioning the policy on thought leads to\\nmore confident and focused behavior.\\n3.2\\nThe Problem of Ungrounded Thought\\nSince action at is heavily influenced by thought\\nτt ∼πthought\\nθ\\n(· | ct), it is crucial that τt accu-\\nrately captures the core decision-relevant informa-\\ntion from the context ct = (ht, ot). If the thought\\nbecomes ungrounded, meaning it is disconnected\\nfrom the actual state, it can mislead the policy and\\ninduce a suboptimal or incorrect action.\\nFigure 3: Comparison of failure rates between NoThink-\\ning and ReAct on GPT-4o and Llama-3.1-8B-Instruct\\nTo assess the overall performance degradation\\nfrom ungrounded thought, we evaluated task fail-\\nure rates across 134 ALFWorld (Shridhar et al.,\\n2021) tasks using πθ realized with GPT-4o (Ope-\\nnAI, 2024) and Llama-3.1-8B-Instruct (Grattafiori\\net al., 2024). Figure 3 categorizes the outcomes\\ninto four groups: (1) only the NoThinking agent\\nfailed, (2) only the ReAct agent failed, (3) both\\nfailed, and (4) both succeeded. As shown in the fig-\\nure, incorporating thought can help the agent solve\\ntasks that would otherwise fail without it. However,\\nthought also introduces new risks, causing failures\\nthat could have been avoided without thought, even\\nin stronger models like GPT-4o.\\nTo see the cause of the ReAct agent’s failure, we\\nexamined a failure case of the ReAct agent in ALF-\\nWorld (Shridhar et al., 2021). As seen in Figure 4\\n(1), the agent is given a simple task: Find a soap\\nbar, take it and place it on the countertop. After\\ninteracting with a soap bottle 2 in cabinet 1, the\\nagent attempts to return to cabinet 1 to search for\\nthe soap bar even though it is not there, because\\nthe generated thought does not capture the current\\n3'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 3}, page_content='→ Although the soapbar is already in cabinet 1, the agent mistakenly \\nthought it needed to return there, which caused the problem. It didn\\'t \\nattempt other paths and ultimately failed the task.\\n(1) Thought on next action\\n(2) Reflection on the current state in relation to   \\n       the task goal\\n→ By reflecting the current state and task goal, it guides more \\npromising actions to reach the task goal, ultimately leading to task \\nsuccess.\\nALFWorld: put a clean soapbar in countertop.\\nWrong Thinking\\n...\\nObservation: You open the cabinet 1. The cabinet 1 is open. In it, you see a soapbottle 2.\\nThought: I found a soapbottle 2 in the cabinet 1, but I need a soapbar. I should check if there\\'s a soapbar in the cabinet 1 or other receptacles. Since I already opened the cabinet 1, I \\ncan check its content again.\\nAction: take soapbottle 2 from cabinet 1\\n\\nObservation: You pick up the soapbottle 2 from the cabinet 1.\\nThought: I took a soapbottle 2, but I need a soapbar. I should try to find a soapbar in other receptacles. Since I already have an object in my hand, I can try to put it somewhere and \\nthen search for a soapbar.\\nAction: put soapbottle 2 in cabinet 1\\n\\nObservation: You put the soapbottle 2 in/on the cabinet 1.\\n\\n\\nThought: I put the soapbottle 2 back in the cabinet 1. Now I can search for a soapbar. I\\'ll \\ngo to the cabinet 1 again to check if there\\'s a soapbar.\\nAction: go to cabinet 1\\n\\nObservation: Nothing happens.\\nThought: Since \"Nothing happened\", my previous action was invalid. I should try to go to \\ncabinet 1 again, but this time, I should also check if there\\'s a soapbar in the cabinet 1.\\nAction: go to cabinet 1'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 3}, page_content=\"Observation: Nothing happens.\\nReflection: Currently, I am at cabinet 1, not holding anything, and I still haven't found \\nthe soap bar to place on the countertop.\\nAction: go to cabinet 2\\nFigure 4: In the ALFWorld task ‘put a clean soapbar in countertop’, the agent picks up a soapbottle from cabinet 1\\nand puts it back, (1) while planning the next action, it redundantly tries to go back to cabinet 1 and fails, (2) after\\nreflecting on the state and goal, it moves elsewhere and succeeds.\\nsituation in the context of goal properly from its\\nobservation history. This redundant and illogical\\nbehavior leads to a loop, and the agent ultimately\\nfails to complete the task. A failure case in Sci-\\nenceWorld is provided in Figure 9 in Appendix B.\\nFrom the examples, we see that the agent fails\\ndue to two major reasoning limitations:\\n(1) A lack of grounding in its internal state. The\\nagent fails to maintain a coherent internal state,\\nleading to inconsistency, e.g., revisiting a loca-\\ntion it already visited or falsely assuming it is\\nholding an object.\\n(2) Short-sighted planning. The ReAct agent\\ntypically exhibits short-sighted planning, mak-\\ning decisions that appear locally plausible but\\ndisregard the long-term task goal.\\nWe recognize that these two shortcomings stem\\nfrom incorrect guidance for the agent’s reasoning\\nprocess although the agent has better reasoning\\ncapability. Indeed, for the same failure scenario in\\nFigure 4 left branch, we input a reasoning guidance\\nsentence different from that of ReAct, to focus not\\non predicting the next step but assess the agent’s\\ncurrent state in relation to the task goal, as seen\\nin Figure 4 right branch. Now, it is seen that the\\nagent can better align its action with the overall\\nobjective by reflecting on what it currently knows\\nand what it aims to achieve. This is also valid\\nfor the ScienceWorld failure case in Figure 9 in\\nAppendix B.\\n4\\nProposed Method: ReflAct\\nIn the LLM POMDP framework, a thought τt ∈T\\nshould be generated so that it leads to the selec-\\ntion of an action at that maximizes the expected\\nlong-term return when used to condition the ac-\\ntion policy πact\\nθ , where the long-term return is de-\\nfined as Gt = P∞\\nk=0 γkRt+k with discount factor\\nγ ∈[0, 1). Here, Rt+k is the immediate reward at\\ntime t + k. Thus, the optimal thought τ ∗\\nt can be\\ndefined as\\nτ ∗\\nt = arg max\\nτ∈T\\nEa∼πact\\nθ (·|ct⊕τ) [E [Gt | st, a]] ,\\nwhere ct denotes the current context and ⊕de-\\nnotes concatenation. To maximize the expected\\nlong-term return, the thought τt should not be gen-\\nerated from the observation solely to decide the\\nnext action. Instead, it should be formed with con-\\nsideration of the final task goal at every time step,\\nas illustrated in Figure 1. In this way, the agent\\ncan rely on thought for action generation without\\ndeviating from a goal-reaching path. Furthermore,\\nsince the environment is partially observable and\"),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 3}, page_content='long-term return, the thought τt should not be gen-\\nerated from the observation solely to decide the\\nnext action. Instead, it should be formed with con-\\nsideration of the final task goal at every time step,\\nas illustrated in Figure 1. In this way, the agent\\ncan rely on thought for action generation without\\ndeviating from a goal-reaching path. Furthermore,\\nsince the environment is partially observable and\\nthe true state st is not directly accessible, the agent\\nmust rely on an internal belief state inferred from\\nits interaction history. So, the generated thought\\nshould make this belief more explicit and stable,\\nwhile encoding task-relevant reasoning that effec-\\ntively guides the downstream policy toward the\\nlong-term objective.\\nTo achieve the generation of such thoughts, we\\ndo not use an additional module but exploit the\\nLLM agent’s reasoning capability maximally. For\\n4'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 4}, page_content='this, we redesign a new thought generation instruc-\\ntion to better guide thought generation as follows:\\nInstruction for ReflAct\\nYou should first reflect on the agent’s state in rela-\\ntion to the task goal, and then output the action for\\nthis turn.\\nIn this new design, we have the explicit guiding\\nterms ‘agent’s state’, ‘task goal’ and their connec-\\ntion term ‘in relation to’ to realize the desired state\\ndiagram of thought dependency in the lower part\\nof Figure 1. Following this instruction, the agent\\nengages in reflective reasoning to gain a clearer\\nunderstanding of both the current situation and the\\nintended goal. We refer to so-generated thought\\nas reflection and name the new reflection-action\\nprocess ReflAct. To formalize this, we define a\\nreflection space K, where each reflection k ∈K\\nis a structured representation that aims to explic-\\nitly encode both the agent’s internal belief state M\\nand the task goal G. The belief state captures the\\nagent’s current understanding of the state based on\\nits interaction history, whereas the goal component\\nprovides a concise summary of what the agent is\\ntrying to achieve. By explicitly representing both\\nin the reflection, ReflAct allows the agent to con-\\ndition its subsequent decision-making on a more\\ncoherent and goal-aligned internal context.\\nExample of Thought vs Reflection Before Action\\nThought: Now I find a spraybottle 2. Next, I need to\\ntake it.\\nReflection: Currently, I am at cabinet 2 and have\\nfound a spraybottle 2, which brings me closer to\\ncompleting the task of placing it on the toilet.\\nIn addition, we incorporate one-shot examples\\nbased on the tasks from Yao et al. (2023); Xiong\\net al. (2025) modified with Reflections on the\\nagent’s state in relation to the task goal, gener-\\nated by GPT-4o-mini (OpenAI, 2024). Above, we\\npresent an example describing the modification\\nfrom Thought to Reflection. The complete set of\\none-shot examples is provided in Appendix H.\\n5\\nRelated Works\\nBuilding on CoT reasoning (Wei et al., 2022), nu-\\nmerous approaches attempted to enhance LLM\\nagent capability. ReAct (Yao et al., 2023) pio-\\nneered the interleaving of reasoning with action\\nsteps for interactive environments, while Plan-and-\\nSolve (Wang et al., 2023) introduced higher-level\\nplanning in the initial stage.\\nRecent enhance-\\nment modules sought to improve ReAct’s CoT\\nthrough various mechanisms: Reflexion (Shinn\\net al., 2024) through post-task analysis of fail-\\nures after task completion, WKM (Qiao et al.,\\n2024), MPO (Xiong et al., 2025), and DC (Suz-\\ngun et al., 2025) via external memory of envi-\\nronment knowledge, and RAFA (Liu et al., 2023)\\nby generating and evaluating future possible tra-\\njectory predictions. However, when the ReAct\\nbackbone incorrectly grounds past observations,\\nall these approaches suffer from degraded perfor-\\nmance. Therefore, ReflAct retouches the reasoning\\nprocess itself to enable more grounded and goal-\\naligned decision making. In our experiments, we\\nwill validate the importance of this approach com-\\npared to the design of enhancement modules, as'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 4}, page_content='by generating and evaluating future possible tra-\\njectory predictions. However, when the ReAct\\nbackbone incorrectly grounds past observations,\\nall these approaches suffer from degraded perfor-\\nmance. Therefore, ReflAct retouches the reasoning\\nprocess itself to enable more grounded and goal-\\naligned decision making. In our experiments, we\\nwill validate the importance of this approach com-\\npared to the design of enhancement modules, as\\nwell as its synergy with them. Additional related\\nworks are discussed in the Appendix A.\\n6\\nExperiments\\n6.1\\nExperimental Settings\\nBenchmarks.\\nWe benchmarked ReflAct on three\\nwidely used text-based environments: ALFWorld\\n(Shridhar et al., 2021), ScienceWorld (Wang et al.,\\n2022), and Jericho (Hausknecht et al., 2020). ALF-\\nWorld evaluates embodied agents on household\\ntasks, ScienceWorld assesses procedural and scien-\\ntific reasoning in educational scenarios, and Jeri-\\ncho tests agents in classic interactive fiction games\\nthat require commonsense reasoning and memory.\\nFor evaluation, ALFWorld uses binary task success,\\nwhile ScienceWorld and Jericho provide dense re-\\nward signals, enabling evaluation based on both\\nsuccess rate and average reward, calculated as the\\nmean reward across all tasks. Additional bench-\\nmark details are provided in Appendix C.\\nAgent Models.\\nWe use GPT-4o and GPT-4o-mini\\n(OpenAI, 2024), and Llama-3.1-8B/70B-Instruct\\n(Grattafiori et al., 2024) as underlying models.\\nGPT-4o variants serve as proprietary models, while\\nLlama-3.1-Instruct variants represent open-source\\ncounterparts, each with large and small sizes.\\n6.2\\nComparison with Prior Methods\\nBaselines.\\nWe first compare ReflAct with three\\nreasoning frameworks. Details for each can be\\nfound in Appendix D.1.\\n(1) NoThinking (Ma et al., 2025): The agent gen-\\nerates an action directly at each time step without\\nany reasoning step.\\n5'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 5}, page_content='Table 2: Performance comparison of ReflAct with NoThinking, ReAct, and Plan-and-Act across ALFWorld,\\nScienceWorld, and Jericho. SR and AR denote success ratio and average reward, respectively. Values in parentheses\\nindicate percentage improvement over the NoThinking baseline.\\nModel\\nPrompting\\nALFWorld\\nScienceWorld\\nJericho\\nAverage\\nSR\\nAR\\nSR\\nAR\\nSR\\nGPT-4o\\nNoThinking\\n76.1\\n67.4\\n50.2\\n27.8\\n10.0\\n46.3\\nReAct\\n85.1\\n68.7\\n55.9\\n50.4\\n20.0\\n56.0 (+21.0%)\\nPlan-and-Act\\n85.8\\n68.7\\n55.0\\n45.6\\n20.0\\n55.0 (+18.8%)\\nReflAct\\n93.3\\n68.9\\n57.8\\n53.2\\n35.0\\n61.6 (+33.1%)\\nGPT-4o-mini\\nNoThinking\\n43.3\\n42.3\\n21.8\\n18.8\\n5.0\\n26.2\\nReAct\\n53.0\\n49.1\\n37.0\\n29.8\\n15.0\\n36.8 (+40.2%)\\nPlan-and-Act\\n59.0\\n51.8\\n35.5\\n37.1\\n15.0\\n39.7 (+51.1%)\\nReflAct\\n66.4\\n55.4\\n37.0\\n45.4\\n20.0\\n44.8 (+70.9%)\\nLlama-3-1-8B\\n-Instruct\\nNoThinking\\n21.6\\n29.9\\n14.2\\n10.0\\n0.0\\n15.1\\nReAct\\n29.1\\n43.0\\n27.5\\n12.8\\n0.0\\n22.5 (+48.5%)\\nPlan-and-Act\\n30.6\\n34.2\\n14.7\\n10.6\\n0.0\\n18.0 (+19.0%)\\nReflAct\\n60.5\\n47.2\\n33.2\\n20.9\\n10.0\\n34.4 (+126.9%)\\nLlama-3-1-70B\\n-Instruct\\nNoThinking\\n53.7\\n65.6\\n46.4\\n27.4\\n5.0\\n39.6\\nReAct\\n81.3\\n66.4\\n53.1\\n33.9\\n10.0\\n48.9 (+23.5%)\\nPlan-and-Act\\n81.3\\n67.7\\n52.6\\n29.6\\n10.0\\n48.2 (+21.8%)\\nReflAct\\n83.6\\n73.7\\n58.8\\n44.5\\n20.0\\n56.1 (+41.6%)\\nFigure 5: A comparison of ReAct, ReflAct, and various verbalization strategies (state, goal, state+goal, and\\nstate+goal with next-action reasoning), using Llama-3.1-8B-Instruct as the agent model. Bars represent success\\nrate; the red dashed line indicates average reward.\\n(2) ReAct (Yao et al., 2023): The agent first reasons\\nabout the next action at each time step and then\\ngenerates an action.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 5}, page_content='state+goal with next-action reasoning), using Llama-3.1-8B-Instruct as the agent model. Bars represent success\\nrate; the red dashed line indicates average reward.\\n(2) ReAct (Yao et al., 2023): The agent first reasons\\nabout the next action at each time step and then\\ngenerates an action.\\n(3) Plan-and-Act: In addition to NoThinking and\\nReAct, we designed another reasoning framework\\ninspired by Plan-and-Solve (Wang et al., 2023) for\\ncomparison. Here, the agent is instructed at the first\\ntimestep (t = 1) to ‘plan your approach to the task,\\nand then output the action.’ It performs reasoning\\nonly at this step and outputs actions without further\\nthoughts in subsequent timesteps.\\nResults.\\nTable 2 presents the performance of\\nReflAct compared with the NoThinking, ReAct,\\nand Plan-and-Act baselines across ALFWorld, Sci-\\nenceWorld, and Jericho. As shown in the table, the\\nReAct agent outperforms the NoThinking agent,\\nhighlighting the effectiveness of the Thinking be-\\nfore Action framework. Plan-and-Act, which be-\\ngins with a single planning step and then executes\\nactions directly, performs comparably or slightly\\nbetter than ReAct in stronger models like GPT-\\n4o. This suggests that when a model has enough\\ncapacity, initial goal-based reasoning is effective,\\nand flawed intermediate reasoning may offer little\\nbenefit. However, in weaker models like Llama,\\nPlan-and-Act underperforms because these models\\nstruggle to retain and follow the initial plan. In\\ncontrast, ReflAct, which reflects on both the state\\nand the goal at every timestep, consistently out-\\nperforms all the baseline reasoning frameworks\\nregardless of backbone model or task. Notably,\\nReflAct achieved performance improvements of\\n77.9%, 25.9%, and 101.1% over NoThinking in\\nALFWorld, ScienceWorld, and Jericho, respec-\\ntively, and improvements of 36.4%, 8.5%, and\\n38.1% over ReAct in the same environments.\\nImportance of Reflection over Simply Stating.\\nTo verify the source of ReflAct’s superior perfor-\\n6'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 6}, page_content='mance gain, we conducted an ablation study. Re-\\nflAct reflects on the agent’s state in relation to the\\ntask goal, so we compared this with variants in\\nwhich the agent simply verbalizes its state, its goal,\\nor both, without engaging in reflection.\\nAs shown in Figure 5, we evaluated four settings:\\nthe agent verbalizes (1) the current state, (2) the\\ntask goal, (3) both the state and the goal, and (4) the\\nstate and goal while also reasoning about the next\\naction. The results indicate that merely stating the\\nstate or goal underperforms compared to the ReAct\\nbaseline. Adding an explicit next-action thought\\nin addition to verbalizing the state and goal yields\\nperformance gains in ALFWorld compared to Re-\\nAct, but still falls short of ReAct in ScienceWorld\\nand Jericho. In contrast, ReflAct, which explic-\\nitly reflects on the relationship between the state\\nand the goal, demonstrates a substantially greater\\nperformance gain. These findings suggest that re-\\nflection, specifically reasoning about the state in\\nthe context of the goal, is more effective than sim-\\nply verbalizing the state or the goal.\\n6.3\\nReflAct with Enhancement Modules\\nWe examine layering enhancement modules on top\\nof ReflAct. We consider Reflexion (Shinn et al.,\\n2024), the use of post-task reflection in ReAct to\\nimprove planning, and WKM (Qiao et al., 2024),\\nwhich incorporates a parametric world model into\\nReAct. Discussion on RAFA (Liu et al., 2023),\\nwhich focuses on long-sighted planning via next-\\nstate prediction, and MPO (Xiong et al., 2025),\\nwhich improves planning through online prefer-\\nence learning, can be found in Appendix F.\\n6.3.1\\nReflAct and Reflexion\\nReflexion (Shinn et al., 2024) performs post-task\\nreflection by analyzing failed trajectories and gen-\\nerating improvement plans for future trials. Since\\npost-task reflection operates independently of the\\nunderlying reasoning process, we analyze its im-\\npact when combined with three reasoning frame-\\nworks: NoThinking, ReAct, and ReflAct.\\nFigure 6 shows the results of applying Reflex-\\nion to each backbone in ALFWorld and Jericho.\\nWe followed Shinn et al. (2024) in applying post-\\ntask reflection after each trial, repeating this for\\nthree trials. The results show that post-task re-\\nflection generally improves performance across all\\nbase agents, except Llama NoThinking and ReAct\\nin Jericho. However, even after applying Reflex-\\nion, the NoThinking and ReAct agents still fall\\nFigure 6: Success rate change with Reflexion post-task\\nreflection (NoThinking, ReAct, ReflAct).\\nshort of ReflAct’s trial 0 performance. This high-\\nlights that when the initial reasoning backbone is\\nweak, even repeated feedback across trials provides\\nonly limited benefit. Although post-task reflection\\naids reasoning by analyzing failures, enhancing in-\\ntask reflection through a stronger backbone proves\\nmore fundamental. Notably, the GPT-4o ReflAct\\nagent with Reflexion achieved an unprecedented\\n94.8% success rate in ALFWorld, bringing house-\\nhold robots one step closer to reality, given suffi-\\ncient hardware support.\\n6.3.2'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 6}, page_content='weak, even repeated feedback across trials provides\\nonly limited benefit. Although post-task reflection\\naids reasoning by analyzing failures, enhancing in-\\ntask reflection through a stronger backbone proves\\nmore fundamental. Notably, the GPT-4o ReflAct\\nagent with Reflexion achieved an unprecedented\\n94.8% success rate in ALFWorld, bringing house-\\nhold robots one step closer to reality, given suffi-\\ncient hardware support.\\n6.3.2\\nReflAct and WKM\\nWKM (Qiao et al., 2024) improves LLM agents’\\ndecision-making in interactive environments by\\nusing Task Knowledge for global planning and\\nState Knowledge for local context. Its paramet-\\nric knowledge model, fine-tuned on knowledge-\\naugmented trajectories, enables context-aware\\ndecision-making by referencing past similar situa-\\ntions. WKM learns and utilizes an external knowl-\\nedge model in contrast to ReflAct, which intends\\nto perform internal state modeling within the rea-\\nsoning backbone.\\nWe applied WKM to ReAct and further exam-\\nined a scenario where state knowledge is placed\\nimmediately before action, replacing the thought,\\nto guide the action. This allows us to assess the\\nimpact of explicit state knowledge compared to\\nReflAct’s internal state modeling. Figure 7 shows\\nperformance related to WKM. Applying WKM to\\nReAct results in a performance improvement, but\\nit still falls short of ReflAct. Replacing the thought\\nstep with state knowledge to directly guide the ac-\\ntion actually degrades performance, highlighting\\nthe side effect of incorrect guidance from the ex-\\n7'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 7}, page_content='Figure 7: Performance: ReflAct, NoThinking, ReAct,\\nand ReAct+WKM with thought replaced by WKM state\\nknowledge (Llama-3.1-8B-Instruct as agent)\\nternal model. This suggests that encouraging the\\nmodel to perform internal state modeling on its\\nown can be more effective than relying on state\\nknowledge generated by an external model.\\n6.4\\nFurther Discussion on ReflAct’s Ability\\nIn this section, we analyze how ReflAct success-\\nfully solves tasks, and in Appendix G, we compare\\nthe hallucinated action ratio and token length be-\\ntween ReflAct and baseline reasoning frameworks.\\n6.4.1\\nFailure Ratio Comparison Between\\nReasoning Frameworks\\nBuilding on the discussion of Figure 3 in Section\\n3.2, we analyze the proportion of tasks failed by\\nthe NoThinking, ReAct, and ReflAct agents across\\n134 tasks in the ALFWorld domain.\\nFigure 8: Failure ratio comparison diagram of NoThink-\\ning, ReAct, and ReflAct on 134 ALFWorld tasks, using\\nGPT-4o and Llama-3.1-8B-Instruct as agent models.\\nFigure 8 illustrates the failure distribution\\namong the three agents. Consistent with earlier\\nobservations, the NoThinking agent accounts for\\nthe largest number of unique failures, especially in\\ntasks where it alone fails. The ReAct agent, while\\nincorporating reasoning, introduces additional fail-\\nure cases not observed in NoThinking. This sug-\\ngests that ungrounded or incorrect reasoning can\\nlead to novel and potentially harmful errors. No-\\ntably, there are no tasks in which only the ReflAct\\nagent fails. ReflAct fails only in cases where other\\nagents also fail, and does not introduce new failure\\nmodes. This highlights the benefit of reflection\\ngrounded in the agent’s state and task goal, sug-\\ngesting that reflective reasoning contributes to safer\\nand more reliable decision-making in LLM agents.\\n6.4.2\\nReflAct Self-Corrects Automatically\\nLLM agents, especially when operating in unfa-\\nmiliar environments with only partially observable\\ninformation, are prone to making mistakes. There-\\nfore, it is essential that they possess the ability to\\nself-correct by identifying the cause of their errors\\nand adjusting their behavior accordingly to return\\nto a correct course of action. The example below\\nby a ReflAct agent demonstrates that ReflAct main-\\ntains an internal belief over the current state and\\ncontinuously aligns its decision-making with the\\ntask goal, enabling the agent to recognize mistakes\\nand flexibly recover from them, ultimately guiding\\nitself back onto the correct path.\\nYour task is cool some lettuce and\\nput it in countertop.\\n...\\nAction:\\ntake lettuce 1 from countertop 2\\nObs:\\nYou pick up the lettuce 1 from the\\ncountertop 2.\\nReflection:\\nI am at countertop 2, holding\\nlettuce 1.\\nI need to cool the lettuce\\nbefore putting it on the countertop to\\ncomplete the task.\\nAction:\\ncool lettuce 1 with fridge 1\\nObs:\\nNothing happens.\\nReflection:\\nI am at countertop 2, holding\\nlettuce 1.\\nThe action to cool the lettuce\\nwith the fridge did not work because I need\\nto be at the fridge to perform that action.\\nAction:\\ngo to fridge 1'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 7}, page_content='lettuce 1.\\nI need to cool the lettuce\\nbefore putting it on the countertop to\\ncomplete the task.\\nAction:\\ncool lettuce 1 with fridge 1\\nObs:\\nNothing happens.\\nReflection:\\nI am at countertop 2, holding\\nlettuce 1.\\nThe action to cool the lettuce\\nwith the fridge did not work because I need\\nto be at the fridge to perform that action.\\nAction:\\ngo to fridge 1\\nObs:\\nThe fridge 1 is open.\\nIn it, ...\\nReflection:\\nI am at fridge 1, holding\\nlettuce 1.\\nI can cool the lettuce now that\\nI’m at the fridge.\\nAction:\\ncool lettuce 1 with fridge 1\\nObs:\\nYou cool the lettuce 1 using the\\nfridge 1.\\n...\\n7\\nConclusion\\nWe have proposed ReflAct, a reflection-based rea-\\nsoning framework that addresses key limitations\\nof ReAct. While ReAct focuses on next-action\\nthinking, it often fails to maintain coherent internal\\nbeliefs about the environment and goal, leading\\nto poor decisions in complex, partially observable\\ntasks. In contrast, ReflAct emphasizes ongoing re-\\nflection on state and goal, enabling more grounded\\nand reliable decision making. Our experiments\\nshow that ReflAct consistently outperforms ReAct\\nand other baselines, demonstrating the value of re-\\nflection in long-horizon reasoning. We hope this\\nwork inspires further research into more robust\\nand informative reasoning guidance for intelligent\\nagents.\\n8'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 8}, page_content='Limitations\\nWhile ReflAct shows strong performance in in-\\nteractive agent environments, its applicability to\\nother domains such as mathematics and coding\\nremains unexplored. These tasks pose unique chal-\\nlenges: mathematics requires step-by-step deduc-\\ntion, while programming demands consistency in\\nlogic, state, and syntax. Extending ReflAct to these\\nareas may require adapting its reflection mecha-\\nnism to better align the current state with task-\\nspecific goals. Incorporating structured reason-\\ning that explicitly supports goal-state alignment\\ncould enhance performance, and we consider this\\na promising direction for future work.\\nIn addition, as discussed in Appendix G, Re-\\nflAct results in a modest increase in token length\\ncompared to ReAct. To address this, it is worth ex-\\nploring more efficient formulations that retain the\\nbenefits of state-goal reflection while reducing ver-\\nbosity. Possible approaches include compressing\\nreflection outputs, using more concise representa-\\ntions of reasoning steps, or integrating summariza-\\ntion modules to maintain informativeness within a\\nsmaller token budget.\\nFinally, there is growing interest in enhancing\\nreasoning with external modules. Incorporating\\nsuch components into ReflAct could further im-\\nprove its reflection process. For example, an exter-\\nnal verifier might evaluate reflected goals or sug-\\ngest fixes for inconsistencies. Exploring such hy-\\nbrid architectures remains a promising direction\\nfor future research.\\nEthical Statements\\nWhile LLM Agents represent powerful tools with\\nsignificant practical applications, they also pose\\nsubstantial risks if misused or deployed without\\nproper safeguards. Of particular concern is their\\ntendency to hallucinate or generate ungrounded rea-\\nsoning, which can lead to unreliable or potentially\\nharmful decisions in real-world contexts. This re-\\nsearch aims to address these challenges by develop-\\ning more grounded decision-making frameworks\\nthat enhance reliability and reduce hallucination.\\nBy focusing on improving the alignment between\\nthe agent’s internal beliefs and the actual environ-\\nment state, our work contributes to the broader\\ngoal of creating more trustworthy AI systems that\\ncan safely operate in complex, partially observable\\nenvironments while maintaining consistent goal-\\ndirected behavior.\\nReferences\\nMa Chang, Junlei Zhang, Zhihao Zhu, Cheng Yang,\\nYujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng\\nKong, and Junxian He. 2024. Agentboard: An an-\\nalytical evaluation board of multi-turn llm agents.\\nAdvances in Neural Information Processing Systems,\\n37:74325–74362.\\nYuri Chervonyi, Trieu H Trinh, Miroslav Olšák, Xi-\\naomeng Yang, Hoang Nguyen, Marcelo Menegali,\\nJunehyuk Jung, Vikas Verma, Quoc V Le, and Thang\\nLuong. 2025. Gold-medalist performance in solv-\\ning olympiad geometry with alphageometry2. arXiv\\npreprint arXiv:2502.03544.\\nAli Forootani. 2025. A survey on mathematical rea-\\nsoning and optimization with large language models.\\narXiv preprint arXiv:2503.17726.\\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 8}, page_content='preprint arXiv:2502.03544.\\nAli Forootani. 2025. A survey on mathematical rea-\\nsoning and optimization with large language models.\\narXiv preprint arXiv:2503.17726.\\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-\\nDahle, Aiesha Letman, Akhil Mathur, Alan Schelten,\\nAlex Vaughan, and 1 others. 2024. The llama 3 herd\\nof models. arXiv preprint arXiv:2407.21783.\\nDavid Ha and Jürgen Schmidhuber. 2018. World mod-\\nels. arXiv preprint arXiv:1803.10122.\\nDanijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mo-\\nhammad Norouzi. 2019. Dream to control: Learn-\\ning behaviors by latent imagination. arXiv preprint\\narXiv:1912.01603.\\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timo-\\nthy Lillicrap. 2025. Mastering diverse control tasks\\nthrough world models. Nature, pages 1–7.\\nShibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong,\\nZhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023.\\nReasoning with language model is planning with\\nworld model. arXiv preprint arXiv:2305.14992.\\nMatthew Hausknecht, Prithviraj Ammanabrolu, Marc-\\nAlexandre Côté, and Xingdi Yuan. 2020. Interactive\\nfiction games: A colossal adventure. In Proceedings\\nof the AAAI Conference on Artificial Intelligence,\\nvolume 34, pages 7903–7910.\\nMatthew J Hausknecht and Peter Stone. 2015. Deep\\nrecurrent q-learning for partially observable mdps.\\nIn AAAI fall symposia, volume 45, page 141.\\nLeslie Pack Kaelbling, Michael L Littman, and An-\\nthony R Cassandra. 1998. Planning and acting in\\npartially observable stochastic domains. Artificial\\nintelligence, 101(1-2):99–134.\\nJacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol\\nHausman, Brian Ichter, Pete Florence, and Andy\\nZeng. 2023.\\nCode as policies: Language model\\nprograms for embodied control. In 2023 IEEE In-\\nternational Conference on Robotics and Automation\\n(ICRA), pages 9493–9500. IEEE.\\n9'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 9}, page_content='Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo,\\nShuqi Ke, Boyi Liu, and Zhaoran Wang. 2023. Rea-\\nson for future, act for now: A principled framework\\nfor autonomous llm agents with provable sample\\nefficiency. arXiv preprint arXiv:2309.17382.\\nWenjie Ma, Jingxuan He, Charlie Snell, Tyler Griggs,\\nSewon Min, and Matei Zaharia. 2025. Reasoning\\nmodels can be effective without thinking.\\narXiv\\npreprint arXiv:2504.09858.\\nJunhyuk Oh, Valliappa Chockalingam, Honglak Lee,\\nand 1 others. 2016. Control of memory, active per-\\nception, and action in minecraft. In International\\nconference on machine learning, pages 2790–2799.\\nPMLR.\\nOpenAI. 2024. Hello gpt-4o.\\nMartin L Puterman. 1990. Markov decision processes.\\nHandbooks in operations research and management\\nscience, 2:331–434.\\nShuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu,\\nXiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie,\\nFei Huang, and Huajun Chen. 2024. Agent planning\\nwith world knowledge model. In The Thirty-eighth\\nAnnual Conference on Neural Information Process-\\ning Systems.\\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\\npher D Manning, Stefano Ermon, and Chelsea Finn.\\n2024. Direct preference optimization: Your language\\nmodel is secretly a reward model. Advances in Neu-\\nral Information Processing Systems, 36.\\nAndres Rodriguez, Ronald Parr, and Daphne Koller.\\n1999. Reinforcement learning using approximate\\nbelief states. Advances in Neural Information Pro-\\ncessing Systems, 12.\\nJulian Schrittwieser, Ioannis Antonoglou, Thomas Hu-\\nbert, Karen Simonyan, Laurent Sifre, Simon Schmitt,\\nArthur Guez, Edward Lockhart, Demis Hassabis,\\nThore Graepel, and 1 others. 2020. Mastering atari,\\ngo, chess and shogi by planning with a learned model.\\nNature, 588(7839):604–609.\\nNoah Shinn, Federico Cassano, Ashwin Gopinath,\\nKarthik Narasimhan, and Shunyu Yao. 2024. Re-\\nflexion: Language agents with verbal reinforcement\\nlearning. Advances in Neural Information Process-\\ning Systems, 36.\\nKeisuke Shirai, Cristian C Beltran-Hernandez, Masashi\\nHamaya, Atsushi Hashimoto, Shohei Tanaka, Kento\\nKawaharazuka, Kazutoshi Tanaka, Yoshitaka Ushiku,\\nand Shinsuke Mori. 2024. Vision-language inter-\\npreter for robot task planning. In 2024 IEEE Inter-\\nnational Conference on Robotics and Automation\\n(ICRA), pages 2051–2058. IEEE.\\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote,\\nYonatan Bisk,\\nAdam Trischler,\\nand Matthew\\nHausknecht. 2021. {ALFW}orld: Aligning text and'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 9}, page_content='preter for robot task planning. In 2024 IEEE Inter-\\nnational Conference on Robotics and Automation\\n(ICRA), pages 2051–2058. IEEE.\\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote,\\nYonatan Bisk,\\nAdam Trischler,\\nand Matthew\\nHausknecht. 2021. {ALFW}orld: Aligning text and\\nembodied environments for interactive learning. In\\nInternational Conference on Learning Representa-\\ntions.\\nYifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian\\nLi, and Bill Yuchen Lin. 2024.\\nTrial and error:\\nExploration-based trajectory optimization of llm\\nagents. In Proceedings of the 62nd Annual Meet-\\ning of the Association for Computational Linguistics\\n(Volume 1: Long Papers), pages 7584–7600.\\nMirac Suzgun, Mert Yuksekgonul, Federico Bianchi,\\nDan Jurafsky, and James Zou. 2025. Dynamic cheat-\\nsheet: Test-time learning with adaptive memory.\\narXiv preprint arXiv:2504.07952.\\nMudit Verma, Siddhant Bhambri, and Subbarao Kamb-\\nhampati. 2024. On the brittle foundations of react\\nprompting for agentic large language models. arXiv\\npreprint arXiv:2405.13966.\\nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi\\nLan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023. Plan-\\nand-solve prompting: Improving zero-shot chain-\\nof-thought reasoning by large language models. In\\nProceedings of the 61st Annual Meeting of the As-\\nsociation for Computational Linguistics (Volume 1:\\nLong Papers), pages 2609–2634.\\nRuoyao Wang, Peter Jansen, Marc-Alexandre Côté, and\\nPrithviraj Ammanabrolu. 2022. Scienceworld: Is\\nyour agent smarter than a 5th grader? In Proceedings\\nof the 2022 Conference on Empirical Methods in\\nNatural Language Processing, pages 11279–11298.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\\nand 1 others. 2022. Chain-of-thought prompting\\nelicits reasoning in large language models. Advances\\nin neural information processing systems, 35:24824–\\n24837.\\nYiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang,\\nand Qingyun Wu. 2024. Stateflow: Enhancing llm\\ntask-solving through state-driven workflows. In First\\nConference on Language Modeling.\\nWeimin Xiong, Yifan Song, Qingxiu Dong, Bingchan\\nZhao, Feifan Song, Xun Wang, and Sujian Li. 2025.\\nMpo: Boosting llm agents with meta plan optimiza-\\ntion. arXiv preprint arXiv:2503.02682.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\\nShafran, Karthik R Narasimhan, and Yuan Cao. 2023.\\nReact: Synergizing reasoning and acting in language\\nmodels. In The Eleventh International Conference'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 9}, page_content='Mpo: Boosting llm agents with meta plan optimiza-\\ntion. arXiv preprint arXiv:2503.02682.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\\nShafran, Karthik R Narasimhan, and Yuan Cao. 2023.\\nReact: Synergizing reasoning and acting in language\\nmodels. In The Eleventh International Conference\\non Learning Representations.\\nWangchunshu Zhou, Yuchen Eleanor Jiang, Long Li,\\nJialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang,\\nJing Chen, Ruipu Wu, Shuai Wang, and 1 oth-\\ners. 2023.\\nAgents: An open-source framework\\nfor autonomous language agents.\\narXiv preprint\\narXiv:2309.07870.\\n10'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 10}, page_content='A\\nExpanded Related Works\\nBelief-State Modeling in RL.\\nReinforcement\\nLearning (RL) has aimed to endow agents with\\nan internal state representation that captures all\\nrelevant information from past observations (Ro-\\ndriguez et al., 1999). In partially observable en-\\nvironments, this often takes the form of a belief\\nstate, a probability distribution over possible world\\nstates, which is updated as new observations are\\nreceived. Kaelbling et al. (1998) describe plan-\\nning as tracking a sufficient statistic of the history\\n(i.e., the belief), which serves as the agent’s core\\nstate for action selection. This approach has been\\nfurther developed in deep RL, where agents learn\\nto track belief states using recurrent neural net-\\nworks (Hausknecht and Stone, 2015), memory-\\naugmented architectures (Oh et al., 2016), and\\nworld models (Ha and Schmidhuber, 2018). Vari-\\nous studies (Hafner et al., 2019; Schrittwieser et al.,\\n2020; Hafner et al., 2025) have demonstrated the ef-\\nfectiveness of belief state modeling, enabling more\\neffective planning and reliable decision-making.\\nState Representations in LLMs.\\nSimilar to\\nbelief-state modeling in RL, recent work on LLMs\\nhas explored how internal or external state rep-\\nresentations can support reasoning and planning.\\nOne line of research adopts an extrinsic model-\\ning approach, inspired by the Code-as-Policies\\nparadigm (Liang et al., 2023), in which observa-\\ntions are structured into symbolic formats such as\\ntextual summaries, PDDL, or finite state machines,\\nand explicitly injected into the prompt. These de-\\nsigns enhance grounding and interpretability in\\nrobotic tasks, but they typically rely on predefined\\ncode or external modules to maintain and update\\nthe state representation (Hao et al., 2023; Shirai\\net al., 2024; Wu et al., 2024).\\nWhile prior work investigates whether LLMs\\ninternally form task-relevant abstractions, ReflAct\\nadvances this line of research by explicitly prompt-\\ning models to articulate and reflect on such ab-\\nstractions. By encouraging LLMs to generate and\\nreason over goal-conditioned state representations,\\nReflAct facilitates more grounded and efficient\\ndecision-making during interaction.\\nBackbone Reasoning Frameworks.\\nThe emer-\\ngence of LLMs has introduced new agent design\\nparadigms, especially via prompting-based reason-\\ning strategies. CoT prompting (Wei et al., 2022)\\nshowed that models can handle complex tasks by\\noutlining intermediate steps. ReAct (Yao et al.,\\n2023) extended this to interactive settings by in-\\nterleaving reasoning and action, while Plan-and-\\nSolve (Wang et al., 2023) added high-level plan-\\nning before stepwise execution. However, recent\\nstudies (Ma et al., 2025) argue that these CoT-\\nbased approaches are often token-inefficient and\\nprone to hallucinations. We attribute these reliabil-\\nity issues to the absence of an explicit belief state.\\nReflAct addresses this by maintaining and reflect-\\ning belief states to guide reasoning and improve\\nboth efficiency and reliability.\\nEnhancement Reasoning Modules.\\nRecently,\\na growing body of research has explored add-on'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 10}, page_content='studies (Ma et al., 2025) argue that these CoT-\\nbased approaches are often token-inefficient and\\nprone to hallucinations. We attribute these reliabil-\\nity issues to the absence of an explicit belief state.\\nReflAct addresses this by maintaining and reflect-\\ning belief states to guide reasoning and improve\\nboth efficiency and reliability.\\nEnhancement Reasoning Modules.\\nRecently,\\na growing body of research has explored add-on\\nor post-processing modules that operate on top of\\nreasoning backbones to enhance reasoning capa-\\nbilities. Reflexion (Shinn et al., 2024) improves\\nperformance by analyzing failed trajectories and\\nstoring insights for future use. WKM (Qiao et al.,\\n2024) mitigates hallucinations by grounding deci-\\nsions in a learned world model that reflects realistic\\ndynamics. RAFA (Liu et al., 2023) strengthens the\\nreasoning-acting link by imagining future trajecto-\\nries and evaluating them with separate Model and\\nCritic components, forming a structured loop of\\nplanning, action, and feedback. Unlike these ap-\\nproaches, ReflAct is not layered on top of a reason-\\ning backbone but instead redefines the backbone\\nitself, enabling more efficient reasoning.\\nB\\nAnother Case of the Problem of\\nUngrounded Thought\\nIn addition to the discussion of the ReAct agent’s\\nfailure case in Figure 4 in Section 3.2, we examine\\nanother failure case in ScienceWorld (Wang et al.,\\n2022). As shown in Figure 9 (1), the agent is\\ntasked with boiling lead. To do this, the agent must\\nfind lead, transfer it to a suitable heat source, and\\nthen boil it. During the previous steps, the agent\\nsuccessfully located the lead in the workshop. Now,\\nthe agent must carry it to the foundry. However, the\\nagent mistakenly assumes that it is already holding\\nthe lead and proceeds with the next action based\\non this false assumption, ultimately resulting in a\\nhallucination.\\nIn the same situation, similar to the discussion\\nin Section 3.2, we replace the thought with a re-\\nflection sentence about the current state and task\\ngoal, as seen in the right branch of Figure 9. This\\nallows the agent to clearly recognize the current\\nsituation, make goal-aware long horizon decisions,\\nand ultimately succeed in the task.\\n11'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 11}, page_content=\"→ Although the agent has only found the lead and has not yet picked \\nit up, it is already planning its next move as if it had.\\n→ By reflecting the current state and task goal, it guides more \\npromising actions to reach the task goal, ultimately leading to task \\nsuccess.\\nScienceWorld: Your task is to boil lead. First, focus on the substance. Then, take actions that will cause it to change its state of matter.\\nWrong Thinking\\n...\\nObservation: You teleport to the workshop\\nThought: Now that I'm in the workshop, I should look around to find lead. Lead is often used in metalworking, so it's likely to be found in a container or on a workbench.\\nAction: look around\\nObservation: This room is called the workshop. Inside, you see the agent, a substance called air, and a table.\\nOn the table, there is a battery, a green wire, an orange light bulb (which is off), an orange wire, a paper cup containing a substance called lead, a red wire, a switch (which is off), a \\nviolet light bulb (which is off), and a yellow light bulb (which is off).\\nThought: I see a paper cup containing lead on the table in the workshop. Now that I have \\nlead, I need to heat it to boil it. I can use the blast furnace in the foundry to heat the lead.\\nAction: teleport to foundry\\n(1) Thought on next action\\n(2) Reflection on the current state in relation to   \\n       the task goal\\nReflection t+2: I am currently in the workshop and have found a paper cup containing \\nlead, the substance I need to focus on and whose state of matter I need to change.\\nAction: pick up cup containing lead\\nFigure 9: Another failure case of ReAct, following Figure 4, is seen in the ScienceWorld task boil lead. The agent\\nfinds the lead in the workshop. (1) It mistakenly believes it is holding the lead, proceeds with the task, and fails. (2)\\nAfter reflecting on its current state in relation to the task goal, the agent correctly recognizes its situation, takes\\ngoal-aware actions, and successfully completes the task.\\nC\\nBenchmark Details\\n• ALFWorld (Shridhar et al., 2021): ALFWorld\\nis a text-based benchmark derived from the AL-\\nFRED dataset, designed to evaluate an agent’s\\nability to interpret and execute natural language\\ninstructions in interactive, multi-step household\\ntasks. It converts embodied vision-and-language\\ntasks into textual form, allowing for assessment\\nof high-level planning, language grounding, and\\nsequential decision making in a simulated envi-\\nronment.\\n• ScienceWorld (Wang et al., 2022): Science-\\nWorld is a text-based benchmark for evaluating\\nagents on scientific reasoning and procedural\\ntask completion. Grounded in standardized K–12\\nscience curricula, it tests an agent’s ability to fol-\\nlow instructions, perform virtual experiments,\\nmake causal inferences, and manipulate objects\\nacross domains such as physics, chemistry, and\\nbiology. Tasks require multi-step interaction, hy-\\npothesis testing, and language grounding in a\\ndynamic environment.\\n• Jericho (Hausknecht et al., 2020): Jericho is a\\nsuite of text-based adventure games, each with\\ndistinct environments and roles. Tasks require\\ncompleting a sequence of implicit subgoals, of-\"),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 11}, page_content='make causal inferences, and manipulate objects\\nacross domains such as physics, chemistry, and\\nbiology. Tasks require multi-step interaction, hy-\\npothesis testing, and language grounding in a\\ndynamic environment.\\n• Jericho (Hausknecht et al., 2020): Jericho is a\\nsuite of text-based adventure games, each with\\ndistinct environments and roles. Tasks require\\ncompleting a sequence of implicit subgoals, of-\\nten in specific order. Since these subgoals often\\ndo not follow intuitive causal logic, agents must\\nrely on interaction to model the environment and\\naccurately infer their current state.\\nIn ALFWorld, success is measured using a bi-\\nnary signal: agents receive a reward of 1 only\\nwhen the task is fully completed, and 0 otherwise.\\nIn contrast, the official environments of Science-\\nWorld and Jericho provide both a success flag and\\na progress reward, which assigns a value between\\n0 and 1 based on the degree of task completion.\\nHowever, we discovered a bug in both Science-\\nWorld and Jericho where the success flag could\\nbe incorrectly set even when the progress reward\\nwas low or incomplete. For example, in Jericho,\\na task was sometimes marked as successful even\\nwhen the agent died during execution. To address\\nthis, we adjusted the success criteria: a task was\\nconsidered successful only if the progress reward\\nwas at least 0.7 in ScienceWorld, or exactly 1.0 in\\nJericho.\\nIn our experiments, the setups for ALFWorld\\nand ScienceWorld were based on the official im-\\nplementation by MPO (Xiong et al., 2025) (https:\\n//github.com/WeiminXiong/MPO), and we used\\nthe same test set for evaluation. The ALFWorld\\ntest set consists of 134 tasks across six different\\nhousehold task types, including ‘pick-and-place’,\\n‘pick-heat-then-place’, and ‘pick-two-and-place’.\\nThe ScienceWorld test set includes 211 tasks across\\n24 different scientific experiment types, including\\n‘Boil’, ‘Test Conductivity of Unknown Substances’,\\nand ‘Grow Fruit’.\\nThe experiments for Jericho were based\\non the implementation by AgentBoard (Chang\\net al., 2024) (https://github.com/hkust-nlp/\\nAgentBoard).\\nThe Jericho test set consists of\\n20 tasks, each corresponding to a different game,\\nincluding 905, Acorncourt, Afflicted, Balances,\\nDragon, Jewel, Library, Omniquest, Reverb, Snack-\\ntime, Zenon, Zork1, Zork2, Zork3, Detective,\\nNight, Pentari, Weapon, Darkhunt, and Loose.\\n12'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 12}, page_content='D\\nBaseline Details\\nD.1\\nBaselines for Backbone Reasoning\\nFrameworks\\nWe use the same environment code base and test set\\nfor all reasoning frameworks, including ReflAct.\\nFor specific environments, we follow existing im-\\nplementations: ALFWorld and ScienceWorld are\\nbased on the implementation by MPO (Xiong et al.,\\n2025), and Jericho is based on the implementation\\nby AgentBoard (Chang et al., 2024), as described\\nin detail in the section above. We implement base-\\nline reasoning frameworks using the following in-\\nstructions:\\n• Instruction for NoThinking\\nYou should directly output the action in this turn.\\n• Instruction for ReAct\\nYou should first think about the current condition\\nand plan for your future actions, and then out-\\nput your action in this turn.\\nNote that this ReAct instruction is from Song\\net al. (2024); Xiong et al. (2025).\\n• Instruction for Plan-and-Act\\nYou should first think about the given task and plan\\nyour approach to the task, and then output the\\naction for this turn.\\nThe one-shot example for ReAct is based on\\nYao et al. (2023); Xiong et al. (2025) and can be\\nfound in Appendix H. For NoThinking, we remove\\nthe thought step from all timesteps in the same\\nexample. For Plan-and-Act, we retain only the\\nthought from the first timestep (t = 1). We will\\nrelease the public implementation repository after\\npublication.\\nD.2\\nBaselines for Enhancement Reasoning\\nModules\\nIn our experiments, we discuss four enhanced\\nreasoning modules: Reflexion (Shinn et al., 2024)\\nand WKM (Qiao et al., 2024) in Section 6.3, and\\nRAFA (Liu et al., 2023), MPO (Xiong et al., 2025),\\nand ReflAct in Appendix F. We implemented\\neach module based on the official repositories\\nprovided by the original papers. For Reflexion, we\\nused the official implementation on top of each\\nenvironment’s base code: ALFWorld and Science-\\nWorld from Xiong et al. (2025), and Jericho from\\nChang et al. (2024). In addition, for WKM, we\\nused the publicly available dataset on Hugging\\nFace (https://huggingface.co/collections/\\nzjunlp/wkm-6684c611102213b6d8104f84)\\nto\\nreproduce the original setup and conducted\\nexperiments using WKM’s world model.\\n• Reflexion (Shinn et al., 2024):\\nhttps://\\ngithub.com/noahshinn/reflexion\\n• WKM (Qiao et al., 2024): https://github.\\ncom/zjunlp/WKM\\n• RAFA (Liu et al., 2023):\\nhttps://github.\\ncom/agentification/RAFA_code\\n• MPO (Xiong et al., 2025): https://github.\\ncom/WeiminXiong/MPO\\nE\\nResources\\nFor inference with the Llama3.1-Instruct model,\\nwe used one A6000 48GB GPU for the 8B model\\nand two A100 80GB GPUs for the 70B model.\\nFor training the WKM world model, we used four\\nA6000 48GB GPUs.\\nF\\nMore Discussion on Enhancement'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 12}, page_content='com/WeiminXiong/MPO\\nE\\nResources\\nFor inference with the Llama3.1-Instruct model,\\nwe used one A6000 48GB GPU for the 8B model\\nand two A100 80GB GPUs for the 70B model.\\nFor training the WKM world model, we used four\\nA6000 48GB GPUs.\\nF\\nMore Discussion on Enhancement\\nModules\\nF.1\\nReflAct and RAFA\\nRAFA (Liu et al., 2023) introduces a next-state\\nprediction framework where a language model re-\\ncursively expands a tree of possible future action-\\nobservation trajectories, selecting actions based on\\nthe highest estimated value. While this foresight\\naids long-term reasoning, ReflAct offers practical\\nadvantages in efficiency and grounded decision-\\nmaking by internally modeling the current state.\\n On the desk 2, you \\nsee a alarmclock 1 ...\\ntake alarmclock 1 \\nfrom desk 2\\nI am at desk 2 with \\nthe alarm clock ...\\nReflection\\nAction\\n# of model queries per step = 13\\nMQ : 2\\nMQ : 4\\nMQ : 4\\nMQ : 1\\n(MQ = Model Queries to LM)\\nMQ : 2\\nCandidate\\nActions\\nPredicted\\nObs\\nValue\\nEstimate\\nCandidate\\nActions\\nObs\\nObs\\nPredicted\\nObs\\n# of model queries per step = 1\\nopen drawer 4\\ngo to drawer 4\\nTask : examine the alarmclock with the desklamp\\ngo to drawer 2\\ngo to desk 1\\ntake mug 1 \\nfrom desk 2\\ngo to drawer 1\\n On the desk 2, you \\nsee a alarmclock 1 ...\\nRAFA\\n(depth = 2, branch = 2)\\nReflAct\\nSelect action\\nwith highest value\\n*\\n*\\nFigure 10: Comparison between RAFA and ReflAct.\\n13'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 13}, page_content='As shown in Figure 10, RAFA constructs a tree\\nat each time step t, requiring 13 queries to the\\nlanguage model per step with depth d = 2 and\\nbranching factor b = 2: 3 for action sampling, 6\\nfor observation prediction, and 4 for value estima-\\ntion. This overhead grows rapidly with depth due\\nto exponential node expansion. In contrast, ReflAct\\nneeds only a single query per step to jointly pro-\\nduce a reflection and action, offering constant cost\\nand greater efficiency when latency or throughput\\nis constrained.\\nFigure 10 also highlights a behavioral difference\\nbetween the two methods. Given the task \"examine\\nthe alarmclock with the desklamp\" in ALFWorld,\\nboth agents observe an alarmclock on desk 2. Re-\\nflAct grounds its reflection in this state and selects\\nthe correct action, while RAFA relies on predicted\\ntrajectories that miss the action and lead to an un-\\nrelated exploratory move. This shows that ReflAct\\naligns decisions more closely with the actual state,\\nachieving more reliable behavior with significantly\\nlower cost via a single LLM call per step.\\nF.2\\nReflAct and MPO\\nRecently, Xiong et al. (2025) proposed a frame-\\nwork that enhances LLM agents by generating and\\nrefining high-level meta plans based on agent feed-\\nback. The meta plans are initially learned through\\nsupervised fine-tuning on expert-generated exam-\\nples and subsequently optimized via preference-\\nbased learning (Rafailov et al., 2024) using feed-\\nback from agent executions. The resulting meta\\nplanner can be applied to various agents in a\\nplug-and-play manner without requiring additional\\nretraining.\\nAccordingly, we applied the pub-\\nlicly available ALFWorld MPO meta plans from\\nhttps://github.com/WeiminXiong/MPO to No-\\nThinking, ReAct, and ReflAct, and compared the\\nresulting performance gains.\\nFigure 11: Performance comparison across NoThinking,\\nReAct, and ReflAct when applying MPO meta-plan.\\nAs shown in Figure 11, applying MPO meta\\nplans to NoThinking and ReAct leads to substan-\\ntial performance improvements.\\nHowever, no-\\ntably, even with these gains, NoThinking+MPO\\nand ReAct+MPO still fall short of ReflAct’s perfor-\\nmance. This further reinforces previous findings\\nthat strengthening the reasoning backbone itself\\nis more crucial than simply adding enhancement\\nmodules to ReAct.\\nApplying MPO meta plans to ReflAct results in\\nslight performance gains for GPT-4o, but a minor\\nperformance drop for Llama-3.1-8B-Instruct. This\\nmay be due to the fact that the meta plans were\\ntrained on tasks different from those in the test\\nset; in some out-of-distribution cases, they may\\noffer misleading guidance that negatively impacts\\nthe agent’s behavior. The limited effectiveness\\nof meta plans on ReflAct also suggests that its\\ngrounded decision-making already enables high-\\nquality planning.\\nG\\nMore Discussion on ReflAct’s Effects\\nG.1\\nReflAct Prevents Suboptimality Through\\nGoal-Oriented Reasoning\\nJericho: You are a treasure hunter who wants to seek out a \\nmysterious cylindrical room under a rock on an island, remember to \\nuse a tool to help you breathe when you swim in the ocean.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 13}, page_content='grounded decision-making already enables high-\\nquality planning.\\nG\\nMore Discussion on ReflAct’s Effects\\nG.1\\nReflAct Prevents Suboptimality Through\\nGoal-Oriented Reasoning\\nJericho: You are a treasure hunter who wants to seek out a \\nmysterious cylindrical room under a rock on an island, remember to \\nuse a tool to help you breathe when you swim in the ocean.\\n(1) ReAct\\n(2) ReflAct\\n→ The agent needed a breathing tool but became fixated on a shovel, repeatedly \\nusing it inappropriately and failing to find the right tool.\\n→ By continuously reflecting on the task goal of reaching the cylindrical room, \\nthe agent generates actions without falling into suboptimal behavior.\\n...\\nReflection: I currently have no items in my inventory, which is concerning since I need a \\ntool to help me breathe while swimming to reach the mysterious cylindrical room.\\xa0\\n...\\nReflection: I found a snorkel, the tool I need to breathe while swimming. Now I can head \\nto the ocean to look for the cylindrical room under a rock.\\n...\\nReflection: I am in the ocean and need to swim towards the island to continue my quest \\nfor the mysterious cylindrical room. \\n...\\nThought: I have found a shovel in this small clearing, which could be useful for digging \\nor uncovering items. Since I need a tool to help me breathe while swimming, I should \\ntake the shovel with me.\\n...\\nThought: Since I have the shovel, I will dig in the small clearing to see if I can uncover \\nanything useful.\\nFigure 12: Comparison of ReAct’s Thought and Re-\\nflAct’s Reflection on a Jericho task: ReAct fixates on a\\nfound shovel, losing sight of the main goal and failing;\\nReflAct succeeds through goal-oriented reasoning.\\nReflAct enables long-sighted planning by con-\\ntinuously reflecting on the current state and goal.\\nFigure 12 illustrates this with an example in a task\\nwhere the agent must gather swimming-related\\nitems and ultimately reach a cylindrical room. As\\nseen, ReAct fails due to short-sighted reasoning,\\nwhereas ReflAct successfully achieves the goal\\nthrough consistent reflection on the state and ob-\\njective.\\n14'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 14}, page_content='G.2\\nToken Length vs. Hallucination Action\\nRate in ReAct and ReflAct\\nHere, we further compare ReflAct and ReAct in\\nterms of token length and the hallucinated action\\nrate. Specifically, token length refers to the number\\nof tokens in each thought (or reflection) with action\\ngenerated by the model, normalized by the number\\nof steps to account for variations in agent trajectory\\nlength. The hallucinated action rate is defined as\\nthe proportion of actions that result in erroneous\\nobservations (e.g., \"Nothing happens\"). Both met-\\nrics were averaged across the four agent models\\nused in our experiments: GPT-4o, GPT-4o-mini,\\nLlama-3.1-8B/70B-Instruct.\\nFigure 13: Comparison of the average token length and\\naverage hallucination action rate between ReAct and\\nReflAct in ALFWorld, ScienceWorld, and Jericho.\\nFigure 13 shows that ReflAct produces slightly\\nlonger token sequences than ReAct, as it incorpo-\\nrates reflection on the current state and goal into\\nits reasoning process. Interestingly, despite the\\nincreased token length, the hallucination rate de-\\ncreases. This suggests that hallucinations in LLM\\nagents may not arise simply from increased rea-\\nsoning (i.e., overthinking), but rather from unstruc-\\ntured or unguided reasoning processes.\\n15'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 15}, page_content='H\\nPrompt\\nH.1\\nALFWorld\\n1) ReAct\\nYou are in the middle of a room.\\nLooking quickly around you, you see a\\ncabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, a garbagecan\\n1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a\\ntoilet 1, a toiletpaperhanger 1, and a towelholder 1.\\nYour task is to:\\nput some spraybottle on toilet.\\nThought:\\nTo solve the task, I need to find and take a sparybottle, then\\nput it on toilet.\\nFirst I need to find a spraybottle.\\nA spraybottle is\\nmore likely to appear in cabinet 1-4, countertop 1, toilet 1, sinkbasin 1-2,\\ngarbagecan 1.\\nI can check one by one, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\nObservation:\\nOn the cabinet 1, you see a cloth 1, a soapbar 1, a soapbottle\\n1.\\nAction:\\ngo to cabinet 2\\nObservation:\\nThe cabinet 2 is closed.\\nAction:\\nopen cabinet 2\\nObservation:\\nYou open the cabinet 2.\\nThe cabinet 2 is open.\\nIn it, you see\\na candle 1, and a spraybottle 2.\\nThought:\\nNow I find a spraybottle 2.\\nNext, I need to take it.\\nAction:\\ntake spraybottle 2 from cabinet 2\\nObservation:\\nYou pick up the spraybottle 2 from the cabinet 2.\\nThought:\\nNow I take a spraybottle 2.\\nNext, I need to put it in/on toilet 1.\\nAction:\\ngo to toilet 1\\nObservation:\\nOn the toilet 1, you see a soapbottle 2.\\nAction:\\nput spraybottle 2 in/on toilet 1\\nYou put the spraybottle 2 in/on the toilet 1.\\nFigure 14: Prompt for ALFWorld ReAct\\n16'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 16}, page_content='2) ReflAct\\nYou are in the middle of a room.\\nLooking quickly around you, you see a\\ncabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, a garbagecan\\n1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a\\ntoilet 1, a toiletpaperhanger 1, and a towelholder 1.\\nYour task is to:\\nput some spraybottle on toilet.\\nReflection:\\nTo solve the task, I need to find and take a sparybottle, then\\nput it on toilet.\\nFirst I need to find a spraybottle.\\nA spraybottle is\\nmore likely to appear in cabinet 1-4, countertop 1, toilet 1, sinkbasin 1-2,\\ngarbagecan 1.\\nI can check one by one, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\nObservation:\\nOn the cabinet 1, you see a cloth 1, a soapbar 1, a soapbottle\\n1.\\nReflection:\\nCurrently, I am at cabinet 1, not holding anything, and am\\nsearching for a spraybottle to place on the toilet, but instead I find a\\ncloth, a soapbar, and a soapbottle.\\nAction:\\ngo to cabinet 2\\nObservation:\\nThe cabinet 2 is closed.\\nReflection:\\nCurrently, I am at cabinet 2, not holding anything, but the\\nclosed cabinet hinders me from finding the spraybottle needed to place on\\nthe toilet.\\nAction:\\nopen cabinet 2\\nObservation:\\nYou open the cabinet 2.\\nThe cabinet 2 is open.\\nIn it, you see\\na candle 1, and a spraybottle 2.\\nReflection:\\nCurrently, I am at cabinet 2 and have found a spraybottle 2,\\nwhich brings me closer to completing the task of placing it on the toilet.\\nAction:\\ntake spraybottle 2 from cabinet 2\\nObservation:\\nYou pick up the spraybottle 2 from the cabinet 2.\\nReflection:\\nCurrently I am located at cabinet 2, now holding a spraybottle 2,\\nand I am ready to complete the task of placing the spraybottle on the toilet,\\nas I have obtained spraybottle 2.\\nAction:\\ngo to toilet 1\\nObservation:\\nOn the toilet 1, you see a soapbottle 2.\\nReflection:\\nCurrently, I am at toilet 1, still holding spraybottle 2, and the\\ntask is nearly complete, with only the placement remaining.\\nAction:\\nput spraybottle 2 in/on toilet 1\\nObservation:\\nYou put the spraybottle 2 in/on the toilet 1.\\nFigure 15: Prompt for ALFWorld ReflAct\\n17'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 17}, page_content='H.2\\nScienceWorld\\n1) ReAct\\nYour task is to use chemistry to create green paint.\\nWhen you are done, focus\\non the green paint.\\nThought:\\nTo solve the task, I need to find materials to create green paint,\\nuse those materials, and focus on the object specified in the task once it is\\nidentified.\\nThe materials for making green paint are likely to be found in an\\nart studio.\\nAction:\\nlook around\\nObservation:\\nThis room is called the bedroom.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nbed.\\nOn the bed is:\\na mattress.\\nOn the mattress is:\\na white pillow..\\ncloset.\\nThe closet door is open.\\nIn the closet is:\\nnothing.\\npicture\\ntable.\\nOn the table is:\\nnothing.\\nYou also see:\\nA door to the hallway (that is open)\\nThought:\\nThe bedroom doesn’t have the materials I need.\\nI should go to a\\nplace where paint and painting supplies are likely to be found, such as an art\\nstudio.\\nAction:\\nteleport to art studio\\nObservation:\\nYou teleport to the art studio.\\nThought:\\nNow that I’m in the art studio, I should look around to find the\\nnecessary materials to create green paint.\\nAction:\\nlook around\\nObservation:\\nThis room is called the art studio.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nlarge cupboard.\\nThe large cupboard door is open.\\nIn the large cupboard is:\\na drawer, a wood cup (containing yellow paint), a wood cup (containing blue\\npaint), a wood cup (containing red paint).\\ntable.\\nOn the table is:\\na glass cup (containing nothing).\\nwood cup (containing yellow paint)\\na wood cup (containing blue paint)\\nwood cup (containing red paint)\\nYou also see:\\nA door to the hallway (that is open)\\nThought:\\nI see blue paint here, which is one of the primary colors needed to\\nmix green paint.\\nI should start by pouring it into an empty container to mix\\nwith another color.\\nAction:\\npour cup containing blue paint in art studio in cup containing\\nnothing\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nThought:\\nYellow paint is the other primary color needed to mix with blue to\\ncreate green.\\nI should add the yellow paint to the container with blue paint.\\nAction:\\npour cup containing yellow paint in art studio in cup containing blue\\npaint in table\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nThought:\\nNow that I have both blue and yellow paint in the same container, I\\nneed to mix them together to create green paint.\\nAction:\\nmix cup containing blue paint and yellow paint\\nObservation:\\nBlue and yellow paint mix to produce green paint.\\nThought:\\nThe task is to create green paint and then focus on it.\\nNow that\\nthe green paint is made, I should focus on the final product.\\nAction:\\nfocus on green paint\\nFigure 16: Prompt for ScienceWorld ReAct\\n18'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 18}, page_content='2) ReflAct\\nYour task is to use chemistry to create green paint.\\nWhen you are done, focus\\non the green paint.\\nReflection:\\nTo solve the task, I need to find materials to create green\\npaint, use those materials, and focus on the object specified in the task\\nonce it is identified.\\nThe materials for making green paint are likely to be\\nfound in an art studio.\\nAction:\\nlook around\\nObservation:\\nThis room is called the bedroom.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nbed.\\nOn the bed is:\\na mattress.\\nOn the mattress is:\\na white pillow..\\ncloset.\\nThe closet door is open.\\nIn the closet is:\\nnothing.\\npicture\\ntable.\\nOn the table is:\\nnothing.\\nYou also see:\\nA door to the hallway (that is open)\\nReflection:\\nCurrently, I am in the bedroom, holding nothing and focused on\\nnothing.\\nThere are no useful materials here to create the green paint I need\\nto focus on.\\nAction:\\nteleport to art studio\\nObservation:\\nYou teleport to the art studio.\\nReflection:\\nCurrently, I am in the art studio, holding nothing and focused on\\nnothing.\\nI need to look for materials to create green paint.\\nAction:\\nlook around\\nObservation:\\nThis room is called the art studio.\\nIn it, you see:\\nthe agent\\nsubstance called air\\nlarge cupboard.\\nThe large cupboard door is open.\\nIn the large cupboard is:\\na drawer, a wood cup (containing yellow paint), a wood cup (containing blue\\npaint), a wood cup (containing red paint).\\ntable.\\nOn the table is:\\na glass cup (containing nothing).\\nwood cup (containing yellow paint)\\na wood cup (containing blue paint)\\nwood cup (containing red paint)\\nYou also see:\\nA door to the hallway (that is open)\\nReflection:\\nCurrently, I am in the art studio, not holding anything.\\nI’ve\\nfound the primary colors yellow, blue, and red, which can be used to make\\ngreen paint, the substance I will need to focus on.\\nAction:\\npour cup containing blue paint in art studio in cup containing\\nnothing\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nReflection:\\nI poured blue paint into the glass cup.\\nI’m now holding it and\\nwill next add yellow paint.\\nAction:\\npour cup containing yellow paint in art studio in cup containing blue\\npaint in table\\nObservation:\\nYou pour the contents of the wood cup into the glass cup.\\nReflection:\\nI’ve added yellow paint to the blue in the glass cup.\\nI’m now\\nholding a mix of blue and yellow paint, ready to be mixed into green.\\nAction:\\nmix cup containing blue paint and yellow paint\\nObservation:\\nBlue and yellow paint mix to produce green paint.\\nReflection:\\nThe task is to create green paint and then focus on it.\\nNow that\\nthe green paint is made, I should focus on the final product.\\nAction:\\nfocus on green paint\\nFigure 17: Prompt for ScienceWorld ReflAct\\n19'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 19}, page_content='H.3\\nJericho\\n1) ReAct\\nGoal:\\nYou are the warrior Link that needs to save the princess from the\\ncastle.\\nObservation:\\nYou are at the path leading to the castle.\\nThe castle is to\\nyour north.\\nThere is a barrel in front of you.\\nThought:\\nTo solve the task, I first need to explore my surroundings to gather\\nany useful items.\\nOnce prepared, I will move north into the castle, navigate\\nto the princess’s location, interact with the princess and complete the rescue\\nmission.\\nAction:\\nExamine barrel\\nObservation:\\nThere is a gleaming elvish sword.\\nThought:\\nThe sword inside the barrel has a gleaming finish, which suggests it\\nis of high quality and possibly enchanted.\\nTaking this sword now will likely\\nincrease my chances of handling any immediate challenges.\\nAction:\\ntake the sword\\nObservation:\\nThe sword is taken\\nThought:\\nI’m now armed.\\nAdvancing north into the castle should provide new\\nopportunities for exploration and reveal the next critical steps.\\nAction:\\nnorth\\nObservation:\\nMain hall\\nThe castle is dimly lit, with lava flowing in many places.\\nThere is a\\nstaircase leading up to princess bedroom, a door to your north leading to\\nthe kitchen hall, and the door you just entered on your south\\nThought:\\nBefore making a move toward any specific direction, I need to\\nevaluate what options are actually available to me right now.\\nIt would be\\nhelpful to check the possible actions I can take from here.\\nAction:\\ncheck valid actions\\nObservation:\\nsouth, north, up, look, examine staircase\\nThought:\\nAmong the available actions, ascending the staircase seems like the\\nmost direct route to explore.\\nSince it leads upward and the hall below seems\\nperilous, I’ll proceed to investigate what’s at the top of the stairs.\\nAction:\\nup\\nObservation:\\nPrincess’s bedroom.\\nPrincess is sleeping in bed.\\nThought:\\nI’ve entered a bedroom where the princess is lying unconscious.\\nThere are likely specific actions I can perform in this situation, and\\nI should understand my options before taking a step that could have\\nconsequences.\\nChecking what I can do here would be the most logical next\\nmove.\\nAction:\\ncheck valid actions\\nObservation:\\nwake up the princess, take out sword, down\\nThought:\\nOne of the available actions is to wake the princess, which might\\nchange the course of events.\\nIt seems like the most immediate and gentle way\\nto interact with her.\\nI’ll go ahead and try that first.\\nAction:\\nwake up the princess\\nObservation:\\nThe princess wake up from the coma.\\nThank you my knight, she\\nsays.\\nThe task is finished.\\nFigure 18: Prompt for Jericho ReAct\\n20'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 20}, page_content='2) ReflAct\\nGoal:\\nYou are the warrior Link that needs to save the princess from the\\ncastle.\\nObservation:\\nYou are at the path leading to the castle.\\nThe castle is to\\nyour north.\\nThere is a barrel in front of you.\\nReflection:\\nTo solve the task, I first need to explore my surroundings to\\ngather any useful items.\\nOnce prepared, I will move north into the castle,\\nnavigate to the princess’s location, interact with the princess and complete\\nthe rescue mission.\\nAction:\\nExamine barrel\\nObservation:\\nThere is a gleaming elvish sword.\\nReflection:\\nI found a powerful elvish sword in the barrel.\\nSince I currently\\nhave no weapons, this sword will be essential for protection once I enter the\\ncastle.\\nAction:\\ntake the sword\\nObservation:\\nThe sword is taken\\nReflection:\\nI have obtained the elvish sword and am now equipped.\\nWith my\\nweapon ready, I should head into the castle to continue the search for the\\nprincess.\\nAction:\\nnorth\\nObservation:\\nMain hall\\nThe castle is dimly lit, with lava flowing in many places.\\nThere is a\\nstaircase leading up to princess bedroom, a door to your north leading to\\nthe kitchen hall, and the door you just entered on your south\\nReflection:\\nI have entered the main hall of the castle.\\nThe environment is\\ndangerous with lava present.\\nThe staircase likely leads to the princess’s\\nbedroom, which aligns with my goal.\\nI should verify available actions first.\\nAction:\\ncheck valid actions\\nObservation:\\nsouth, north, up, look, examine staircase\\nReflection:\\nThe valid actions include going “up,” which matches the staircase\\nthat leads to the princess’s bedroom.\\nThis is likely the shortest path to the\\ngoal.\\nAction:\\nup\\nObservation:\\nPrincess’s bedroom.\\nPrincess is sleeping in bed.\\nReflection:\\nI have reached the princess, but she appears to be unconscious\\nor in a coma.\\nI need to determine how to safely wake her to complete the\\nmission.\\nAction:\\ncheck valid actions\\nObservation:\\nwake up the princess, take out sword, down\\nReflection:\\nThe available actions include “wake up the princess,” which\\ndirectly supports the goal of saving her.\\nNo threat is present, so this is\\nthe appropriate move.\\nAction:\\nwake up the princess\\nObservation:\\nThe princess wake up from the coma.\\nThank you my knight, she\\nsays.\\nThe task is finished.\\nFigure 19: Prompt for Jericho ReflAct\\n21'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 21}, page_content='I\\nMore Case Study\\nALFWorld: clean some soapbar and put it in cabinet.\\nReAct\\nGoal:\\nclean some soapbar and put it\\nin cabinet.\\nThought:\\nTo solve the task, I need\\nto find a soapbar, then clean it with\\nsinkbasin, then put it in cabinet.\\nFirst I need to find a soapbar.\\nA\\nsoapbar is more likely to appear in\\ncabinet 1-4, countertop 1, sinkbasin\\n1-2, or toilet 1.\\nI can check one by\\none, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\n...\\nAction:\\ngo to cabinet 4\\nObservation:\\nYou open the cabinet 4.\\nThe cabinet 4 is open.\\nIn it, you\\nsee a candle 1, and a cloth 2.\\nThought:\\nNow I find a cloth 2 in\\ncabinet 4, which I can use to clean\\nthe soapbar.\\nNext, I need to find a\\nsoapbar.\\nI will go to countertop 1\\nto check if it contains a soapbar.\\nAction:\\ngo to countertop 1\\nObservation:\\nOn the countertop 1,\\nyou see a soapbar 1, and a soapbottle\\n1.\\nThought:\\nNow I find a soapbar 1 on\\nthe countertop 1.\\nNext, I need to\\nclean it with sinkbasin.\\nI will go\\nto sinkbasin 1 to clean the soapbar.∗\\n∗Ungrounded thought:\\nThe agent\\nattempts to go to the sinkbasin\\nwithout having taken the soapbar.\\nAction:\\ngo to sinkbasin 1\\nObservation:\\nOn the sinkbasin 1, you\\nsee nothing.\\nThought:\\nSince the sinkbasin 1 is\\nempty, I need to clean the soapbar\\n1 with something.\\nI will use the\\ncloth 2 from cabinet 4 to clean the\\nsoapbar.∗\\n∗Hallucination:\\nThe agent performs\\nan action without soapbar present.\\nAction:\\nuse cloth 2\\nObservation:\\nNothing happens.\\nThought:\\nSince using the cloth 2 did\\nnot have any effect, I need to find\\na way to use it to clean the soapbar.\\nI will go back to the cabinet 4 and\\ntake the cloth 2 to use it with the\\nsinkbasin 1.\\nAction:\\ntake cloth 2 from cabinet 4\\nObservation:\\nNothing happens.\\n...\\n# Task Failed\\nReflAct\\nGoal:\\nclean some soapbar and put it\\nin cabinet.\\nReflection:\\nTo solve the task, I\\nneed to find a soapbar, clean it\\nwith sinkbasin, and then put it in\\ncabinet.\\nFirst, I need to find a\\nsoapbar.\\nA soapbar is more likely to\\nappear in cabinet 1-4, countertop 1,\\nor sinkbasin 1-2.\\nI can check one by\\none, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\n...\\nAction:\\ngo to countertop 1\\nObservation:\\nOn the countertop 1,\\nyou see a soapbar 1, and a soapbottle\\n1.\\nReflection:\\nCurrently, I am at\\ncountertop 1, and I have found a'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 21}, page_content='or sinkbasin 1-2.\\nI can check one by\\none, starting by going to cabinet 1.\\nAction:\\ngo to cabinet 1\\n...\\nAction:\\ngo to countertop 1\\nObservation:\\nOn the countertop 1,\\nyou see a soapbar 1, and a soapbottle\\n1.\\nReflection:\\nCurrently, I am at\\ncountertop 1, and I have found a\\nsoapbar 1, which I need to clean\\nbefore placing it in the cabinet to\\ncomplete the task.∗\\n∗The agent performs an action that\\nare goal-related and well grounded in\\nthe current situation.\\nAction:\\ntake soapbar 1 from\\ncountertop 1\\nObservation:\\nYou pick up the soapbar\\n1 from the countertop 1.\\nReflection:\\nCurrently, I am at\\ncountertop 1, now holding soapbar 1,\\nwhich I need to clean before placing\\nit in the cabinet to complete my\\ntask.\\nObservation:\\nOn the sinkbasin 1, you\\nsee nothing.\\nReflection:Currently, I am at\\nsinkbasin 1, I’m holding a soapbar\\n1, and I am now ready to clean it\\nbefore placing it in the cabinet to\\ncomplete my task.\\nAction:\\nAction:\\nclean soapbar 1\\nwith sinkbasin 1\\nObservation:\\nYou clean the soapbar 1\\nusing the sinkbasin 1.\\n...\\n# Task Succeed\\nFigure 20: Case study for ALFWorld\\n22'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 22}, page_content='ScienceWorld: Your task is to boil tin.\\nFor compounds without a boiling point, combusting the substance is also acceptable.\\nFirst, focus on the substance. Then, take actions that will cause it to change its state of matter.\\nReAct\\n...\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nThought:\\nNow that I’m in the\\nworkshop, I should look around to\\nfind tin.\\nThe workshop is a place\\nwhere various projects and repairs\\nare done, so I might find tin here in\\nthe form of scraps, sheets, or other\\nobjects.\\nAction:\\nlook around\\nObservation:\\nThis room is called the\\nworkshop.\\nIn it, you see:\\n...\\nOn\\nthe table is:\\na battery, a green\\nwire, a metal pot (containing a\\nsubstance called tin), ...\\nThought:\\nI found tin in the metal\\npot on the table!\\nNow that I’ve\\nlocated the tin, I should focus on it\\nas per the task instructions.\\nAction:\\nfocus on tin\\nObservation:\\nYou focus on the tin.\\nThought:\\nNow that I’ve focused on\\nthe tin, I need to take actions to\\nboil or combust it.\\nSince the tin\\nis in a metal pot, I can use a heat\\nsource to boil it.\\nI see a blast\\nfurnace in the foundry, which would\\nbe perfect for heating the tin.\\nI\\nshould teleport back to the foundry\\nand use the blast furnace.∗\\n∗Ungrounded thought:\\nThe agent\\nconfirms the presence of tin and\\nproceeds with planning, but does not\\nactually possess the tin.\\nAction:\\nteleport to foundry\\nObservation:\\nYou teleport to the\\nfoundry.\\nThought:\\nNow that I’m back in the\\nfoundry, I should move the metal\\npot containing the tin to the blast\\nfurnace and then activate the blast\\nfurnace to heat the tin.\\nAction:\\nmove metal pot to blast\\nfurnace\\nObservation:\\nNo known action matches\\nthat input.\\nThought:\\nIt seems I made a mistake\\nwith the action.\\nI should try again,\\nusing a different action to move the\\nmetal pot to the blast furnace.∗\\n∗Hallucination:\\nAlthough the agent\\nrecognizes the mistake, it continues\\nto attempt the same invalid action.\\nAction:\\nmove metal pot to blast\\nfurnace\\n...\\n# Task Failed\\nReflAct\\n...\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nReflection:\\nCurrently, I am in the\\nworkshop, holding nothing and focused\\non nothing.\\nI need to look for tin\\nin this room.\\nAction:\\nlook around\\nObservation:\\nThis room is called the\\nworkshop.\\nIn it, you see:\\n...\\nOn\\nthe table is:\\na battery, a green\\nwire, a metal pot (containing a\\nsubstance called tin), ...\\nReflection:\\nCurrently, I am in the\\nworkshop, holding nothing and focused\\non nothing.\\nI’ve found a metal pot\\ncontaining tin on the table, which is\\nthe substance I need to focus on and\\nthen boil or combust\\nAction:\\nfocus on tin\\nObservation:\\nYou focus on the tin.\\nReflection:\\nI am now focused on'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 22}, page_content='wire, a metal pot (containing a\\nsubstance called tin), ...\\nReflection:\\nCurrently, I am in the\\nworkshop, holding nothing and focused\\non nothing.\\nI’ve found a metal pot\\ncontaining tin on the table, which is\\nthe substance I need to focus on and\\nthen boil or combust\\nAction:\\nfocus on tin\\nObservation:\\nYou focus on the tin.\\nReflection:\\nI am now focused on\\nthe tin, which is contained in the\\nmetal pot on the table.\\nTo boil\\nor combust the tin, I need to apply\\nheat to it.\\nI see a foundry in the\\nenvironment, which is likely to have\\na heat source.\\nAction:\\nteleport to foundry\\n...\\nReflection:\\nThe blast furnace is now\\nactivated and ready to be used as a\\nheat source.\\nI need to move the tin\\nfrom the metal pot in the workshop to\\nthe blast furnace in the foundry.\\nAction:\\nteleport to workshop\\nObservation:\\nYou teleport to the\\nworkshop.\\nReflection:\\nI am now back in the\\nworkshop, where the metal pot\\ncontaining the tin is located.\\nI\\nneed to move the tin to the blast\\nfurnace in the foundry.\\nAction:\\nmove metal pot to blast\\nfurnace\\nObservation:\\nNo known action matches\\nthat input.\\nReflection:\\nI need to move the\\ntin to the blast furnace, but the\\naction is not recognized.\\nInstead,\\nI can pick up the metal pot and then\\nteleport to the foundry.\\nAction:\\npick up metal pot\\nObservation:\\nYou move the metal pot\\nto the inventory.\\nReflection:\\nI am now back in\\nthe foundry, with the metal pot\\ncontaining the tin in my inventory.\\nI can now use the blast furnace to\\nboil or combust the tin.\\n...\\n# Task Succeed\\nFigure 21: Case study for ScienceWorld\\n23'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 23}, page_content='Jericho: You are a pizza delivery man. Today you are making a new delivery on your boss’s order.\\nYou need to find out by yourself who to deliver.\\nReAct\\n...\\nObservation:\\nThe note reads:\\n\"Stanley, Don’t forget to make your\\ndelivery to Mr.\\nCalzone, located at\\nthe San Doppleton Courthouse.\\n...\\n...\\nObservation:\\nStreet, Near Courthouse\\nYou are approaching the center of\\ndowntown San Doppleton.\\nThere is a\\ncourthouse to the south.\\nThe street\\nruns east and west.\\nThought:\\nIt seems like I’m on the\\nright track, as the courthouse is now\\nvisible to the south.\\nI should head\\nsouth to reach the courthouse and\\ndeliver the pizza to Mr.\\nCalzone as\\ninstructed in the note.\\nAction:\\nSouth\\nObservation:\\nCourthouse You are in\\na crowded courthouse.\\nThe street is\\noff to the north.\\nThe courtroom is\\ncurrently abuzz with excitement as\\nit seems that the pre-trial hearing\\nof the infamous gangster, Guido \"The\\nArmadillo\" Calzone is winding to a\\nclose.\\nGuido and his hotshot lawyer\\nsit placidly at their table, while\\nthe flustered young district attorney\\nwho is prosecuting the case seems\\nlike she’s at her wits’ end.\\nAt the\\nmoment, the D.A. stands at the front\\nof the courtroom, arguing over a\\nlegal point with the judge.\\nThought:\\nI have arrived at the\\ncourthouse where Mr.\\nCalzone is\\npresent.\\nSince the courtroom is busy,\\nI need to find a way to deliver the\\npizza to Mr.\\nCalzone without causing\\na disruption.\\nI should approach him\\nor his lawyer to hand over the pizza\\nbox.\\nAction:\\nShow people box\\nObservation:\\nYou can’t see any such\\nthing.\\nThought:\\nIt seems that the action\\n\"show people box\" was not understood\\nin this context.\\nI need to find a\\nmore direct way to deliver the pizza\\nto Mr.Calzone.\\nSince he is present\\nin the courtroom, I should try to\\ngive the pizza box directly to him or\\nhis lawyer.∗\\n∗Mismatched execution:\\nThe agent\\nfails to specify the target, leading\\nto another invalid action.\\nAction:\\nGive people box\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\n# Task Failed\\nReflAct\\n...\\nObservation:\\nThe note reads:\\n\"Stanley, Don’t forget to make your\\ndelivery to Mr.\\nCalzone, located at\\nthe San Doppleton Courthouse.\\n...\\n...\\nObservation:\\nStreet, Near Courthouse\\nYou are approaching the center of\\ndowntown San Doppleton.\\nThere is a\\ncourthouse to the south.\\nThe street\\nruns east and west.\\nReflection:\\nI’ve finally found the\\ncourthouse, which is located to\\nthe south of my current position.\\nThis is where I need to deliver\\nthe pizza to Mr.\\nCalzone.\\nNow\\nthat I’ve located the courthouse,\\nI should proceed south to complete\\nthe delivery task.\\nAction:\\nSouth\\nObservation:\\nCourthouse You are in\\na crowded courthouse.\\nThe street is\\noff to the north.\\nThe courtroom is\\ncurrently abuzz with excitement as\\nit seems that the pre-trial hearing'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 23}, page_content='the south of my current position.\\nThis is where I need to deliver\\nthe pizza to Mr.\\nCalzone.\\nNow\\nthat I’ve located the courthouse,\\nI should proceed south to complete\\nthe delivery task.\\nAction:\\nSouth\\nObservation:\\nCourthouse You are in\\na crowded courthouse.\\nThe street is\\noff to the north.\\nThe courtroom is\\ncurrently abuzz with excitement as\\nit seems that the pre-trial hearing\\nof the infamous gangster, Guido \"The\\nArmadillo\" Calzone is winding to a\\nclose.\\nGuido and his hotshot lawyer\\nsit placidly at their table, while\\nthe flustered young district attorney\\nwho is prosecuting the case seems\\nlike she’s at her wits’ end.\\nAt the\\nmoment, the D.A. stands at the front\\nof the courtroom, arguing over a\\nlegal point with the judge.\\nReflection:\\nI’ve entered the\\ncourthouse where the pre-trial\\nhearing for Guido \"The Armadillo\"\\nCalzone is taking place.\\nThis is\\nthe location where I need to deliver\\nthe pizza to Mr.\\nCalzone.\\nSince\\nI’ve found him, I should proceed with\\ndelivering the pizza to complete my\\ntask.∗\\n∗Well-grounded and goal-aligned\\nreasoning:\\nThe agent explicitly\\nidentifies the recipient and forms a\\nvalid, context-aware action.\\nAction:\\nGive pizza box to Guido\\nCalzone\\nObservation:\\nGuido grins shiftily\\nand takes the pizza from you.\\nHe\\nhands it to his lawyer so he can\\neat it later.\\nYou walk away,\\ncongratulating yourself on a job\\nwell done.\\n# Task Succeed\\nFigure 22: Case study for Jericho\\n24'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 24}, page_content='Jericho: search for a mug in an inn.\\nReAct\\n...\\nObservation:\\nInside the Inn There\\nare a few patches of mould on the\\nwalls and the floorboards creak\\nslightly, but the building seems safe\\nenough.\\n...\\nYou see some tables and\\nchairs.\\n...\\nYou can go west (back\\noutside) or down some steps.\\nYou\\ncan see a magnificently carved chair\\nhere.\\nThought:\\nI’m inside the inn, and I\\nneed to find a mug.\\nI should start\\nby examining the tables and chairs to\\nsee if there’s a mug lying around.\\nAction:\\nExamine tables and chairs\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\nAction:\\nExamine floorboards\\nObservation:\\nThe floor is made\\nof large, rather uneven rough\\nfloorboards, on which lie the remains\\nof the scattered rushes once used as\\na floor covering.\\nThought:\\nI’ve examined the\\nfloorboards, but I didn’t find a\\nmug.\\nI should try to find something\\nto pick up, and since I’m in the inn,\\nI should check the inventory again to\\nsee if I have any other options, but\\nit seems I’m empty-handed.\\nI should\\ntry to find something to pick up.\\nAction:\\nExamine stone steps leading\\ndown\\n...\\nAction:\\nExamine the floorboards\\nagain\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nfloor.\\nThought:\\nI’ve tried examining\\nvarious objects and places in the inn,\\nbut I didn’t find a mug.\\nI should\\ntry to find something to pick up, and\\nsince I’m in the inn, I should check\\nthe inventory again to see if I have\\nany other options, but it seems I’m\\nempty-handed.\\nI should try to find\\nsomething to pick up.∗\\n∗Short-sighted planning:\\nThe\\nagent repeatedly focuses narrowly\\non immediate surroundings without\\nreconsidering its strategy in light\\nof prior failures.\\nAction:\\nExamine the rushes on the\\nfloor again\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nfloor.\\n...\\n# Task Failed\\nReflAct\\n...\\nObservation:\\nInside the Inn There\\nare a few patches of mould on the\\nwalls and the floorboards creak\\nslightly, but the building seems safe\\nenough.\\n...\\nYou see some tables and\\nchairs.\\n...\\nYou can go west (back\\noutside) or down some steps.\\nYou\\ncan see a magnificently carved chair\\nhere.\\nReflection:\\nI’ve entered the\\nabandoned inn, the Troll’s Arms,\\nand it appears to be old and dusty,\\nbut safe enough.\\nI’ve seen some\\ntables and chairs, and a dark,\\nintricately-carved wooden chair in\\nthe corner.\\nSince my goal is to\\nsearch for a mug in an inn, I should\\ninvestigate the tables and chairs to\\nsee if there’s anything useful.\\nAction:\\nExamine tables and chairs\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\nAction:\\nExamine bar or counter\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nwalls.\\nReflection:\\nI’ve been trying to\\nfind a mug, but that didn’t reveal\\nanything.\\nI should try to think of a'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 24}, page_content='investigate the tables and chairs to\\nsee if there’s anything useful.\\nAction:\\nExamine tables and chairs\\nObservation:\\nYou can’t see any such\\nthing.\\n...\\nAction:\\nExamine bar or counter\\nObservation:\\nI only understood you\\nas far as wanting to examine the\\nwalls.\\nReflection:\\nI’ve been trying to\\nfind a mug, but that didn’t reveal\\nanything.\\nI should try to think of a\\ndifferent approach to find the mug.\\nAction:\\nDown\\nObservation:\\nInn Cellar The cellar\\nseems to have been formed from a\\nnatural cavern in the rock under the\\ninn, ...\\n, which will remain cool in\\nthe slightly chill air.\\n...\\nYou can\\ngo up (to the inn) or west (into the\\ndark tunnel).\\nYou can see an ancient\\nsilver coin and some barrels here.\\nReflection:\\nI’ve been trying to find\\na mug, but so far, I haven’t found\\nanything useful.\\nI should try to\\nthink of a different approach to find\\nthe mug.\\nThe cellar seems like a\\npromising location to search for a\\nmug, as it’s a storage area for the\\ninn’s supplies.∗\\n∗Reflecting on long-term goal:\\nThe\\nagent adapts its exploration strategy\\nbased on environmental cues and prior\\nsearch failures.\\nAction:\\nExamine barrels\\nObservation:\\nThe barrels are now no\\nmore than rotten staves of dry wood,\\nheld together by the woodworm holding\\nhands.\\nYou have found a pewter mug.\\n# Task Succeed\\nFigure 23: Another case study for Jericho\\n25')],\n",
              " 'context': [Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 0, '_id': '19183ec8bca9443eb909c19ce9224bd0', '_collection_name': 'fa88065fcac3474fa1ac981e92cb298a'}, page_content='ReflAct: World-Grounded Decision Making in\\nLLM Agents via Goal-State Reflection\\nJeonghye Kim1∗, Sojeong Rhee1∗, Minbeom Kim2, Dohyung Kim2,\\nSangmook Lee2, Youngchul Sung1†, Kyomin Jung2†,\\n1KAIST, 2Seoul National University\\n{jeonghye.kim, sojeong.rhee, ycsung}@kaist.ac.kr, kjung@snu.ac.kr\\nAbstract\\nRecent advances in LLM agents have largely\\nbuilt on reasoning backbones like ReAct (Yao\\net al., 2023), which interleave thought and ac-\\ntion in complex environments. However, Re-\\nAct often produces ungrounded or incoherent\\nreasoning steps, leading to misalignment be-\\ntween the agent’s actual state and goal. Our\\nanalysis finds that this stems from ReAct’s\\ninability to maintain consistent internal be-\\nliefs and goal alignment, causing compound-\\ning errors and hallucinations. To address this,\\nwe introduce ReflAct, a novel backbone that\\nshifts reasoning from merely planning next ac-\\ntions to continuously reflecting on the agent’s\\nstate relative to its goal. By explicitly ground-\\ning decisions in states and enforcing ongoing\\ngoal alignment, ReflAct dramatically improves\\nstrategic reliability. This design delivers sub-\\nstantial empirical gains: ReflAct surpasses Re-\\nAct by 27.7% on average, achieving a 93.3%\\nsuccess rate in ALFWorld. Notably, ReflAct\\neven outperforms ReAct with added enhance-\\nment modules (e.g., Reflexion, WKM), show-\\ning that strengthening the core reasoning back-\\nbone is key to reliable agent performance.\\n1\\nIntroduction\\nRecent advancements in Large Language Mod-\\nels (LLMs) have significantly enhanced their rea-\\nsoning capabilities, enabling LLM-based agents\\nto perform complex multi-step decision making\\nbeyond static problem solving (Forootani, 2025;\\nChervonyi et al., 2025). As LLMs are extended\\ninto agentic frameworks where they interact with\\nopen-ended environments, the ability to solve long-\\nhorizon tasks through ongoing interaction and se-\\nquential reasoning has become a central research\\nfocus (Zhou et al., 2023; Song et al., 2024).\\nA large number of recent LLM agents build on\\nthe ReAct (Yao et al., 2023) framework, which in-\\n∗Equal contribution.\\n† Co-corresponding authors.\\nAction\\nReflection\\nTimestep\\n1\\n2\\n3\\nT-1\\nObs\\nGoal\\n. . .\\n. . .\\n. . .\\n1\\n2\\n2\\n3\\n3\\nT-1\\n1\\n2\\n3\\nT-1\\nT-1\\nT\\nT\\nInternal\\nState\\n1\\n2\\n3\\nT-1\\nAction\\nThought\\nObs\\nTimestep\\n1\\n2\\n3\\nT-1\\nT\\nT\\nGoal\\n. . .\\n. . .\\nReasoning Direction in ReAct\\n. . .\\n1\\n1\\n2\\n2\\n2\\n3\\n3\\n3\\nT-1\\nT-1\\nT-1\\nT\\nT\\nReasoning Direction in ReflAct\\nFigure 1: Comparison of reasoning influence in ReflAct'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 1, '_id': '0c9f4c0b8ed94b7c99f5923188c788d8', '_collection_name': 'fa88065fcac3474fa1ac981e92cb298a'}, page_content='namic or partially observable environments, such\\nreasoning errors compound over time, leading to\\nincreasingly divergent internal beliefs, deteriorated\\ndecision quality, and failed task execution.\\nTo address this limitation, we introduce ReflAct\\n(Reflect for Action), a new backbone framework\\nthat shifts the focus of the agent’s thought from pre-\\ndicting the next action to continuously reflecting\\non its current state in the context of the task goal,\\nas shown in Figure 1. Unlike previous approaches\\nthat layer reflective or memory modules onto the\\nReAct backbone (Shinn et al., 2024; Qiao et al.,\\n2024; Xiong et al., 2025), ReflAct does not rely\\non such additional components but replaces the\\ncore reasoning–action cycle itself. That is, at each\\ntimestep, the agent evaluates whether its current\\ntrajectory and situation align with its intended long-\\nterm objective before selecting an action. This\\nreflective thought mechanism enables early detec-\\ntion of potential deviations and facilitates timely\\nstrategy adjustments, as we shall see shortly. By\\ngrounding decisions in actual observations and\\nmaintaining continuous goal alignment, ReflAct\\nsubstantially reduces hallucination tendency and\\nenhances long-term strategic coherence.\\nWe implemented ReflAct using both open-\\nsource (Llama 3.1-8B/70B-Instruct (Grattafiori\\net al., 2024)) and proprietary (GPT-4o-mini/4o\\n(OpenAI, 2024)) LLMs, and evaluated it in three\\ntext-based environments: ALFWorld (Shridhar\\net al., 2021), ScienceWorld (Wang et al., 2022) and\\nJericho (Hausknecht et al., 2020), which require an\\nagent to decompose the goal and acts over a long\\ntime horizon under partial observability. Empirical\\nresults show that ReflAct helps the agent better\\nalign its internal beliefs with the environment and\\npromotes goal-consistent behavior. As a result, Re-\\nflAct significantly outperforms ReAct by 36.4%,\\n8.5%, and 38.1% on ALFWorld, ScienceWorld,\\nand Jericho, respectively. Notably, ReflAct also\\nsurpasses enhancement modules layered on top of\\nexisting backbones, demonstrating that revising the\\nreasoning process itself can be more effective than\\nadding new components.\\n2\\nPreliminaries\\nWe model the agent’s task in a language-based en-\\nvironment as a Partially Observable Markov Deci-\\nsion Process (POMDP) (Puterman, 1990), defined\\nas M = ⟨U, S, A, O, P, R⟩, where u ∈U is a\\ntask instruction, s ∈S is the (hidden) environment\\nstate, a ∈A is an action, o ∈O is an observation,\\nP is the transition function, and R is the reward\\nfunction. In our setting, U, A and O are expressed\\nin natural language.\\nThe ReAct Framework\\nThe ReAct framework\\n(Yao et al., 2023) enables LLM agents to solve\\ntasks through interleaved reasoning and action. To\\nincorporate reasoning steps (thoughts), we extend\\nthe above POMDP by including a thought space\\nT , where each thought τ ∈T represents a natural\\nlanguage reasoning step generated by the agent.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 5, '_id': '28c394ffce21455a9f74003ae94dad15', '_collection_name': 'fa88065fcac3474fa1ac981e92cb298a'}, page_content='Table 2: Performance comparison of ReflAct with NoThinking, ReAct, and Plan-and-Act across ALFWorld,\\nScienceWorld, and Jericho. SR and AR denote success ratio and average reward, respectively. Values in parentheses\\nindicate percentage improvement over the NoThinking baseline.\\nModel\\nPrompting\\nALFWorld\\nScienceWorld\\nJericho\\nAverage\\nSR\\nAR\\nSR\\nAR\\nSR\\nGPT-4o\\nNoThinking\\n76.1\\n67.4\\n50.2\\n27.8\\n10.0\\n46.3\\nReAct\\n85.1\\n68.7\\n55.9\\n50.4\\n20.0\\n56.0 (+21.0%)\\nPlan-and-Act\\n85.8\\n68.7\\n55.0\\n45.6\\n20.0\\n55.0 (+18.8%)\\nReflAct\\n93.3\\n68.9\\n57.8\\n53.2\\n35.0\\n61.6 (+33.1%)\\nGPT-4o-mini\\nNoThinking\\n43.3\\n42.3\\n21.8\\n18.8\\n5.0\\n26.2\\nReAct\\n53.0\\n49.1\\n37.0\\n29.8\\n15.0\\n36.8 (+40.2%)\\nPlan-and-Act\\n59.0\\n51.8\\n35.5\\n37.1\\n15.0\\n39.7 (+51.1%)\\nReflAct\\n66.4\\n55.4\\n37.0\\n45.4\\n20.0\\n44.8 (+70.9%)\\nLlama-3-1-8B\\n-Instruct\\nNoThinking\\n21.6\\n29.9\\n14.2\\n10.0\\n0.0\\n15.1\\nReAct\\n29.1\\n43.0\\n27.5\\n12.8\\n0.0\\n22.5 (+48.5%)\\nPlan-and-Act\\n30.6\\n34.2\\n14.7\\n10.6\\n0.0\\n18.0 (+19.0%)\\nReflAct\\n60.5\\n47.2\\n33.2\\n20.9\\n10.0\\n34.4 (+126.9%)\\nLlama-3-1-70B\\n-Instruct\\nNoThinking\\n53.7\\n65.6\\n46.4\\n27.4\\n5.0\\n39.6\\nReAct\\n81.3\\n66.4\\n53.1\\n33.9\\n10.0\\n48.9 (+23.5%)\\nPlan-and-Act\\n81.3\\n67.7\\n52.6\\n29.6\\n10.0\\n48.2 (+21.8%)\\nReflAct\\n83.6\\n73.7\\n58.8\\n44.5\\n20.0\\n56.1 (+41.6%)\\nFigure 5: A comparison of ReAct, ReflAct, and various verbalization strategies (state, goal, state+goal, and\\nstate+goal with next-action reasoning), using Llama-3.1-8B-Instruct as the agent model. Bars represent success\\nrate; the red dashed line indicates average reward.\\n(2) ReAct (Yao et al., 2023): The agent first reasons\\nabout the next action at each time step and then\\ngenerates an action.'),\n",
              "  Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-22T00:36:41+00:00', 'source': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'file_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf', 'total_pages': 25, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-22T00:36:41+00:00', 'trapped': '', 'modDate': 'D:20250522003641Z', 'creationDate': 'D:20250522003641Z', 'page': 3, '_id': 'd83fbe7074784ad8bb1c558bdeb0072e', '_collection_name': 'fa88065fcac3474fa1ac981e92cb298a'}, page_content=\"Observation: Nothing happens.\\nReflection: Currently, I am at cabinet 1, not holding anything, and I still haven't found \\nthe soap bar to place on the countertop.\\nAction: go to cabinet 2\\nFigure 4: In the ALFWorld task ‘put a clean soapbar in countertop’, the agent picks up a soapbottle from cabinet 1\\nand puts it back, (1) while planning the next action, it redundantly tries to go back to cabinet 1 and fails, (2) after\\nreflecting on the state and goal, it moves elsewhere and succeeds.\\nsituation in the context of goal properly from its\\nobservation history. This redundant and illogical\\nbehavior leads to a loop, and the agent ultimately\\nfails to complete the task. A failure case in Sci-\\nenceWorld is provided in Figure 9 in Appendix B.\\nFrom the examples, we see that the agent fails\\ndue to two major reasoning limitations:\\n(1) A lack of grounding in its internal state. The\\nagent fails to maintain a coherent internal state,\\nleading to inconsistency, e.g., revisiting a loca-\\ntion it already visited or falsely assuming it is\\nholding an object.\\n(2) Short-sighted planning. The ReAct agent\\ntypically exhibits short-sighted planning, mak-\\ning decisions that appear locally plausible but\\ndisregard the long-term task goal.\\nWe recognize that these two shortcomings stem\\nfrom incorrect guidance for the agent’s reasoning\\nprocess although the agent has better reasoning\\ncapability. Indeed, for the same failure scenario in\\nFigure 4 left branch, we input a reasoning guidance\\nsentence different from that of ReAct, to focus not\\non predicting the next step but assess the agent’s\\ncurrent state in relation to the task goal, as seen\\nin Figure 4 right branch. Now, it is seen that the\\nagent can better align its action with the overall\\nobjective by reflecting on what it currently knows\\nand what it aims to achieve. This is also valid\\nfor the ScienceWorld failure case in Figure 9 in\\nAppendix B.\\n4\\nProposed Method: ReflAct\\nIn the LLM POMDP framework, a thought τt ∈T\\nshould be generated so that it leads to the selec-\\ntion of an action at that maximizes the expected\\nlong-term return when used to condition the ac-\\ntion policy πact\\nθ , where the long-term return is de-\\nfined as Gt = P∞\\nk=0 γkRt+k with discount factor\\nγ ∈[0, 1). Here, Rt+k is the immediate reward at\\ntime t + k. Thus, the optimal thought τ ∗\\nt can be\\ndefined as\\nτ ∗\\nt = arg max\\nτ∈T\\nEa∼πact\\nθ (·|ct⊕τ) [E [Gt | st, a]] ,\\nwhere ct denotes the current context and ⊕de-\\nnotes concatenation. To maximize the expected\\nlong-term return, the thought τt should not be gen-\\nerated from the observation solely to decide the\\nnext action. Instead, it should be formed with con-\\nsideration of the final task goal at every time step,\\nas illustrated in Figure 1. In this way, the agent\\ncan rely on thought for action generation without\\ndeviating from a goal-reaching path. Furthermore,\\nsince the environment is partially observable and\")],\n",
              " 'response': 'A ReAct agent is an agent that solves tasks through interleaved reasoning and action. It generates reasoning steps (thoughts) and actions in an alternating manner, with the process typically involving reasoning about the next action before executing it. The ReAct framework enables the agent to perform complex multi-step decision making by reasoning about the environment and planning its actions accordingly.',\n",
              " 'pdf_path': '/tmp/b7223613-b8d8-470f-95f4-f8dcef9acb9c.pdf',\n",
              " 'retriever': VectorStoreRetriever(tags=['Qdrant', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.qdrant.Qdrant object at 0x135d683d0>, search_kwargs={}),\n",
              " 'arxiv_metadata': {'title': 'ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection',\n",
              "  'summary': \"Recent advances in LLM agents have largely built on reasoning backbones like\\nReAct, which interleave thought and action in complex environments. However,\\nReAct often produces ungrounded or incoherent reasoning steps, leading to\\nmisalignment between the agent's actual state and goal. Our analysis finds that\\nthis stems from ReAct's inability to maintain consistent internal beliefs and\\ngoal alignment, causing compounding errors and hallucinations. To address this,\\nwe introduce ReflAct, a novel backbone that shifts reasoning from merely\\nplanning next actions to continuously reflecting on the agent's state relative\\nto its goal. By explicitly grounding decisions in states and enforcing ongoing\\ngoal alignment, ReflAct dramatically improves strategic reliability. This\\ndesign delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7%\\non average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even\\noutperforms ReAct with added enhancement modules (e.g., Reflexion, WKM),\\nshowing that strengthening the core reasoning backbone is key to reliable agent\\nperformance.\",\n",
              "  'authors': ['Jeonghye Kim',\n",
              "   'Sojeong Rhee',\n",
              "   'Minbeom Kim',\n",
              "   'Dohyung Kim',\n",
              "   'Sangmook Lee',\n",
              "   'Youngchul Sung',\n",
              "   'Kyomin Jung'],\n",
              "  'pdf_url': 'http://arxiv.org/pdf/2505.15182v1'},\n",
              " 'search_query': 'ReAct agent'}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test2 = rag_graph1.invoke({\"question\" : \"What is a ReAct agent?\"})\n",
        "test2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A ReAct agent is an agent that solves tasks through interleaved reasoning and action. It generates reasoning steps (thoughts) and actions in an alternating manner, with the process typically involving reasoning about the next action before executing it. The ReAct framework enables the agent to perform complex multi-step decision making by reasoning about the environment and planning its actions accordingly.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test2[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6a_pqQ9uWf"
      },
      "source": [
        "## Task 2: Helper Functions for Agent Graphs\n",
        "\n",
        "We'll be using a number of agents, nodes, and supervisors in the rest of the notebook - and so it will help to have a collection of useful helper functions that we can leverage to make our lives easier going forward.\n",
        "\n",
        "Let's start with the most simple one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUnpEEl-L_F"
      },
      "source": [
        "#### Import Wall\n",
        "\n",
        "Here's a wall of imports we'll be needing going forward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TbzoL3Q3-SG1"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.graph import END, StateGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb6Z3EEz-Asi"
      },
      "source": [
        "### Agent Node Helper\n",
        "\n",
        "Since we're going to be wrapping each of our agents into a node - it will help to have an easy way to create the node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5IF7KWfS-JKd"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwND2teK-WHm"
      },
      "source": [
        "### Agent Creation Helper Function\n",
        "\n",
        "Since we know we'll need to create agents to populate our agent nodes, let's use a helper function for that as well!\n",
        "\n",
        "Notice a few things:\n",
        "\n",
        "1. We have a standard suffix to append to our system messages for each agent to handle the tool calling and boilerplate prompting.\n",
        "2. Each agent has its our scratchpad.\n",
        "3. We're relying on OpenAI's function-calling API for tool selection\n",
        "4. Each agent is its own executor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "NxLyHJt5-eUx"
      },
      "outputs": [],
      "source": [
        "def create_agent(\n",
        "    llm: ChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> str:\n",
        "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason!\")\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6kmlR9d-1K5"
      },
      "source": [
        "### Supervisor Helper Function\n",
        "\n",
        "Finally, we need a \"supervisor\" that decides and routes tasks to specific agents.\n",
        "\n",
        "Since each \"team\" will have a collection of potential agents - this \"supervisor\" will act as an \"intelligent\" router to make sure that the right agent is selected for the right task.\n",
        "\n",
        "Notice that, at the end of the day, this \"supervisor\" is simply directing who acts next - or if the state is considered \"done\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "S2MXA83mrYE2"
      },
      "outputs": [],
      "source": [
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
        "    \"\"\"An LLM-based router.\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [\n",
        "                        {\"enum\": options},\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Given the conversation above, who should act next?\"\n",
        "                \" Or should we FINISH? Select one of: {options}\",\n",
        "            ),\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=\", \".join(members))\n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd0zfyq48jKb"
      },
      "source": [
        "## Task 3: Research Team - A LangGraph for Researching Loan Policy\n",
        "\n",
        "Now that we have our RAG chain set-up and some awesome helper functions, we want to create a LangGraph related to researching a specific topic, in this case: Loans!\n",
        "\n",
        "We're going to start by equipping our Research Team with a few tools:\n",
        "\n",
        "1. Tavily Search - aka \"Google\", for the most up to date information possible.\n",
        "2. Our RAG chain - specific and high quality information about our topic.\n",
        "\n",
        "Let's create those tools now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNsVTZrH_alw"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "As you can see below, some tools already come pre-packaged ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ce7FKTZDgAWG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pg/rr8c6_fx079ctz0nd__xmlgm0000gn/T/ipykernel_45772/1911882425.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIR7cbTL9agM"
      },
      "source": [
        "Creating a custom tool, however, is very straightforward.\n",
        "\n",
        "> NOTE: You *must* include a docstring, as that is what the LLM will consider when deciding when to use this tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "sSwO2L_UqFhm"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retrieve_information(\n",
        "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
        "    ):\n",
        "  \"\"\"Use Retrieval Augmented Generation to retrieve information about student loan policies\"\"\"\n",
        "  return rag_graph.invoke({\"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsMnqjpBTCj"
      },
      "source": [
        "> NOTE: We could just as easily use the LCEL chain directly, since nodes can be LCEL objects - but creating a tool helps explain the tool creation process at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHCajO4_gB2"
      },
      "source": [
        "### Research Team State\n",
        "\n",
        "Since we're using LangGraph - we're going to need state!\n",
        "\n",
        "Let's look at how we've created our state below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "mXminK9d_1fa"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "import functools\n",
        "\n",
        "class ResearchTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvPM5msq_18C"
      },
      "source": [
        "Notice how we've used `messages`, `team_members`, and `next`.\n",
        "\n",
        "These states will help us understand:\n",
        "\n",
        "1. What we've done so far (`messages`)\n",
        "2. Which team members we have access to (`team_members`)\n",
        "3. Which team member is up next! (`next`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu7B_6qHAFjK"
      },
      "source": [
        "### Research Team LLM\n",
        "\n",
        "We'll be using `gpt-4o-mini` today. This LLM is going to be doing a lot of reasoning - but we also want to keep our costs down, so we'll use a lightweight; but powerful, model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "dTNqrip8AcKR"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfb_VCNKIy9w"
      },
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "Why is a \"powerful\" LLM important for this use-case?\n",
        "\n",
        "What tasks must our Agent perform that make it such that the LLM's reasoning capability is a potential limiter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "1. The Supervisor agent should understand the plan to properly build the research. If the supervisor agent is too simple and/or incapable of deep reasoning, we might run into a. issues with proper routing; b. incorrect/bad plan. \n",
        "2. Other research agents need to properly use tools at their disposal. For example, search is heavily dependent on writing correct queries. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_1LuMKAekf"
      },
      "source": [
        "### Research Team Agents & Nodes\n",
        "\n",
        "Now we can use our helper functions to create our agent nodes, with their related tools.\n",
        "\n",
        "Let's start with our search agent node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzx6wuPoAlPq"
      },
      "source": [
        "#### Research Team: Search Agent\n",
        "\n",
        "We're going to give our agent access to the Tavily tool, power it with our GPT-4o Mini model, and then create its node - and name it `Search`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "FIlLPxj7Atpj"
      },
      "outputs": [],
      "source": [
        "search_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
        ")\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLtesudA9Dd"
      },
      "source": [
        "#### Research Team: RAG Agent Node\n",
        "\n",
        "Now we can wrap our LCEL RAG pipeline in an agent node as well, using the LCEL RAG pipeline as the tool, as created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "z-nnAG9XA_p7"
      },
      "outputs": [],
      "source": [
        "research_agent = create_agent(\n",
        "    llm,\n",
        "    [retrieve_information],\n",
        "    \"You are a research assistant who can provide specific information on the student loan policies\",\n",
        ")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"LoanRetriever\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA5z6T1CBeSc"
      },
      "source": [
        "### Research Team Supervisor Agent\n",
        "\n",
        "Notice that we're not yet creating our supervisor *node*, simply the agent here.\n",
        "\n",
        "Also notice how we need to provide a few extra pieces of information - including which tools we're using.\n",
        "\n",
        "> NOTE: It's important to use the *exact* tool name, as that is how the LLM will reference the tool. Also, it's important that your tool name is all a single alphanumeric string!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "J0g8CQMBrtFs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pg/rr8c6_fx079ctz0nd__xmlgm0000gn/T/ipykernel_45772/488856706.py:34: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
            "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
          ]
        }
      ],
      "source": [
        "supervisor_agent = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  Search, LoanRetriever. Given the following user request,\"\n",
        "    \" determine the subject to be researched and respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. \"\n",
        "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
        "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
        "    \" When finished, respond with FINISH.\"),\n",
        "    [\"Search\", \"LoanRetriever\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qohn0DcgB_U1"
      },
      "source": [
        "### Research Team Graph Creation\n",
        "\n",
        "Now that we have our research team agent nodes created, and our supervisor agent - let's finally construct our graph!\n",
        "\n",
        "We'll start by creating our base graph from our state, and then adding the nodes/agent we've created as nodes on our LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "p0s2GAgJCN8G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x1451a40d0>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "research_graph = StateGraph(ResearchTeamState)\n",
        "\n",
        "research_graph.add_node(\"Search\", search_node)\n",
        "research_graph.add_node(\"LoanRetriever\", research_node)\n",
        "research_graph.add_node(\"supervisor\", supervisor_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33qixRGNCaAX"
      },
      "source": [
        "Now we can define our edges - include our conditional edge from our supervisor to our agent nodes.\n",
        "\n",
        "Notice how we're always routing our agent nodes back to our supervisor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "yYSJIhijsGyg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x1451a40d0>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "research_graph.add_edge(\"Search\", \"supervisor\")\n",
        "research_graph.add_edge(\"LoanRetriever\", \"supervisor\")\n",
        "research_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"Search\": \"Search\", \"LoanRetriever\": \"LoanRetriever\", \"FINISH\": END},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGcuZzkCj1-"
      },
      "source": [
        "Now we can set our supervisor node as the entry point, and compile our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1l-1I2Z3CnPX"
      },
      "outputs": [],
      "source": [
        "research_graph.set_entry_point(\"supervisor\")\n",
        "compiled_research_graph = research_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwQpYTSEY13"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "l8n6SXhpEa2b",
        "outputId": "6dac5e4e-daed-4d7a-d629-cd83119e7e2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(49905) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_research_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRvA2QfCqFL"
      },
      "source": [
        "The next part is key - since we need to \"wrap\" our LangGraph in order for it to be compatible in the following steps - let's create an LCEL chain out of it!\n",
        "\n",
        "This allows us to \"broadcast\" messages down to our Research Team LangGraph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1G7hmEINCx3i"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "    }\n",
        "    return results\n",
        "\n",
        "research_chain = enter_chain | compiled_research_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdoCdXWC7Pi"
      },
      "source": [
        "Now, finally, we can take it for a spin!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDpFIg2sRUl",
        "outputId": "bb3803d4-5b32-4b0a-c8a1-1a1917425812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'LoanRetriever'}}\n",
            "---\n",
            "{'LoanRetriever': {'messages': [HumanMessage(content=\"In 2025, the maximum student loan limits are as follows:\\n\\n- **Dependent Undergraduates**: Up to $31,000 total in subsidized and unsubsidized loans combined, with no more than $23,000 of that amount being subsidized.\\n\\n- **Independent Undergraduates**: Up to $57,500 total in subsidized and unsubsidized loans combined, with a maximum of $23,000 being subsidized.\\n\\n- **Graduate and Professional Students**: Up to $138,500 total in subsidized and unsubsidized loans combined, with up to $65,500 of that being subsidized.\\n\\nThese limits are aggregate limits, reflecting the total amount a student can borrow over their entire educational career, rather than annual limits. Specific annual loan amounts may vary based on the student's grade level and other factors.\", additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in research_chain.stream(\n",
        "    \"What is the maximum student loan in 2025?\", {\"recursion_limit\": 100}\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHAgsbwIIhwj"
      },
      "source": [
        "##### 🏗️ Activity #2:\n",
        "\n",
        "Using whatever drawing application you wish - please label the flow above on a diagram of your graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "I'm not sure I understand what this activity means (\"label the **flow** above on a **diagram** of your **graph**\" is a very confusing sentence for a non-native speaker. The three marked words are quite similar in their meaning to me; \"flow above\" — I assume that's the run (supervisor -> LoanRetriever -> supervisor), but I'm not sure I understand what \"diagram of your graph\" is).\n",
        "\n",
        "Hopefully the image below covers it. \n",
        "![flow_diagram_graph](img/flow_above_on_a_diagram_of_my_graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH70eHGlJbq4"
      },
      "source": [
        "##### ❓ Question #2:\n",
        "\n",
        "How could you make sure your Agent uses specific tools that you wish it to use? Are there any ways to concretely set a flow through tools?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "1. The main way: specify \"tool_choice\" in bind_tools method. In this way, the agent will be forced to use the tool. Caution: the agent will use it even when it doesn't make sense. \n",
        "2. Additional, non-robust way: write a prompt focused on ensuring the tool gets used.\n",
        "3. Additional, non-robust way: Validate output and return to agent if tool wasn't used.\n",
        "\n",
        "If we use tool_choice in bind_tools method to force tool usage, we may want to set up one tool per one forced agent. In that way, we can allocate mandatory tool usage while relying on supervisor to select tool-agent that fits the case. \n",
        "\n",
        "P.S. tool_choice can be set to 'any' in case we just want to force the model to use at least one tool from agent's toolbox. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iktcBorGXmAW"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejsHCZZ2EmwM"
      },
      "source": [
        "## Task 4: Document Writing Team - A LangGraph for Planning, Writing, and Editing a Formal Complaint Response.\n",
        "\n",
        "Let's run it all back, this time specifically creating tools, agent nodes, and a graph for Planning, Writing, and Editing a Formal Complaint Response!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Previous Complaint Data\n",
        "\n",
        "Let's add a retriever for [previous complaint data](./data/complaints.csv) here!\n",
        "\n",
        "This will allow our response writing team reference previous responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/complaints.csv', 'row': 0}, page_content=\"Consumer complaint narrative: The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\\nCompany public response: None\\nCompany response to consumer: Closed with explanation\")"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "complaint_loader = CSVLoader(\"data/complaints.csv\", content_columns=[\"Consumer complaint narrative\", \"Company public response\", \"Company response to consumer\"])\n",
        "complaints = complaint_loader.load()\n",
        "complaints[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "qdrant_complaint_vectorstore = Qdrant.from_documents(\n",
        "    documents=complaints,\n",
        "    embedding=embedding_model,\n",
        "    location=\":memory:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "qdrant_complaint_retriever = qdrant_complaint_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4awQtZ-oFUN-"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "Let's create some tools that will help us understand, open, work with, and edit documents to our liking!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ptXilgparOkq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Dict, Optional\n",
        "from typing_extensions import TypedDict\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "os.makedirs('./content/data', exist_ok=True)\n",
        "\n",
        "def create_random_subdirectory():\n",
        "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
        "    subdirectory_path = os.path.join('./content/data', random_id)\n",
        "    os.makedirs(subdirectory_path, exist_ok=True)\n",
        "    return subdirectory_path\n",
        "\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "@tool\n",
        "def create_outline(\n",
        "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
        "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
        ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"Outline saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_document(\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
        "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
        ") -> str:\n",
        "    \"\"\"Read the specified document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is not None:\n",
        "        start = 0\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "@tool\n",
        "def write_document(\n",
        "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a text document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "### Previous Complaint Data\n",
        "@tool \n",
        "def reference_previous_responses(\n",
        "    query: Annotated[str, \"The query to search for in the previous responses.\"],\n",
        ") -> Annotated[str, \"The previous responses that match the query.\"]:\n",
        "    \"\"\"Search for previous responses that match the query.\"\"\"\n",
        "    return qdrant_complaint_retriever.invoke(query)\n",
        "\n",
        "\n",
        "@tool\n",
        "def edit_document(\n",
        "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
        "    ] = {},\n",
        ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f\"Document edited and saved to {file_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8yH1IAYK7nL"
      },
      "source": [
        "##### 🏗️ Activity #3:\n",
        "\n",
        "Describe, briefly, what each of these tools is doing in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ✅ Answer:\n",
        "1. Create outline: creates outline (main points of the document), saves it to file.\n",
        "2. Read document: \"reads\" (returns) the document by joining it line by line.\n",
        "3. Write document: saves provided text to file.\n",
        "4. Reference previous responses: searches for query in previous responses by comparing embeddings of previous responses with the query.\n",
        "5. Edit document: adds lines to a document on specified indices, saves the file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Jw_XBIFwwa"
      },
      "source": [
        "### Document Writing State\n",
        "\n",
        "Just like with our Research Team state - we want to keep track of a few things, however this time - we also want to keep track of which files we've created - so let's add that here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "DoU2YwJRu7wD"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from pathlib import Path\n",
        "\n",
        "class DocWritingState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: str\n",
        "    next: str\n",
        "    current_files: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p1kQShmGHCh"
      },
      "source": [
        "### Document Writing Prelude Function\n",
        "\n",
        "Since we have a working directory - we want to be clear about what our current working directory looks like - this helper function will allow us to do that cleanly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "G79mUggQGLVq"
      },
      "outputs": [],
      "source": [
        "def prelude(state):\n",
        "    written_files = []\n",
        "    if not WORKING_DIRECTORY.exists():\n",
        "        WORKING_DIRECTORY.mkdir()\n",
        "    try:\n",
        "        written_files = [\n",
        "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
        "        ]\n",
        "    except:\n",
        "        pass\n",
        "    if not written_files:\n",
        "        return {**state, \"current_files\": \"No files written.\"}\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
        "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSre9agT9Gb"
      },
      "source": [
        "### Document Writing Node Creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "v7oso327T_wa"
      },
      "outputs": [],
      "source": [
        "doc_writer_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert writing customer assistance responses.\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
        "doc_writing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
        ")\n",
        "\n",
        "note_taking_agent = create_agent(\n",
        "    llm,\n",
        "    [create_outline, read_document, reference_previous_responses],\n",
        "    (\"You are an expert senior researcher tasked with writing a customer assistance outline and\"\n",
        "    \" taking notes to craft a customer assistance response.\\n{current_files}\"),\n",
        ")\n",
        "context_aware_note_taking_agent = prelude | note_taking_agent\n",
        "note_taking_node = functools.partial(\n",
        "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
        ")\n",
        "\n",
        "copy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert copy editor who focuses on fixing grammar, spelling, and tone issues\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_copy_editor_agent = prelude | copy_editor_agent\n",
        "copy_editing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_copy_editor_agent, name=\"CopyEditor\"\n",
        ")\n",
        "\n",
        "empathy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert in empathy, compassion, and understanding - you edit the document to make sure it's empathetic and compassionate.\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "empathy_editor_agent = prelude | empathy_editor_agent\n",
        "empathy_node = functools.partial(\n",
        "    agent_node, agent=empathy_editor_agent, name=\"EmpathyEditor\"\n",
        ")\n",
        "\n",
        "doc_writing_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers: {team_members}. You should always verify the technical\"\n",
        "    \" contents after any edits are made. \"\n",
        "    \"Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When each team is finished,\"\n",
        "    \" you must respond with FINISH.\"),\n",
        "    [\"DocWriter\", \"NoteTaker\", \"EmpathyEditor\", \"CopyEditor\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiNMpJBGXN0"
      },
      "source": [
        "### Document Writing Team LangGraph Construction\n",
        "\n",
        "This part is almost exactly the same (with a few extra nodes) as our Research Team LangGraph construction - so we'll leave it as one block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Q6n8A1ytxVTv"
      },
      "outputs": [],
      "source": [
        "authoring_graph = StateGraph(DocWritingState)\n",
        "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
        "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
        "authoring_graph.add_node(\"CopyEditor\", copy_editing_node)\n",
        "authoring_graph.add_node(\"EmpathyEditor\", empathy_node)\n",
        "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
        "\n",
        "authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"CopyEditor\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"EmpathyEditor\", \"supervisor\")\n",
        "\n",
        "authoring_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"DocWriter\": \"DocWriter\",\n",
        "        \"NoteTaker\": \"NoteTaker\",\n",
        "        \"CopyEditor\" : \"CopyEditor\",\n",
        "        \"EmpathyEditor\" : \"EmpathyEditor\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "authoring_graph.set_entry_point(\"supervisor\")\n",
        "compiled_authoring_graph = authoring_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-EKGkHKUBO"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AZdOb3GZKSM7",
        "outputId": "6b64588d-5568-4234-d062-4dc83ea9abec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(51194) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_authoring_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB_rOw1hGpwd"
      },
      "source": [
        "Just as before - we'll need to create an \"interface\" between the level above, and our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "G-RbbCKoG_nt"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str, members: List[str]):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "        \"team_members\": \", \".join(members),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "authoring_chain = (\n",
        "    functools.partial(enter_chain, members=authoring_graph.nodes)\n",
        "    | authoring_graph.compile()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgyhpTrRNgQd"
      },
      "source": [
        "Now we can test this out!\n",
        "\n",
        "> NOTE: It is possible you may see an error here - rerun the cell to clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWUxv4XDx3kg",
        "outputId": "62ee7d3d-31ba-4348-b852-7fd96f6875ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'DocWriter'}}\n",
            "---\n",
            "{'DocWriter': {'messages': [HumanMessage(content='I have created and saved a customer assistance response regarding the positioning of student loans as it relates to low-income students. If you need further modifications or additional information, please let me know!', additional_kwargs={}, response_metadata={}, name='DocWriter')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'NoteTaker'}}\n",
            "---\n",
            "{'NoteTaker': {'messages': [HumanMessage(content=\"I have reviewed and noted the response you've composed regarding student loans and low-income students. Here’s the crafted customer assistance response based on the document:\\n\\n---\\n\\n**Subject: Understanding Student Loans for Low-Income Students**\\n\\nDear [Customer's Name],\\n\\nThank you for reaching out to us regarding the positioning of student loans, especially as it relates to low-income students. We understand how essential it is for you to navigate this aspect of funding your education.\\n\\nStudent loans can play a crucial role for low-income students seeking higher education. Here are some key points to consider:\\n\\n1. **Accessibility**: Student loans are designed to help cover tuition and other educational expenses for students who may not have the financial means to pay for school upfront. They provide access to education that might otherwise be out of reach.\\n\\n2. **Federal Student Loans**: Many low-income students may qualify for federal student loans, which often have lower interest rates and more flexible repayment options compared to private loans. Programs such as the Direct Subsidized Loan are specifically aimed at undergraduates with demonstrated financial need, where interest does not accrue while the student is enrolled at least half-time.\\n\\n3. **Income-Driven Repayment Plans**: For federal loans, income-driven repayment plans can adjust monthly payments based on income, which can significantly ease the financial burden after graduation.\\n\\n4. **Loan Forgiveness Programs**: There are also various loan forgiveness programs available for those who go into certain fields, particularly public service roles. These can provide significant financial relief for low-income graduates who qualify.\\n\\n5. **Financial Literacy**: Understanding the terms of loans, interest rates, and repayment options is vital for making informed choices. We encourage students to seek workshops, counseling, or resources that can help improve financial literacy.\\n\\n6. **Scholarship Opportunities**: While student loans are an option, we also recommend exploring scholarships, grants, and work-study opportunities that do not require repayment. These can considerably reduce the amount borrowed and help manage future financial obligations.\\n\\nWe are here to support you in exploring the best options based on your particular situation. Please do not hesitate to reach out if you have more questions or need assistance with your financial aid journey.\\n\\nBest Regards,\\n\\n[Your Name]  \\n[Your Title]  \\n[Your Organization]  \\n[Your Contact Information]  \\n[Your Website]  \\n\\n---\\n\\nFeel free to make any modifications or let me know if you need additional assistance!\", additional_kwargs={}, response_metadata={}, name='NoteTaker')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'EmpathyEditor'}}\n",
            "---\n",
            "{'EmpathyEditor': {'messages': [HumanMessage(content='The customer assistance response regarding the positioning of student loans as related to low-income students has been successfully crafted and saved. If you need any further modifications or additional information, please feel free to let me know!', additional_kwargs={}, response_metadata={}, name='EmpathyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'CopyEditor'}}\n",
            "---\n",
            "{'CopyEditor': {'messages': [HumanMessage(content='The customer assistance response regarding the positioning of student loans as it relates to low-income students has been successfully edited and saved. The content is clear, empathetic, and informative, addressing the needs and concerns of low-income students regarding student loans effectively. If further modifications or additional assistance are needed, please let me know!', additional_kwargs={}, response_metadata={}, name='CopyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in authoring_chain.stream(\n",
        "    \"Write a customer assistance response on the positioning of Student Loans as it relates to low income students.\",\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpW2R9SUHGUq"
      },
      "source": [
        "## Task 5: Meta-Supervisor and Full Graph\n",
        "\n",
        "Finally, now that we have our two LangGraph agents (some of which are already multi-agent), we can build a supervisor that sits above all of them!\n",
        "\n",
        "The final process, surprisingly, is quite straight forward!\n",
        "\n",
        "Let's jump in!\n",
        "\n",
        "First off - we'll need to create our supervisor agent node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "wkpxeUf9ygKp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "supervisor_node = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following teams: {team_members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When all workers are finished,\"\n",
        "    \" you must respond with FINISH.\",\n",
        "    [\"Research team\", \"Response team\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvOh_xWIKig"
      },
      "source": [
        "We'll also create our new state - as well as some methods to help us navigate the new state and the subgraphs.\n",
        "\n",
        "> NOTE: We only pass the most recent message from the parent graph to the subgraph, and we only extract the most recent message from the subgraph to include in the state of the parent graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "O7HJ8MF0yh_i"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    next: str\n",
        "\n",
        "def get_last_message(state: State) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RHao1sIanG"
      },
      "source": [
        "Next, we'll create our base graph.\n",
        "\n",
        "Notice how each node we're adding is *AN ENTIRE LANGGRAPH AGENT* (wrapped into an LCEL chain with our helper functions above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "PfCWABCMIaFy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x1604f69d0>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "super_graph = StateGraph(State)\n",
        "\n",
        "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
        "super_graph.add_node(\"Response team\", get_last_message | authoring_chain | join_graph)\n",
        "super_graph.add_node(\"supervisor\", supervisor_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpwpUXMtI62E"
      },
      "source": [
        "Next, we'll create our edges!\n",
        "\n",
        "This process is completely idenctical to what we've seen before - just addressing the LangGraph subgraph nodes instead of individual nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "tLtjRuUYI-fx"
      },
      "outputs": [],
      "source": [
        "super_graph.add_edge(\"Research team\", \"supervisor\")\n",
        "super_graph.add_edge(\"Response team\", \"supervisor\")\n",
        "super_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"Response team\": \"Response team\",\n",
        "        \"Research team\": \"Research team\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "super_graph.set_entry_point(\"supervisor\")\n",
        "compiled_super_graph = super_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KMfFqgJKw8"
      },
      "source": [
        "That's it!\n",
        "\n",
        "Now we can finally use our full agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6wUDR-yk8s",
        "outputId": "056fe89e-5a81-4852-f0cb-35367da8cef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'Research team'}}\n",
            "---\n",
            "{'Research team': {'messages': [HumanMessage(content=\"**Subject: Assistance Regarding Student Loans for Low-Income Students**\\n\\nDear [Customer Name],\\n\\nThank you for reaching out to us regarding the positioning of student loans, particularly as they relate to low-income students. We understand that navigating student loans can be a challenging experience, especially for those from underprivileged backgrounds.\\n\\nRecent insights from the **2023-2024 Student Loan Borrower Survey** highlight some critical challenges faced by low-income borrowers. It was found that around **31%** of these borrowers, especially those on standard repayment plans, were unaware of their options to switch to more manageable repayment plans. Furthermore, **14%** indicated a need for more support in selecting appropriate plans. This gap in knowledge can hinder low-income students who could greatly benefit from Income-Driven Repayment (IDR) plans but often do not take advantage due to their complexity.\\n\\nThe resumption of federal student loan payments in **October 2023**, following an extended moratorium, adds more pressure to these borrowers. The **Consumer Financial Protection Bureau** noted that while many borrowers experienced positive changes after receiving debt relief, numerous individuals are still uninformed about how to successfully navigate the repayment process.\\n\\nConcerning federal student loan policies, low-income students may be eligible for **Direct Subsidized Loans**, which are specifically designed for those with financial need and do not accrue interest while enrolled at least half-time or during certain other periods. Schools are required to consider a student's financial need when packaging aid and must also determine a student's eligibility for Pell Grants before originating loans. It's worthwhile to note that the total loan amount in combination with other forms of aid cannot exceed a student’s identified financial need.\\n\\nIn response to the unique challenges faced by low-income students, initiatives such as the **SAVE program** have been implemented to simplify repayment terms and potentially lessen monthly financial burdens based on income levels. Staying informed about these resources is crucial for borrowers in making informed decisions that affect their financial futures.\\n\\nIf you or anyone else needs guidance on exploring repayment options or managing student debt, we encourage you to reach out. Our team is here to assist you in finding the necessary resources and support to navigate this complex financial landscape.\\n\\nBest regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]  \\n[Your Organization]  \\n\\n---\\n\\nThis response has been crafted to ensure clarity, accuracy, and readiness for the customer's concerns. If further adjustments are needed or additional information should be included, please let me know.\", additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'Response team'}}\n",
            "---\n",
            "{'Response team': {'messages': [HumanMessage(content='The revised document has been successfully saved as **Student_Loans_Assistance_Low_Income_Students.txt**. If you require any further modifications or additional assistance, please feel free to ask!', additional_kwargs={}, response_metadata={}, name='DocWriter')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "for s in compiled_super_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Write a customer assistance response on the positioning of Student Loans as it relates to low income students. First consult the research team. Then make sure you consult the response team, and check for copy editing and dopeness, and write the file to disk.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 30},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZAvSlJJpPP"
      },
      "source": [
        "## SAMPLE POST!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEMCrXTJaxW"
      },
      "source": [
        "**Subject: Assistance Regarding Student Loans for Low-Income Students**\n",
        "\n",
        "Dear [Customer's Name],\n",
        "\n",
        "Thank you for reaching out regarding student loans and their implications for low-income students. We understand that navigating the financial aid landscape can be daunting, and we’re here to provide guidance and support.\n",
        "\n",
        "Student loans are instrumental in granting low-income students access to higher education, especially when scholarships and grants may fall short of covering the full cost of attendance. The federal student loan program presents various options designed to make borrowing more manageable for those in need.\n",
        "\n",
        "**1. Understanding Loan Types:**\n",
        "   - **Subsidized Loans**: These loans are available to undergraduate students who demonstrate financial need. The government covers the interest while the borrower is enrolled at least half-time, which can significantly alleviate the overall debt burden upon graduation.\n",
        "   - **Unsubsidized Loans**: Accessible to both undergraduate and graduate students, these loans do not require a demonstration of financial need. However, interest starts accruing from the moment the loan is disbursed.\n",
        "\n",
        "**2. Income-Based Repayment Options:**\n",
        "For low-income borrowers, Income-Based Repayment (IBR) plans can be especially advantageous. These plans ensure that monthly payments are based on income and family size, which helps keep payments manageable. Additionally, after 20-25 years of qualifying payments, any remaining loan balance may be eligible for forgiveness. \n",
        "\n",
        "**3. Key Benefits:**\n",
        "   - **Lower Payments**: IBR plans decrease the monthly payment amount, making it easier for low-income students to manage their loans successfully.\n",
        "   - **Forgiveness Opportunities**: Those who pursue careers in public service may qualify for further loan forgiveness options.\n",
        "\n",
        "**4. The Importance of Financial Aid Awareness:**\n",
        "It is vital for low-income students to be aware of their options concerning financial aid and student loans. We recommend that students and families familiarize themselves with the array of resources available, such as [Federal Student Aid](https://studentaid.gov), which provides comprehensive information on eligibility and application processes.\n",
        "\n",
        "If you need further assistance or have specific questions, please don’t hesitate to reach out. Our goal is to ensure that every student can pursue their educational aspirations without the fear of overwhelming debt.\n",
        "\n",
        "Best regards,\n",
        "\n",
        "[Your Name]  \n",
        "[Your Position]  \n",
        "[Your Contact Information]  \n",
        "[Your Organization]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
